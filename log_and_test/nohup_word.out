hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)
Scipy not supported!
Traceback (most recent call last):
  File "train.py", line 10, in <module>
    from data_util_hdf5 import create_or_load_vocabulary,load_data_multilabel,get_part_validation_data #,imprisonment_mean,imprisonment_std
  File "/root/ai_lawyer/data_util_hdf5.py", line 16, in <module>
    import h5py
ImportError: No module named h5py
Scipy not supported!
Traceback (most recent call last):
  File "train.py", line 13, in <module>
    import gensim
ImportError: No module named gensim
Scipy not supported!
Traceback (most recent call last):
  File "train.py", line 13, in <module>
    import gensim
ImportError: No module named gensim
('model:', 'text_cnn')
('cache_path:', 'cache_text_cnn/vocab_label.pik', 'file_exists:', True)
going to load cache file.vocab of words and labels
('cnn_model.vocab_size:', 100002)
('accusation_num_classes:', 202)
('article_num_clasess:', 183)
('cache_path:', 'cache_text_cnn/train_valid_test.h5', 'train_valid_test_file_exists:', False)
('length of train_lines:', 529068, ';length of valid_lines:', 13094, ';length of test_lines:', 32508)
('start multi-processing:', 0, 'cache_text_cnn/training_data_temp_0.pik')
('start multi-processing:', 1, 'cache_text_cnn/training_data_temp_1.pik')
('start multi-processing:', 2, 'cache_text_cnn/training_data_temp_2.pik')
('start multi-processing:', 3, 'cache_text_cnn/training_data_temp_3.pik')
('start multi-processing:', 4, 'cache_text_cnn/training_data_temp_4.pik')
('start multi-processing:', 5, 'cache_text_cnn/training_data_temp_5.pik')
('start multi-processing:', 6, 'cache_text_cnn/training_data_temp_6.pik')
('start multi-processing:', 7, 'cache_text_cnn/training_data_temp_7.pik')
('start multi-processing:', 8, 'cache_text_cnn/training_data_temp_8.pik')
('start multi-processing:', 9, 'cache_text_cnn/training_data_temp_9.pik')
('start multi-processing:', 10, 'cache_text_cnn/training_data_temp_10.pik')
('start multi-processing:', 11, 'cache_text_cnn/training_data_temp_11.pik')
('start multi-processing:', 12, 'cache_text_cnn/training_data_temp_12.pik')
('start multi-processing:', 13, 'cache_text_cnn/training_data_temp_13.pik')
('start multi-processing:', 14, 'cache_text_cnn/training_data_temp_14.pik')
('start multi-processing:', 15, 'cache_text_cnn/training_data_temp_15.pik')
('start multi-processing:', 16, 'cache_text_cnn/training_data_temp_16.pik')
('start multi-processing:', 17, 'cache_text_cnn/training_data_temp_17.pik')
('start multi-processing:', 18, 'cache_text_cnn/training_data_temp_18.pik')
('start multi-processing:', 19, 'cache_text_cnn/training_data_temp_19.pik')
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Dumping model to file cache /tmp/jieba.cache
Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 1.856 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1266, 5652, 6910, 45, 18, 30, 73, 9, 19, 10, 46, 12, 201, 36, 200, 154, 2, 6, 126, 19, 13, 3, 1290, 14, 5649, 11, 5652, 6910, 2173, 13249, 30620, 29969, 155, 226, 2, 164, 37530, 57086, 26, 4576, 4039, 5, 1397, 1214, 5, 69676, 2, 63081, 13, 1367, 779, 230, 1023, 62, 9042, 33, 26, 8571, 4, 5652, 6910, 45, 18, 94, 169, 1917, 5, 34, 76, 30, 14, 3, 252, 40, 19, 3, 173, 40, 46, 3, 67, 69, 40, 58, 3, 6, 44, 41, 214, 40, 49, 3, 32, 197, 40, 83, 3, 290, 3, 282, 3, 177, 3, 699, 3087, 22, 60, 40, 80, 3, 734, 4, 5652, 6910, 45, 64, 30, 6, 126, 19, 13, 3, 1290, 14, 5649, 1286, 317, 4154, 206, 5494, 2, 124, 47, 7, 7, 137, 114, 2, 6, 126, 19, 13, 3, 1290, 14, 92200, 470, 2, 327, 1085, 51, 68, 78, 50, 7, 7, 3, 7, 7, 110, 71, 74, 26, 116, 104, 2, 27, 210, 104, 6, 126, 19, 13, 3, 1290, 14, 5649, 5800, 343, 7, 7, 4])
(0, 'x_feature:', [0.09523809523809523, 0.0, 0.07142857142857142, 0.0, 0.05263157894736842, 0.1875, 0.0, 0.10526315789473684, 0.05263157894736842, 0.045454545454545456, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0625, 0.06666666666666667, 0.16666666666666666, 0.0, 0.0, 0.08333333333333333, 0.0, 0.14285714285714285, 0.08333333333333333, 0.0, 0.0, 0.1, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u6545\u610f\u6740\u4eba'])
(0, '#######transform_data_to_index.accusation_list(index):', [187])
(0, '#######transform_data_to_index.article_list(string):', [u'232'])
(0, '#######transform_data_to_index.article_list(index):', [156])
Loading model cost 1.767 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17580, 45, 18, 2, 6, 8397, 11, 809, 13215, 17580, 9321, 4378, 2963, 13377, 204, 2, 477, 21, 1258, 9118, 62, 10548, 5, 188, 2, 616, 76, 30, 2133, 9, 75, 10, 2, 6, 8397, 76830, 8, 1, 8, 3, 737, 8, 3, 2364, 8, 768, 901, 819, 75, 257, 2, 645, 200, 257, 2, 1885, 8, 364, 20, 2238, 224, 643, 4, 1838, 9, 2, 6, 8397, 25, 401, 8, 47, 307, 8, 3, 63, 146, 3, 138, 8, 768, 901, 819, 75, 257, 2, 645, 200, 257, 2, 401, 8, 364, 20, 2238, 224, 643, 4, 2133, 9, 86, 10, 38, 1838, 9, 49, 817, 2, 6, 8397, 25, 12687, 96, 95, 23, 13215, 17580, 4378, 2258, 4292, 1328, 2488, 24, 70218, 8, 3, 88, 8, 3, 1050, 8, 768, 901, 819, 75, 257, 2, 645, 200, 257, 2, 2238, 224, 643, 4, 1838, 9, 2, 6, 8397, 5, 540, 738, 1, 13, 835, 819, 27, 150, 21, 819, 169, 2550, 5, 235, 542, 4, 80035, 13, 390, 738, 150, 5, 542, 2, 1663, 738, 22, 2796, 2, 108, 432, 58, 10, 388, 12, 819, 75, 257, 2, 174, 26, 2116, 502, 4867, 2, 2238, 224, 643, 4, 322, 42, 2, 29, 28, 443, 21, 2, 173, 3, 67, 69, 3, 6, 44, 41, 214, 22, 34, 2, 64, 6, 8397, 5, 61, 66, 130, 7, 7, 3, 7, 7, 2, 194, 115, 116, 104, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.0, 0.0, 0.10526315789473684, 0.1875, 0.0, 0.0, 0.05263157894736842, 0.13636363636363635, 0.0, 0.09090909090909091, 0.07692307692307693, 0.058823529411764705, 0.0, 0.0, 0.25, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.1, 0.0, 0.2727272727272727])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u8fdd\u6cd5\u53d1\u653e\u8d37\u6b3e', u'\u632a\u7528\u8d44\u91d1'])
(0, '#######transform_data_to_index.accusation_list(index):', [34, 100])
(0, '#######transform_data_to_index.article_list(string):', [u'272', u'186'])
(0, '#######transform_data_to_index.article_list(index):', [79, 151])
('####################freq_accusation:', 313, 'freq_article:', 312, ';num_copy:', 6)
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Dumping model to file cache /tmp/jieba.cache
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 2.583 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 30, 6, 96, 120, 220, 9, 75, 10, 536, 11, 4022, 8689, 212, 423, 8354, 36254, 3547, 207, 4, 98, 9, 49, 10, 398, 12, 2, 6, 96, 164, 14326, 2, 25, 2225, 431, 4570, 2, 4746, 38, 2609, 3958, 22, 559, 2674, 2, 1773, 237, 431, 6591, 1745, 1640, 5, 1534, 170, 1, 15, 4, 727, 4022, 3985, 62, 1205, 4277, 2762, 431, 679, 237, 431, 4, 57, 9, 14, 10, 388, 12, 2, 6, 96, 11, 1090, 1396, 2696, 37, 91, 4])
(0, 'x_feature:', [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05263157894736842, 0.045454545454545456, 0.0, 0.0, 0.0, 0.058823529411764705, 0.0, 0.0, 0.08333333333333333, 0.0, 0.09090909090909091, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data('train', 'transform_data_to_index.####################.start.')
_to_index.accusation_list(string):', [u'\u62d2\u4e0d\u652f\u4ed8\u52b3\u52a8\u62a5\u916c'])
(0, '#######transform_data_to_index.accusation_list(index):', [108])
(0, '#######transform_data_to_index.article_list(string):', [u'276'])
(0, '#######transform_data_to_index.article_list(index):', [149])
Loading model cost 2.140 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 2204, 3963, 161, 2, 785, 256, 2252, 3160, 5, 188, 62, 34, 4])
(0, 'x_feature:', [0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u632a\u7528\u8d44\u91d1'])
(0, '#######transform_data_to_index.accusation_list(index):', [100])
(0, '#######transform_data_to_index.article_list(string):', [u'272'])
(0, '#######transform_data_to_index.article_list(index):', [79])
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Dumping model to file cache /tmp/jieba.cache
Loading model cost 0.836 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 30, 256, 3, 317, 1627, 3430, 1469, 118, 855, 9, 38, 220, 9, 204, 2, 6, 3807, 14, 5913, 3, 1116, 146, 11, 1403, 1518, 1514, 2141, 5, 175, 273, 2, 47, 3187, 997, 25, 3875, 2, 84, 1205, 237, 4138, 209, 1627, 1469, 4, 1579, 520, 30, 14, 3, 6, 3807, 14, 5913, 47, 11, 7045, 30051, 212, 22565, 661, 27714, 1255, 577, 5, 768, 2, 731, 579, 9, 75, 10, 38, 365, 9, 14, 10, 370, 3529, 84, 63, 2128, 732, 2, 170, 2940, 264, 4, 19, 3, 6, 3807, 14, 5913, 47, 428, 5621, 3, 1255, 591, 3, 577, 5, 768, 2, 731, 855, 9, 49, 10, 38, 579, 9, 49, 10, 370, 3529, 84, 339, 13, 732, 2, 170, 10780, 264, 4, 46, 3, 6, 3807, 14, 5913, 47, 428, 5621, 5, 768, 2, 108, 365, 9, 120, 79, 14, 846, 732, 143, 264, 4, 58, 3, 6, 3807, 14, 5913, 11, 126, 232, 13, 5, 1081, 273, 2, 47, 4867, 5, 768, 2, 731, 365, 9, 14, 10, 38, 432, 97, 10, 370, 2171, 84, 79, 146, 732, 2, 170, 3487, 264, 4, 49, 3, 6, 3807, 14, 5913, 3, 1116, 146, 25998, 591, 3, 577, 5, 768, 2, 731, 365, 9, 46, 10, 38, 432, 49, 10, 370, 915, 84, 39905, 42761, 8817, 207, 732, 2, 170, 349, 264, 4, 83, 3, 6, 3807, 14, 5913, 3, 1116, 146, 25998, 591, 3, 577, 5, 768, 2, 731, 365, 9, 58, 10, 38, 220, 9, 6174, 370, 915, 84, 377, 732, 2, 170, 143, 264, 4, 80, 3, 6, 3807, 14, 5913, 25998, 591, 5, 768, 2, 108, 365, 9, 58, 10, 84, 975, 13, 732, 200, 264, 4, 89, 3, 6, 3807, 14, 5913, 3, 1116, 146, 25998, 591, 5, 768, 2, 108, 365, 9, 49, 10, 84, 79, 13, 95, 732, 200, 264, 4, 97, 3, 6, 3807, 14, 5913, 291, 92, 8423, 5, 1081, 2, 108, 365, 9, 83, 3, 80, 304, 370, 915, 84, 79, 1109, 732, 2, 170, 592, 264, 4, 75, 3, 6, 3807, 14, 5913, 25998, 591, 3, 577, 22, 768, 2, 108, 220, 9, 46, 10, 84, 92, 6420, 732, 19, 264, 4, 86, 3, 6, 3807, 14, 5913, 291, 203, 430, 5, 1081, 2, 731, 365, 9, 89, 10, 38, 365, 9, 100, 10, 47, 4867, 5, 768, 370, 1204, 84, 138, 13, 95, 732, 2, 170, 4812, 264, 4, 100, 3, 6, 3807, 14, 5913, 291, 203, 95, 41, 138, 1109, 5, 1081, 2, 731, 365, 9, 89, 10, 38, 365, 9, 75, 10, 47, 4867, 3, 2719, 577, 22, 768, 2, 84, 59, 1360, 732, 2, 170, 592, 264, 4, 250, 3, 6, 3807, 14, 5913, 291, 63, 14, 13, 423, 5, 5435, 18116, 168, 1081, 2, 108, 365, 9, 97, 10, 47, 178, 5, 768, 2, 84, 1175, 13, 732, 75, 264, 4, 232, 3, 6, 3807, 14, 5913, 3, 1116, 146, 291, 63, 14, 13, 423, 5, 5435, 18116, 168, 1081, 2, 108, 365, 9, 97, 10, 84, 79, 1831, 732, 200, 264, 4, 201, 3, 6, 3807, 14, 5913, 291, 88, 14, 13, 1081, 2, 108, 365, 9, 75, 10, 25998, 577, 5, 768, 2, 84, 88, 2128, 732, 371, 264, 4, 239, 3, 6, 3807, 14, 1, 4867, 5, 768, 2, 108, 365, 9, 100, 10, 84, 385, 13, 95, 732, 143, 264, 4, 241, 3, 6, 3807, 14, 5913, 25998, 591, 3, 577, 5, 768, 2, 108, 220, 37307, 5270, 84, 307, 146, 732, 2, 170, 301, 264, 4, 248, 3, 6, 3807, 14, 5913, 291, 63, 146, 1081, 2, 108, 220, 9, 19, 10, 25998, 7540, 591, 5, 768, 2, 84, 79, 13, 1360, 732, 143, 264, 4, 242, 3, 6, 3807, 14, 5913, 3, 1116, 3332, 4261, 5, 768, 2, 108, 220, 9, 46, 10, 84, 126, 6908, 732, 49, 264, 4, 143, 3, 6, 3807, 14, 1, 220, 9, 14, 10, 75, 2090, 339, 14, 13, 732, 75, 264, 4, 179, 3, 6, 3807, 14, 5913, 3, 1116, 146, 25998, 591, 5, 768, 2, 108, 220, 9, 84, 63, 1831, 732, 49, 264, 4, 233, 3, 6, 3807, 14, 5913, 3, 1116, 146, 291, 238, 54, 5, 1081, 2, 108, 220, 9, 46, 10, 25998, 591, 5, 768, 84, 63, 3220, 732, 200, 264, 4, 247, 3, 6, 3807, 14, 1, 2719, 2385, 1255, 577, 5, 768, 2, 108, 220, 9, 49, 10, 84, 39905, 1798, 24762, 732, 301, 264, 4, 388, 3, 6, 3807, 14, 5913, 3, 1116, 2722, 220, 9, 89, 10, 84, 238, 95, 732, 58, 264, 4, 321, 3, 6, 3807, 14, 5913, 47, 428, 5621, 5, 768, 2, 108, 220, 9, 86, 10, 84, 339, 19, 13, 732, 200, 264, 4, 403, 3, 6, 3807, 14, 1, 17886, 20084, 5, 768, 2, 108, 365, 9, 415, 84, 385, 146, 732, 49, 264, 4, 393, 3, 6, 3807, 14, 5913, 3, 1116, 146, 25998, 591, 5, 768, 2, 108, 220, 9, 84, 92, 12651, 732, 592, 264, 4, 398, 3, 6, 3807, 14, 5913, 291, 26, 900, 126, 19, 13, 16428, 1081, 2, 731, 365, 9, 38, 220, 37307, 318, 47, 2935, 1770, 84, 138, 1109, 732, 2, 170, 349, 264, 4, 452, 3, 6, 3807, 14, 5913, 3, 1116, 146, 25998, 591, 3, 577, 5, 768, 2, 108, 365, 9, 80, 10, 75, 2090, 92, 6420, 732, 3191, 264, 4, 200, 3, 6, 3807, 14, 1, 4867, 5, 768, 2, 108, 365, 9, 1819, 84, 126, 58, 13, 732, 75, 264, 4, 560, 3, 6, 1116, 2722, 220, 9, 83, 10, 415, 2, 84, 1116, 13, 95, 62, 732, 75, 264, 129, 3807, 14, 5913, 364, 4, 2218, 3, 6, 1116, 2722, 220, 9, 83, 10, 452, 12, 2, 84, 126, 9508, 732, 1329, 264, 129, 3807, 14, 5913, 364, 4, 2479, 3, 6, 1116, 2722, 220, 9, 100, 10, 250, 12, 2, 84, 3807, 13, 732, 321, 264, 129, 3807, 14, 5913, 364, 4, 454, 3, 3794, 840, 118, 6, 3807, 14, 5913, 731, 220, 9, 46, 10, 1576, 2, 11, 553, 155, 397, 1291, 1280, 37, 1422, 82, 815, 38, 7045, 667, 2, 166, 155, 1249, 423, 5, 591, 3, 577, 3548, 1249, 8095, 5, 175, 273, 2, 679, 47, 1028, 1255, 591, 3, 577, 5, 768, 2, 47, 3187, 997, 25, 6241, 2, 323, 714, 2, 18507, 520, 30, 14, 3, 6, 3807, 14, 5913, 25998, 591, 3, 577, 5, 768, 108, 220, 9, 83, 10, 143, 2090, 126, 9508, 732, 200, 264, 4, 19, 3, 6, 3807, 14, 1, 155, 2180, 16135, 5, 7045, 30051, 212, 22565, 661, 1322, 1356, 3787, 865, 4513, 289, 20, 1394, 129, 126, 9508, 2, 73816, 146, 5, 768, 108, 220, 9, 83, 10, 452, 12, 840, 1329, 264, 4, 46, 3, 6, 3807, 14, 5913, 25998, 591, 1474, 2, 73816, 146, 5, 768, 108, 220, 9, 100, 10, 250, 2090, 3807, 13, 732, 321, 264, 4, 58, 3, 6, 3807, 14, 5913, 25998, 577, 1474, 2, 73816, 146, 5, 768, 108, 220, 9, 83, 10, 415, 84, 1116, 13, 95, 62, 732, 75, 264, 4, 49, 3, 6, 3807, 14, 5913, 25998, 591, 3, 577, 5, 768, 2, 108, 220, 9, 80, 10, 3, 220, 9, 97, 10, 3, 220, 9, 100, 10, 370, 1204, 84, 92, 6420, 732, 2, 170, 301, 264, 4, 83, 3, 6, 3807, 14, 1, 4867, 5, 768, 2, 108, 220, 9, 83, 10, 3, 220, 9, 89, 10, 370, 915, 84, 126, 58, 13, 732, 2, 170, 371, 264, 4, 641, 3, 840, 118, 6, 3807, 14, 5913, 2180, 16135, 7045, 30051, 212, 22565, 661, 1322, 1356, 3787, 1853, 2, 865, 1261, 4513, 289, 9169, 2, 11, 138, 1109, 318, 5329, 1352, 36, 2, 230, 497, 1873, 2054, 4513, 289, 11489, 138, 1109, 6252, 264, 1352, 2, 27, 33, 6252, 264, 5, 3038, 6491, 4, 74, 18, 5, 94, 2, 883, 150, 21, 6, 3807, 14, 5913, 3, 1116, 146, 5, 44, 41, 214, 3, 16, 133, 3, 67, 69, 3, 173, 3, 32, 197, 22, 34, 191, 81, 4, 29, 28, 64, 2, 6, 3807, 14, 5913, 3, 1116, 3332, 5948, 25, 3875, 2, 84, 1205, 237, 4138, 209, 1627, 1469, 2, 26, 61, 202, 21, 51, 68, 78, 50, 7, 7, 110, 71, 2, 327, 47, 7, 7, 137, 114, 2, 210, 74, 6, 3807, 14, 5913, 11, 7, 7, 330, 498, 27, 335Loading model cost 0.625 seconds.
, 2, 74, 6, 1116, 146, 11, 7, 7, 330, 498, 27, 335, 40, 6, 3807, 14, 1, 488, 25, 433, 2, 1028, 188, 2, 317, 3794, 2, 26, 61, 202, 21, 51, 68, 78, 50, 7, 7, 5, 71, 2, 327, 47, 7, 7, 137, 114, 2, 210, 74, 26, 11, 7, 7, 330, 498, 27, 335, 40, 47, 488, 25, 433, 2, 323, 243, 490, 2, 26, 61, 202, 21, 51, 68, 78, 50, 7, 7, 5, 71, 2, 327, 47, 5553, 137, 114, 2, 210, 11, 7, 7, 330, 498, 27, 335, 4])
Prefix dict has been built succesfully.
(0, 'x_feature:', [0.09523809523809523, 0.0, 0.2857142857142857, 0.08333333333333333, 0.42105263157894735, 0.25, 0.0, 0.10526315789473684, 0.05263157894736842, 0.45454545454545453, 0.0, 0.0, 0.5384615384615384, 0.058823529411764705, 0.25, 0.06666666666666667, 0.4166666666666667, 0.2, 0.18181818181818182, 0.08333333333333333, 0.0, 0.07142857142857142, 0.4166666666666667, 0.0, 0.0, 0.1, 0.2727272727272727, 0.09090909090909091])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u5438\u6536\u516c\u4f17\u5b58\u6b3e', u'\u96c6\u8d44\u8bc8\u9a97'])
(0, '#######transform_data_to_index.accusation_list(index):', [67, 120])
(0, '#######transform_data_to_index.article_list(string):', [u'176'])
(0, '#######transform_data_to_index.article_list(index):', [104])
('####################freq_accusation:', 851, 'freq_article:', 4490, ';num_copy:', 3)
(0, '#######transform_data_to_index.x:', [1479, 657, 12533, 45, 18, 30, 181, 9, 14, 10, 89, 12, 216, 2, 6, 59, 38, 1159, 1376, 5820, 1, 1005, 277, 201, 945, 14, 4781, 760, 2, 359, 4044, 22, 4433, 2, 258, 16, 92, 19, 272, 11, 665, 5, 52, 56621, 53, 149, 356, 338, 229, 4, 2581, 2, 6, 59, 11, 123, 277, 201, 945, 43, 239, 945, 799, 2, 359, 2053, 21274, 20, 10025, 4225, 22, 4433, 2, 357, 258, 16, 2497, 5, 52, 1, 53, 149, 83, 378, 91226, 378, 592, 407, 982, 14, 763, 3, 52, 1, 53, 149, 83, 378, 24285, 378, 2493, 407, 982, 14, 763, 3, 16, 59, 14, 5, 52, 20023, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 3, 16, 853, 5, 52, 20023, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 23, 2215, 763, 56, 31, 2023, 15, 24, 3, 16, 733, 46, 5, 52, 16848, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 3, 16, 92, 14, 5, 52, 20023, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 38, 4, 109, 426, 356, 338, 43, 86016, 170, 56, 31, 82192, 15, 4, 20, 6, 59, 35, 109, 258, 5, 982, 338, 602, 258, 5, 982, 506, 36, 2, 11, 123, 277, 254, 37, 105, 91, 2, 20, 128, 44, 109, 118, 4, 181, 9, 19, 10, 393, 12, 216, 2, 6, 59, 38, 1479, 657, 12533, 10037, 1005, 5457, 2, 359, 4044, 22, 4433, 2, 357, 258, 16, 3272, 3, 231, 272, 11, 123, 277, 2280, 2262, 5, 52, 81961, 53, 149, 356, 338, 43, 52, 733, 14, 53, 149, 356, 338, 901, 229, 4, 204, 2, 6, 59, 11, 123, 277, 2, 359, 6856, 273, 982, 20, 9403, 5, 262, 2, 357, 258, 16, 3272, 5, 52, 16848, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 3, 16, 733, 19, 5, 52, 808, 53, 149, 83, 378, 24285, 378, 200, 407, 982, 49, 763, 3, 16, 96, 5, 52, 16848, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 89, 763, 3, 16, 59, 19, 5, 52, 3882, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 3, 16, 2420, 5, 52, 16848, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 3, 16, 703, 13, 5, 52, 20023, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 3, 16, 1966, 5, 52, 16848, 53, 149, 83, 378, 24285, 378, 143, 407, 43, 52, 16848, 53, 149, 83, 378, 24285, 378, 200, 407, 982, 901, 58, 763, 3, 16, 337, 5, 52, 16848, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 3, 16, 310, 5, 52, 16848, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 58, 763, 4, 109, 426, 356, 338, 43, 982, 170, 56, 31, 1, 15, 4, 181, 9, 19, 10, 393, 12, 336, 2, 6, 59, 11, 1479, 657, 12533, 37, 105, 91, 2, 20, 128, 44, 109, 118, 4, 142, 2, 109, 426, 456, 2464, 16, 853, 5, 52, 20023, 53, 149, 83, 378, 24285, 378, 143, 407, 982, 14, 1, 2, 234, 174, 105, 462, 668, 428, 901, 16, 4, 29, 28, 64, 30, 6, 59, 5, 61, 202, 21, 51, 68, 78, 50, 7, 7, 5, 71, 2, 124, 47, 7, 7, 137, 114, 4, 6, 59, 11, 1427, 20, 1100, 70, 1390, 124, 104, 7, 7, 330, 712, 1672, 2, 386, 51, 68, 78, 50, 7, 7, 7, 7, 5, 71, 2, 298, 762, 2, 124, 999, 183, 4, 6, 59, 276, 20, 128, 44, 155, 5, 360, 2, 386, 51, 68, 78, 50, 7, 7, 7, 7, 5, 71, 2, 358, 278, 183, 4])
(0, 'x_feature:', [0.23809523809523808, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.058823529411764705, 0.0, 0.05263157894736842, 0.045454545454545456, 0.0, 0.0, 0.07692307692307693, 0.058823529411764705, 0.0625, 0.0, 0.25, 0.2, 0.0, 0.08333333333333333, 0.125, 0.14285714285714285, 0.08333333333333333, 0.2, 0.0, 0.1, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u76d7\u7a83'])
(0, '#######transform_data_to_index.accusation_list(index):', [189])
(0, '#######transform_data_to_index.article_list(string):', [u'264'])
(0, '#######transform_data_to_index.article_list(index):', [57])
Dumping model to file cache /tmp/jieba.cache
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.621 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1482, 4552, 45, 18, 2, 57, 9, 75, 10, 38, 86, 817, 2, 6, 72, 7083, 108, 3690, 19548, 35105, 3313, 1249, 1714, 168, 1260, 23, 287, 24, 2, 11, 123, 168, 809, 2588, 2, 11, 3690, 19548, 35105, 3313, 1249, 1714, 168, 441, 1482, 2583, 1, 1798, 929, 5, 5555, 717, 2, 84, 8607, 3865, 1249, 1482, 36054, 1074, 5, 1, 25230, 3, 15470, 5, 52648, 2245, 814, 3, 3582, 5, 15767, 814, 2, 47, 20142, 38176, 5, 3187, 997, 6296, 10092, 1249, 4, 17, 9624, 32, 2, 72, 442, 41, 63, 13, 3, 1970, 3, 92, 3, 238, 3, 337, 12678, 10092, 979, 1249, 732, 698, 2, 698, 895, 592, 257, 2, 66, 828, 895, 27353, 15, 2, 224, 828, 895, 1, 15, 4, 1068, 81, 18, 5, 188, 2, 883, 261, 529, 27, 309, 21, 235, 34, 270, 2, 461, 64, 2, 6, 72, 5, 61, 66, 130, 7, 7, 2, 116, 2650, 460, 4, 29, 28, 210, 104, 6, 72, 572, 292, 812, 415, 7, 7, 2, 27, 335, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.07142857142857142, 0.0, 0.10526315789473684, 0.125, 0.0, 0.05263157894736842, 0.10526315789473684, 0.09090909090909091, 0.0, 0.09090909090909091, 0.15384615384615385, 0.058823529411764705, 0.0625, 0.0, 0.25, 0.0, 0.0, 0.16666666666666666, 0.0625, 0.21428571428571427, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u5438\u6536\u516c\u4f17\u5b58\u6b3e'])
(0, '#######transform_data_to_index.accusation_list(index):', [67])
(0, '#######transform_data_to_index.article_list(string):', [u'176'])
(0, '#######transform_data_to_index.article_list(index):', [104])
Dumping model to file cache /tmp/jieba.cache
Loading model cost 3.007 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1266, 5745, 45, 18, 30, 6, 653, 555, 73, 9, 75, 10, 233, 12, 242, 36, 321, 154, 342, 35, 392, 227, 47458, 1374, 174, 16602, 25090, 53460, 379, 85, 38, 47458, 1374, 349, 1417, 2, 774, 5745, 2657, 1331, 1328, 2349, 1416, 251, 249, 41, 788, 651, 121, 417, 2, 320, 651, 180, 158, 4, 17, 5745, 333, 162, 145, 32, 30, 2125, 939, 880, 9725, 320, 722, 2954, 141, 158, 2798, 17, 5745, 333, 924, 274, 140, 2, 646, 374, 829, 119, 366, 134, 4, 651, 374, 790, 134, 4, 29, 28, 64, 2, 6, 646, 485, 534, 751, 744, 2, 121, 113, 2, 724, 158, 2273, 2, 26, 61, 66, 130, 7, 7, 2, 194, 115, 2089, 26, 114, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.0, 0.0, 0.05263157894736842, 0.0, 0.058823529411764705, 0.10526315789473684, 0.10526315789473684, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0625, 0.0, 0.16666666666666666, 0.0, 0.0, 0.08333333333333333, 0.375, 0.5, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u4ea4\u901a\u8087\u4e8b'])
(0, '#######transform_data_to_index.accusation_list(index):', [13])
(0, '#######transform_data_to_index.article_list(string):', [u'133'])
(0, '#######transform_data_to_index.article_list(index):', [46])
Loading model cost 0.631 seconds.
Prefix dict has been built succesfully.
(0, ('train', 'transform_data_to_index.####################.start.')
'#######transform_data_to_index.x:', [29, 28, 18, 2, 55, 9, 97, 10, ('train', 'i:', 0)
100, 12, 517, 75, 39, 2, 11, 10367, 13737, 10641, 13, 5982, 2, 6, 126, 14, 13, 1775, 1805, 11, 1411, 48697, 1584, 16, 92, 49, 23, 97, 988, Building prefix dict from the default dictionary ...
2, 8653, 2112, 59, 14, 5, 9901, 24, 62, 683, 46, 23, 97, 988, 24, 11, 566, 1934, 505, 42104, 144, 4482, 2, 7502, 59, 14, 1674, 2037, 2, 438, 835, Loading model from cache /tmp/jieba.cache
29716, 92, 49, 4, 126, 14, 12076, 92, 49, 65780, 30, 52, 2585, 2242, 13996, 53, 1056, 92, 49, 397, 20212, 2, 126, 14, 13, 285, 1052, 1645, 3453, 2144, 92, 49, 6792, 2030, 1349, 6655, 2, 320, 92, 49, 158, 4, 455, 2, 126, 14, 13, 292, 1052, 6541, 59, 14, 519, 2, 2144, 4194, 11, 980, 2291, 5, 59, 14, 2030, 1349, 6655, 2, 320, 59, 14, 1337, 3, 5938, 22, 1279, 211, 4, 17, 32, 2, 92, 49, 4773, 3327, 2174, 13263, 2069, 730, 3824, 6497, 943, 1612, 3651, 7939, 445, 158, 40, 59, 14, 5, 141, 217, 25, 193, 294, 40, 126, 14, 13, 633, 51418, 2011, 67342, 7788, 2283, 2, 457, 3174, 23, 521, 24, 114, 1280, 4, 29, 28, 25, 81, 18, 5, 1802, 2, 150, 21, 448, 5, 34, 4, 29, 28, 64, 6, 126, 14, 13, 5, 61, 271, 51, 68, 78, 50, 7, 7, 5, 71, 2, 327, 47, 7, 7, 548, 114, 4])
(0, 'x_feature:', [0.09523809523809523, 0.125, 0.0, 0.08333333333333333, 0.0, 0.125, 0.0, 0.05263157894736842, 0.10526315789473684, 0.0, 0.08333333333333333, 0.0, 0.0, 0.058823529411764705, 0.0625, 0.0, 0.16666666666666666, 0.0, 0.09090909090909091, 0.08333333333333333, 0.125, 0.14285714285714285, 0.08333333333333333, 0.0, 0.0, 0.2, 0.09090909090909091, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u6545\u610f\u6740\u4eba'])
(0, '#######transform_data_to_index.acLoading model cost 3.114 seconds.
cPrefix dict has been built succesfully.
usation_list(index):', [187])
(0, '#######transform_data_to_index.article_list(string):', [u'232'])
(0, '#######transform(0, '#######transform_data_to_index.x:', [29, 28, 18, 2, 55, 9, 100, 10, 239, 750, 73, 9, 14, 10, 242, 12, 2, 6, 509, 284, 4863, 4957, 3, 147, 3181, 3, 642, 62944, 23, 234, 11, 870, 24, 22, 82, 11, 18407, 3291, 44123, 1, 1, 75, 48, 811, 249, 2, 390, 3699, 47, 7124, 52, 7965, 53, 5, 1835, 187, 2999, 2, 1014, 1881, 2791, 2, 1688, 5010, 1127, 143, 82, 4, 29, 28, 1085, 173, 3, 67, 69, 3, 6, 44, 41, 214, 22, 34, 2, 64, 6, 509, 47, 2216, 25, 433, 2, 1025, 2999, 2, 26, 61, 202, 21, 51, 68, 78, 50, 7, 7, 7, 7, 110, 71, 2, 130, 7, 7, 2, 124, 47, 7, 7, 137, 114, 2, 600, 116, 104, 4])
_data_to_(0, 'x_feature:', [0.047619047619047616, 0.0, 0.07142857142857142, 0.0, 0.0, 0.1875, 0.0, 0.05263157894736842, 0.05263157894736842, 0.045454545454545456, 0.0, 0.09090909090909091, 0.07692307692307693, 0.17647058823529413, 0.0, 0.0, 0.16666666666666666, 0.0, 0.09090909090909091, 0.16666666666666666, 0.0, 0.0, 0.08333333333333333, 0.2, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u8d4c\u535a'])
(0, '#######transform_data_to_index.accusation_list(index):', [74])
ind(0, '#######transform_data_to_index.article_list(string):', [u'303'])
(0, '#######transform_data_to_index.article_list(index):', [74])
ex.article_list(index):', [156])
Dumping model to file cache /tmp/jieba.cache
Loading model cost 2.925 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1266, 10206, 6074, 45, 18, 30, 73, 9, 46, 10, 1560, 2, 6, 138, 8, 602, 843, 2, 2180, 268, 641, 36685, 1979, 1, 54267, 2528, 9961, 329, 6167, 3644, 242, 3439, 70, 2, 317, 951, 5660, 14, 2856, 2, 1, 36685, 1979, 1500, 4096, 4316, 249, 135, 30, 5660, 25, 7486, 11631, 5161, 51659, 2590, 4, 27, 64, 2, 6, 138, 8, 485, 512, 44260, 744, 2, 2180, 93, 3653, 15246, 317, 951, 512, 4123, 2813, 2, 26, 61, 202, 21, 51, 68, 78, 50, 7, 7, 110, 71, 2, 118, 312, 2, 34, 302, 297, 2, 124, 47, 317, 951, 512, 4123, 2813, 450, 137, 114, 4])
(0, 'x_feature:', [0.0, 0.75, 0.07142857142857142, 0.0, 0.05263157894736842, 0.0625, 0.0, 0.05263157894736842, 0.05263157894736842, 0.045454545454545456, 0.0, 0.0, 0.15384615384615385, 0.058823529411764705, 0.0, 0.3333333333333333, 0.16666666666666666, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.09090909090909091, 0.1, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u91c7\u4f10\u3001\u6bc1\u574f\u56fd\u5bb6\u91cd\u70b9\u4fdd\u62a4\u690d\u7269'])
(0, '#######transform_data_to_index.accusation_list(index):', [138])
(0, '#######transform_data_to_index.article_list(string):', [u'344'])
(0, '#######transform_data_to_index.article_list(index):', [120])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 3.009 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [5797, 7578, 45, 18, 2, 98, 9, 2223, 2, 890, 8, 23, 287, 24, 1031, 1924, 7578, 17669, 580, 23279, 3230, 203, 23, 287, 24, 2, 3323, 11, 138, 13, 5, 741, 273, 1506, 3393, 93, 7578, 17669, 580, 23279, 5, 3542, 2, 27, 568, 4331, 1506, 1192, 580, 44226, 74, 138, 13, 8289, 4, 11, 10320, 42, 62745, 5457, 580, 991, 3, 9762, 814, 5740, 3555, 695, 2, 11, 138, 13, 5, 1140, 273, 2, 890, 8, 941, 902, 4411, 2570, 168, 43, 31761, 76, 3053, 5, 168, 187, 61149, 2, 4633, 890, 8, 47, 4840, 3499, 15237, 1, 8145, 580, 207, 1572, 1366, 5, 768, 3393, 93, 123, 814, 580, 4, 204, 2, 203, 652, 1071, 580, 9765, 5, 5921, 789, 16959, 328, 1786, 2, 890, 8, 3695, 2, 27, 652, 129, 4674, 4361, 6, 92, 5, 1786, 890, 8, 237, 6024, 2, 174, 138, 13, 1140, 4, 432, 89, 10, 2, 11, 138, 13, 3, 92, 5, 741, 273, 2, 890, 8, 292, 3393, 75788, 23279, 84126, 696, 15282, 3, 5171, 1876, 5272, 2226, 814, 580, 4, 98, 9, 80, 10, 201, 12, 2, 7578, 17669, 580, 23279, 84, 3499, 15237, 1, 8145, 580, 207, 1572, 1366, 3168, 10320, 42, 62745, 5457, 580, 991, 3, 9762, 5, 19216, 521, 3, 46170, 521, 580, 698, 9145, 9629, 5, 35328, 2970, 264, 4, 1354, 8311, 2, 203, 1435, 890, 8, 718, 5, 2454, 264, 4111, 2, 203, 33, 497, 89, 264, 4749, 92, 4, 98, 9, 86, 10, 58, 12, 2, 7578, 17669, 580, 23279, 84, 3499, 15237, 1, 8145, 580, 207, 1572, 1366, 3168, 84126, 696, 15282, 3, 5171, 1876, 5272, 2226, 3542, 2046, 3818, 15, 4, 695, 4173, 2, 203, 1435, 890, 8, 718, 5, 75, 264, 2589, 2, 203, 33, 497, 49, 264, 129, 92, 4, 142, 2, 6, 92, 84, 5797, 7578, 7281, 1356, 874, 281, 2, 27, 33, 351, 250, 264, 31, 208, 2842, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.07142857142857142, 0.0, 0.05263157894736842, 0.0, 0.0, 0.0, 0.0, 0.13636363636363635, 0.0, 0.0, 0.07692307692307693, 0.11764705882352941, 0.0625, 0.0, 0.08333333333333333, 0.0, 0.0, 0.4166666666666667, 0.0, 0.07142857142857142, 0.16666666666666666, 0.0, 0.0, 0.1, 0.0, 0.36363636363636365])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u53d7\u8d3f'])
(0, '#######transform_data_to_index.accusation_list(index):', [87])
(0, '#######transform_data_to_index.article_list(string):', [u'385', u'383', u'386'])
(0, '#######transform_data_to_index.article_list(index):', [88, 111, 130])
Loading model cost 0.905 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [8496, 45, 18, 2, 6, 863, 8, 553, 246, 394, 5, 82, 2, 15533, 26, 150, 34947, 169, 2, 741, 2751, 2, 26, 61, 124, 47, 15020, 548, 114, 4, 6, 863, 8, 186, 20, 2, 128, 44, 155, 5, 360, 2, 358, 278, 183, 4])
(0, 'x_feature:', [0.19047619047619047, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05263157894736842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.1, 0.09090909090909091, 0.08333333333333333, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u7a9d\u85cf\u3001\u5305\u5e87'])
(0, '#######transform_data_to_index.accusation_list(index):', [36])
(0, '#######transform_data_to_index.article_list(string):', [u'310'])
(0, '#######transform_data_to_index.article_list(index):', [49])
Loading model cost 0.591 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 2, 164, 2179, 90, 41, 6, 96, 5694, 6751, 755, 3502, 2, 115, 108, 55, 9, 100, 10, 233, 12, 1172, 23, 55, 24, 2975, 3756, 640, 316, 22943, 48, 6844, 253, 2, 3872, 3, 6183, 21, 63, 13, 164, 8638, 957, 23, 57, 24, 28609, 3756, 640, 316, 42236, 48, 3, 68918, 48, 2651, 6807, 15587, 13, 20025, 5, 371, 257, 11181, 23, 123, 550, 42, 8638, 957, 3872, 642, 6712, 2472, 2725, 24, 2, 108, 55, 9, 100, 10, 247, 2090, 8638, 957, 7147, 20058, 678, 2, 2298, 73, 9, 14, 10, 14, 2090, 63, 13, 116, 3005, 21, 123, 6844, 253, 4, 73, 9, 46, 10, 239, 12, 2, 115, 285, 90, 41, 63, 13, 5694, 6751, 755, 3502, 1172, 23, 55, 24, 2975, 3756, 640, 316, 22943, 48, 6807, 96, 11, 598, 2651, 10457, 5076, 70, 1291, 90, 732, 371, 257, 947, 43, 997, 4, 598, 2651, 20, 2, 96, 224, 1071, 598, 12239, 204, 16957, 2, 90, 84, 957, 1077, 5692, 2, 115, 116, 108, 73, 9, 83, 10, 179, 2090, 63, 13, 3005, 680, 678, 3, 1561, 1634, 5855, 22, 1283, 2, 726, 63, 13, 11, 224, 84, 957, 2192, 1077, 2330, 3005, 4983, 2, 166, 3005, 4983, 10082, 144, 4523, 679, 11, 364, 5, 175, 273, 2, 17, 4432, 1514, 1247, 785, 5, 3005, 4983, 43, 4523, 3005, 2, 941, 4765, 96, 1386, 2, 103, 440, 13893, 2, 691, 115, 680, 678, 3, 283, 1561, 5855, 37, 14204, 3679, 4, 204, 2, 6, 96, 11, 1435, 23, 55, 24, 2975, 3756, 640, 316, 22943, 48, 6844, 30313, 2, 553, 51999, 957, 33, 26, 11, 8638, 957, 5, 680, 550, 42, 74, 11362, 642, 6712, 20025, 5, 11181, 3872, 3, 6183, 5, 175, 273, 2, 19482, 73, 9, 14, 10, 49, 12, 12430, 41, 642, 6712, 711, 2, 33, 26, 371, 257, 11181, 15256, 6712, 1291, 96, 592, 4416, 27, 191, 431, 2, 584, 96, 3344, 15587, 6712, 5, 680, 1077, 2, 27, 1077, 8638, 957, 5834, 15587, 6712, 2472, 5, 3872, 2, 8638, 957, 1085, 96, 5, 1077, 2, 1172, 23, 55, 24, 28609, 8348, 316, 1, 378, 14, 48, 43, 23, 55, 24, 28609, 8348, 316, 1, 378, 14, 48, 680, 3741, 2, 123, 680, 550, 680, 5582, 4, 96, 3720, 33, 711, 758, 1312, 1291, 90, 2, 5020, 1291, 21, 960, 15441, 72, 2, 694, 224, 33, 680, 550, 711, 175, 972, 115, 4, 2179, 90, 108, 73, 9, 83, 10, 200, 2090, 105, 597, 2, 439, 548, 6, 96, 4974, 957, 598, 3, 4594, 450, 5, 114, 2, 105, 1866, 4846, 270, 2, 90, 108, 73, 9, 80, 10, 14, 2090, 115, 2070, 18164, 4, 109, 118, 76, 1131, 17, 261, 468, 5, 34, 191, 81, 30, 23, 57, 24, 28609, 3756, 640, 316, 42236, 48, 395, 3, 23, 57, 24, 28609, 3756, 640, 316, 68918, 48, 395, 81, 642, 1, 6, 96, 5, 30763, 2, 96, 15587, 6712, 5, 11181, 522, 3106, 1664, 40, 23, 55, 24, 2975, 3756, 640, 316, 22943, 48, 6844, 253, 3, 20058, 678, 3005, 7619, 2, 81, 115, 108, 55, 9, 100, 10, 233, 12, 3872, 3, 6183, 96, 15587, 6712, 5, 371, 257, 11181, 2, 27, 33, 123, 6844, 1, 73, 9, 14, 10, 14, 2090, 63, 13, 3005, 2, 108, 55, 9, 100, 10, 247, 2090, 8638, 957, 3005, 123, 6844, 2673, 20058, 678, 40, 2851, 5445, 3, 23, 55, 24, 28609, 8348, 316, 1, 378, 14, 48, 680, 3741, 3, 23, 55, 24, 28609, 8348, 316, 1, 378, 14, 48, 680, 3741, 2, 81, 96, 11, 1435, 115, 5, 6844, 30313, 2, 553, 1, 6712, 5, 11181, 66, 37, 3872, 3, 6183, 5, 175, 273, 878, 41, 642, 6712, 419, 711, 289, 2, 4452, 15587, 6712, 5, 5692, 1077, 2, 27, 439, 8638, 957, 5834, 15587, 6712, 2472, 5, 3872, 2, 4394, 198, 115, 6807, 787, 680, 5, 2273, 40, 115, 1111, 3005, 4983, 10082, 43, 2384, 4966, 2, 81, 96, 11, 397, 1077, 2330, 9030, 3, 166, 1328, 8733, 679, 11, 364, 5, 175, 273, 2, 17, 4432, 1514, 1247, 785, 5, 3005, 4983, 43, 4523, 3005, 2, 941, 4765, 96, 1386, 2, 103, 440, 13893, 2, 691, 115, 680, 678, 3, 283, 1561, 5855, 37, 14204, 3679, 40, 5445, 570, 60, 81, 2, 90, 44414, 105, 597, 439, 548, 96, 5, 114, 2, 105, 1866, 4846, 270, 2, 20, (90', t84, 957, 2070, 18164, 2, 439, 548, 96, 4974, 598, 3, 4594, 5, 114, 4, 109, 34, 1471, 66, 2460, 8646, 5, 34, 17074, 2, 3933, 81, 63, 3009, 4974, 957, 598, 3, 4594, 450, 5, 118, 4])rain', 'transform_data_to_index.####################.start.')

(0, 'x_feature:', [0.047619047619047616, 0.0, 0.0, 0.08333333333333333, ('train', 'i:', 0)
0.05263157894736842, 0.25, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.0, 0.07692307692307693, 0.11764705882352941, 0.0, 0.0, 0.4166666666666667, 0.1, 0.0, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091])
(0, '#######traBuilding prefix dict from the default dictionary ...
nsform_data_to_index.accusation_list(string):', [u'\u62d2\u4e0d\u6267\u884c\u5224\u51b3\u3001\u88c1\u5b9a'])
(0, '#####Loading model from cache /tmp/jieba.cache
##transform_data_to_index.accusation_list(index):', [172])
(0, '#######transform_data_to_index.article_list(string):', [u'313'])
(0, '#######transform_data_to_index.article_list(index):', [17])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model cost 0.715 seconds.
Prefix dict has been built succesfully.
(Loading model from cache /tmp/jieba.cache
0, '#######transform_data_to_index.x:', [17, 106, 99, 2, 57, 9, 58, 10, 403, 12, 336, 2, 6, 583, 43, 63, 13, 23, 287, 24, 11, 9710, 35577, 1797, 1, 277, 279, 26, 9524, 5, 1647, 3034, 37, 7026, 20, 2, 47, 136, 24164, 25, 174, 2, 84, 533, 1109, 1244, 2205, 2, 27, 3545, 533, 1, 237, 6574, 285, 33, 26, 4139, 206, 483, 2, 84, 533, 1, 467, 31, 58, 2, 492, 15, 4, 142, 2, 6, 583, 84, 533, 1109, 1092, 351, 31, 58, 2, 492, 15, 2, 27, 266, 157, 4, 94, 2, 6, 583, 11, 161, 101, 42, 167, 131, 2, 166, 76, 16, 906, 430, 5, 597, 270, 43, 133, 40, 67, 533, 146, 3, 906, 95, 3, 96, 5, 69, 40, 105, 5, 91, 107, 3, 177, 60, 102, 3, 2747, 60, 40, 692, 43, 157, 253, 40, 6, 583, 5, 44, 22, 34, 81, 2, 132, 4])
(0, 'x_feature:', [0.09523809523809523, 0.0, 0.0, 0.0, 0.0, 0.3125, 0.0, 0.0, 0.05263157894736842, 0.045454545454545456, 0.0, 0.0, 0.07692307692307693, 0.058823529411764705, 0.0625, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u6572\u8bc8\u52d2\u7d22'])
(0, '#######transform_data_to_index.accusation_list(index):', [200])
(0, '#######transform_data_to_index.article_list(string):', [u'274'])
(0, '#######transform_data_to_index.article_list(index):', [39])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 1.293 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 342, 73, 9, 83, 10, 46, 12, 216, 49, 39, 2, 6, 59, 11, 9660, 329, 5021, 212, 14195, 491, 13, 591, 254, 33, 16, 337, 272, 11, 530, 5, 402, 3681, 288, 122, 23, 3934, 2315, 7, 7, 7, 7, 7, 7, 80, 2, 3368, 48, 983, 7, 7, 7, 7, 58, 24, 165, 4, 20, 59, 33, 123, 710, 122, 16940, 515, 9660, 329, 7, 7, 212, 7, 7, 2757, 277, 7, 7, 20564, 21164, 1, 899, 2, 164, 1704, 4078, 445, 33, 486, 1841, 11, 530, 4, 17, 9660, 329, 112, 315, 145, 112, 315, 2, 185, 122, 56, 74800, 15, 4])
(0, 'x_feature:', [0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.0, 0.05263157894736842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.058823529411764705, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0625, 0.07142857142857142, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u76d7\u7a83'])
(0, '#######transform_data_to_index.accusation_list(index):', [189])
(0, '#######transform_data_to_index.article_list(string):', [u'264'])
(0, '#######transform_data_to_index.article_list(index):', [57])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.966 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [3310, 45, 18, 30, 98, 9, 75, 10, 388, 373, 2, 6, 72, 54, 35, 565, 1153, 7, 7, 7, 7, 7, 48, 1158, 12827, 392, 120, 3310, 19591, 153, 1637, 3310, 6828, 379, 4, 1069, 248, 36, 143, 154, 2, 716, 3310, 45791, 491, 14406, 926, 23014, 774, 6828, 1, 244, 437, 2, 45991, 13, 6767, 266, 192, 368, 35, 5, 296, 476, 2302, 288, 122, 23, 4951, 986, 90, 3, 1165, 54, 24, 1515, 2170, 38, 437, 3455, 8272, 213, 7392, 36, 2, 6, 72, 54, 562, 2805, 3205, 1606, 2, 320, 182, 121, 9727, 2, 182, 2415, 417, 123, 296, 476, 2302, 288, 122, 2, 198, 90, 3, 1165, 54, 211, 2, 497, 90, 516, 108, 405, 158, 5, 163, 113, 4, 142, 2, 6, 72, 54, 11, 626, 84, 111, 281, 4, 17, 3310, 1155, 140, 2, 6, 79, 4408, 119, 5, 366, 134, 4, 142, 2, 525, 551, 521, 66, 503, 4])
(0, 'x_feature:', [0.09523809523809523, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.058823529411764705, 0.0, 0.05263157894736842, 0.0, 0.08333333333333333, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.16666666666666666, 0.1, 0.0, 0.08333333333333333, 0.375, 0.35714285714285715, 0.0, 0.2, 0.0, 0.2, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u4ea4\u901a\u8087\u4e8b'])
(0, '#######transform_data_to_index.accusation_list(index):', [13])
(0, '#######transform_data_to_index.article_list(string):', [u'133'])
(0, '#######transform_data_to_index.article_list(index):', [46])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 1.156 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 30, 220, 9, 75, 304, 1689, 216, 49, 39, 2, 6, 63, 8, 218, 1597, 268, 16, 79, 8, 226, 2, 37, 79, 8, 1397, 79, 14, 13, 279, 2, 79, 14, 13, 1016, 7888, 79, 46, 13, 33, 6, 63, 8, 2463, 2, 6, 63, 8, 5, 3521, 96, 43, 63, 8, 136, 79, 46, 13, 4453, 15, 4, 98, 9, 97, 10, 201, 12, 216, 46, 39, 2, 6, 63, 8, 218, 708, 1597, 268, 79, 8, 226, 2, 37, 79, 8, 279, 2, 675, 29047, 1821, 14801, 8, 2, 6, 63, 8, 1059, 4, 16, 79, 8, 455, 93, 19909, 334, 597, 4, 94, 2, 6, 63, 8, 11, 161, 101, 42, 167, 131, 2, 166, 76, 1104, 3571, 8, 5, 133, 2, 67, 72, 54, 3, 63, 146, 3, 72, 95, 3, 96, 430, 69, 2, 6, 63, 8, 159, 87, 1733, 81, 2, 166, 994, 261, 468, 2, 2243, 2, 34, 302, 3, 297, 2, 132, 4])
(0, 'x_feature:', [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.07692307692307693, 0.058823529411764705, 0.0, 0.0, 0.08333333333333333, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u4fb5\u5165\u4f4f\u5b85'])
(0, '#######transform_data_to_index.accusation_list(index):', [191])
(0, '#######transform_data_to_index.article_list(string):', [u'245'])
(0, '#######transform_data_to_index.article_list(index):', [155])
('####################freq_accusation:', 1589, 'freq_article:', 1597, ';num_copy:', 3)
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.978 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 2, 55, 9, 46, 10, 1070, 2, 6, 4283, 8, 3, 238, 3796, 20, 11, 14056, 16360, 153, 482, 618, 783, 1088, 9067, 47, 52, 21291, 3410, 53, 262, 617, 5, 1937, 4, 55, 9, 58, 10, 14, 12, 239, 39, 2, 1911, 1632, 111, 11, 482, 618, 783, 70, 125, 123, 617, 1937, 2, 27, 180, 156, 617, 637, 43, 1870, 560, 2, 5292, 15, 4, 454, 6, 5, 61, 130, 7, 7, 4])
(0, 'x_feature:', [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.05263157894736842, 0.045454545454545456, 0.08333333333333333, 0.0, 0.0, 0.17647058823529413, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u5f00\u8bbe\u8d4c\u573a'])
(0, '#######transform_data_to_index.accusation_list(index):', [6])
(0, '#######transform_data_to_index.article_list(string):', [u'303'])
(0, '#######transform_data_to_index.article_list(index):', [74])
Loading model cost 0.967 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 30, 73, 9, 86, 10, 80, 12, 2, 4916, 77, 17, 413, 279, 2229, 33, 11, 219, 2287, 1074, 3845, 519, 648, 187, 117, 421, 2, 1215, 187, 12083, 4, 405, 242, 39, 2, 4280, 11, 219, 11925, 2287, 1074, 3845, 519, 648, 7836, 554, 91, 6, 96, 3, 223, 23, 287, 24, 17, 116, 746, 62, 1106, 2, 120, 6, 96, 1115, 70, 2532, 1087, 9106, 311, 1522, 7167, 402, 1522, 1577, 5, 311, 725, 4, 382, 492, 151, 40, 1087, 9106, 402, 1522, 7167, 2231, 11017, 1577, 5, 311, 725, 2, 382, 301, 151, 4, 17, 32, 2, 109, 725, 234, 303, 190, 363, 2, 497, 2, 9106, 311, 1522, 7167, 402, 1522, 1577, 5, 311, 725, 2, 190, 139, 25, 30690, 4, 29, 28, 285, 18, 6, 96, 5, 118, 261, 529, 27, 309, 21, 6, 96, 5, 44, 41, 214, 3, 67, 69, 3, 186, 107, 3, 746, 60, 3, 32, 197, 3, 156, 199, 189, 3, 173, 3, 252, 3, 1239, 22, 34, 270, 4, 29, 28, 64, 2, 6, 96, 317, 798, 117, 190, 670, 151, 2, 118, 312, 2, 34, 302, 3, 297, 2, 124, 47, 7, 7, 548, 6, 96, 114, 2, 194, 115, 116, 104, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.07142857142857142, 0.0, 0.05263157894736842, 0.1875, 0.0, 0.2631578947368421, 0.15789473684210525, 0.09090909090909091, 0.0, 0.0, 0.15384615384615385, 0.23529411764705882, 0.0625, 0.06666666666666667, 0.25, 0.0, 0.0, 0.08333333333333333, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u6301\u6709\u6bd2\u54c1'])
(0, '#######transform_data_to_index.accusation_list(index):', [9])
(0, '#######transform_data_to_index.article_list(string):', [348])
(0, '#######transform_data_to_index.article_list(index):', [65])
('####################freq_accusation:', 362, 'freq_article:', 788, ';num_copy:', 3)
('####################freq_accusation:', 373122, 'freq_article:', 153, ';num_copy:', 3)
('####################freq_accusation:', 325, 'freq_article:', 326, ';num_copy:', 6)
('####################freq_accusation:', 340, 'freq_article:', 976, ';num_copy:', 3)
('####################freq_accusation:', 781, 'freq_article:', 749, ';num_copy:', 3)
('####################freq_accusation:', 919, 'freq_article:', 985, ';num_copy:', 3)
('####################freq_accusation:', 2488, 'freq_article:', 76, ';num_copy:', 3)
('####################freq_accusation:', 372, 'freq_article:', 788, ';num_copy:', 3)
('####################freq_accusation:', 365, 'freq_article:', 426, ';num_copy:', 5)
('####################freq_accusation:', 460, 'freq_article:', 462, ';num_copy:', 4)
('####################freq_accusation:', 119, 'freq_article:', 335, ';num_copy:', 8)
('####################freq_accusation:', 1899, 'freq_article:', 2434, ';num_copy:', 3)
('####################freq_accusation:', 445, 'freq_article:', 438, ';num_copy:', 4)
('train', 'i:', 10000)
('train', 'i:', 10000)
('####################freq_accusation:', 1325, 'freq_article:', 8091, ';num_copy:', 3)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('####################freq_accusation:', 532, 'freq_article:', 2499, ';num_copy:', 3)
(('train'train', 'i', 'i::', 10000)
', 10000)
('####################freq_accusation:', 721, 'freq_article:', 726, ';num_copy:', 3)
('train', 'i:', 10000)
('####################freq_accusation:', 255, 'freq_article:', 1489, ';num_copy:', 3)
('####################freq_accusation:', 204, 'freq_article:', 363, ';num_copy:', 7)
('####################freq_accusation:', 159, 'freq_article:', 166, ';num_copy:', 10)
('####################freq_accusation:', 32, 'freq_article:', 189, ';num_copy:', 10)
('####################freq_accusation:', 427, 'freq_article:', 5514, ';num_copy:', 3)
('####################freq_accusation:', 5123, 'freq_article:', 444, ';num_copy:', 3)
('####################freq_accusation:', 550, 'freq_article:', 6520, ';num_copy:', 3)
('####################freq_accusation:', 1254, 'freq_article:', 1322, ';num_copy:', 3)
('####################freq_accusation:', 140, 'freq_article:', 142, ';num_copy:', 10)
('####################freq_accusation:', 1470, 'freq_article:', 1098, ';num_copy:', 3)
('####################freq_accusation:', 188, 'freq_article:', 192, ';num_copy:', 10)
('####################freq_accusation:', 1899, 'freq_article:', 2434, ';num_copy:', 3)
('####################freq_accusation:', 1589, 'freq_article:', 1597, ';num_copy:', 3)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('####################freq_accusation:', 919, 'freq_article:', 985, ';num_copy:', 3)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('####################freq_accusation:', 140, 'freq_article:', 142, ';num_copy:', 10)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('####################freq_accusation:', 760, 'freq_article:', 5329, ';num_copy:', 3)
('####################freq_accusation:', 1359, 'freq_article:', 1348, ';num_copy:', 3)
('####################freq_accusation:', 1359, 'freq_article:', 1348, ';num_copy:', 3)
('####################freq_accusation:', 851, 'freq_article:', 849, ';num_copy:', 3)
('####################freq_accusation:', 445, 'freq_article:', 438, ';num_copy:', 4)
('####################freq_accusation:', 530, 'freq_article:', 470, ';num_copy:', 4)
('####################freq_accusation:', 151, 'freq_article:', 189, ';num_copy:', 10)
('####################freq_accusation:', 1140, 'freq_article:', 1146, ';num_copy:', 3)
('####################freq_accusation:', 1037, 'freq_article:', 1819, ';num_copy:', 3)
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_3.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_1.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_0.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_2.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_4.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_7.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_6.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_8.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_11.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_12.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_13.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_10.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_5.pik')
('####################freq_accusation:', 1589, 'freq_article:', 1597, ';num_copy:', 3)
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_16.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_9.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_14.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_18.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_17.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_15.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_19.pik')
finish reduce stage...
('valid', 'transform_data_to_index.####################.start.')
('valid', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.256 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 2, 220, 9, 46, 10, 2, 6, 79, 19, 793, 26, 900, 1024, 8, 5, 768, 1249, 657, 27264, 1344, 23, 5508, 24, 207, 23, 343, 1117, 657, 27264, 168, 24, 2, 798, 657, 27264, 168, 8502, 5, 984, 4, 432, 100, 10, 2, 657, 27264, 168, 164, 423, 11113, 15439, 84, 79, 19, 13, 652, 732, 2, 79, 19, 13, 372, 390, 809, 1, 7029, 1281, 76229, 1434, 3, 6116, 619, 413, 5, 567, 735, 2, 33, 665, 5, 714, 31, 301, 257, 3678, 657, 27264, 168, 502, 423, 1110, 4, 57, 9, 83, 10, 388, 12, 62, 393, 12, 2, 657, 27264, 168, 370, 915, 84, 76229, 643, 21, 301, 257, 732, 4, 98, 9, 14, 1269, 2, 6, 79, 19, 6178, 82, 1494, 33, 76229, 5, 349, 257, 714, 810, 3678, 63, 8, 937, 364, 4, 63, 8, 38, 913, 224, 643, 4, 57, 9, 83, 10, 242, 12, 2, 6, 79, 19, 1091, 1020, 12077, 45, 15304, 313, 719, 20, 874, 281, 2, 128, 44, 21, 94, 4])
(0, 'x_feature:', [0.14285714285714285, 0.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.0, 0.0, 0.0, 0.045454545454545456, 0.0, 0.2727272727272727, 0.07692307692307693, 0.11764705882352941, 0.0625, 0.0, 0.25, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.09090909090909091])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u632a\u7528\u516c\u6b3e'])
(0, '#######transform_data_to_index.accusation_list(index):', [135])
(0, '#######transform_data_to_index.article_list(string):', [384])
(0, '#######transform_data_to_index.article_list(index):', [179])
('valid', 'i:', 10000)
('valid', '#########################finished.transform_data_to_index')
('test', 'transform_data_to_index.####################.start.')
('test', 'i:', 0)
(0, '#######transform_data_to_index.x:', [17, 106, 99, 30, 98, 9, 49, 10, 2238, 2, 6, 79, 8, 11, 10953, 13, 1738, 155, 686, 70, 2, 390, 6336, 663, 318, 74, 2862, 88, 8, 23, 1484, 2, 2677, 9, 75, 10, 248, 12, 2145, 2, 2862, 24, 3, 63, 8, 23, 1484, 2, 2133, 9, 19, 10, 143, 12, 2145, 2, 2862, 24, 562, 12768, 1220, 3, 26295, 22, 434, 2, 187, 7831, 4, 94, 2, 6, 79, 8, 11, 161, 101, 42, 167, 131, 2, 166, 76, 107, 322, 468, 3, 315, 5, 1131, 34, 87, 30, 14, 367, 1973, 222, 3, 424, 222, 3, 545, 236, 3, 495, 107, 3, 6, 43, 16, 159, 87, 22, 40, 19, 367, 16, 88, 8, 3, 96, 5, 133, 40, 46, 367, 67, 59, 5, 69, 40, 58, 367, 65, 4402, 1635, 43, 102, 40, 49, 367, 6, 79, 8, 5, 44, 22, 34, 81, 2, 132, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07692307692307693, 0.058823529411764705, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u7325\u4eb5\u513f\u7ae5'])
(0, '#######transform_data_to_index.accusation_list(index):', [134])
(0, '#######transform_data_to_index.article_list(string):', [237])
(0, '#######transform_data_to_index.article_list(index):', [69])
('test', 'i:', 10000)
('test', 'i:', 20000)
('test', 'i:', 30000)
('test', '#########################finished.transform_data_to_index')
going to dump train/valid/test data to file sytem!
('length of training data:', 699696, ';valid data:', 13094, ';test data:', 32508, ';feature_length:', 28)
('trainX_[0]:', array([    0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
          29,    28,    18,     2,    98,     9,    58,  5770,    38,
          98,     9,    80,    10,   247,    12,   204,     2,     6,
        3114,     7,     7,    11,    26,   423,     5,  3648,  3648,
        1008,  3648,  3648,   153,  3648,  3648,  5417,    70,     2,
       17091,    52,   681, 13903,  3219, 13903,    53,  3993,   528,
           3,     1,  7168,  2079,   206,   617,     2,  1048,   670,
          15,   415,     4,    29,    28,    64,     2,     6,  3114,
           7,     7,     5,    61,    66,   130,     7,     7,     2,
         327,  2089,    26,   114,     4]))
('train_feature_X[0]:', array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        ,  0.05263158,  0.04545455,
        0.        ,  0.        ,  0.        ,  0.05882353,  0.        ,
        0.        ,  0.08333333,  0.        ,  0.        ,  0.08333333,
        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        ]))
('train_Y_accusation_short:', [6], [191], [124], [87], [87], ';train_Y_article_short:', [74])
('train_Y_deathpenalty:', array([ 1.,  0.]), ';train_Y_lifeimprisonment:', array([ 1.,  0.]), ';train_Y_imprisonment:', 12.0)
2018-07-14 18:09:10.572919: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:09:10.572962: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:09:10.572975: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:09:10.572984: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:09:10.572994: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:09:35.022865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-07-14 18:09:35.023840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:00:08.0
Total memory: 15.89GiB
Free memory: 15.60GiB
2018-07-14 18:09:35.023877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-07-14 18:09:35.023887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-07-14 18:09:35.023897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:08.0)
('self.filter_sizes:', [2, 3, 4, 5], ';self.num_filters:', 256, '; self.stride_length:', 1)
('self.single_sequence_length:', 31, ';self.total_sequence_length:', 500, ';self.num_sentences:', 16)
('model====>:', 'text_cnn')
going to use model:text cnn model
(0, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-2/cnn1/batchnorm/add_1:0' shape=(128, 499, 1, 256) dtype=float32>)
(0, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-2/cnn2/batchnorm/add_1:0' shape=(128, 498, 1, 256) dtype=float32>)
(0, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-2/Squeeze:0' shape=(128, 256) dtype=float32>)
(1, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-3/cnn1/batchnorm/add_1:0' shape=(128, 498, 1, 256) dtype=float32>)
(1, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-3/cnn2/batchnorm/add_1:0' shape=(128, 496, 1, 256) dtype=float32>)
(1, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-3/Squeeze:0' shape=(128, 256) dtype=float32>)
(2, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-4/cnn1/batchnorm/add_1:0' shape=(128, 497, 1, 256) dtype=float32>)
(2, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-4/cnn2/batchnorm/add_1:0' shape=(128, 494, 1, 256) dtype=float32>)
(2, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-4/Squeeze:0' shape=(128, 256) dtype=float32>)
(3, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-5/cnn1/batchnorm/add_1:0' shape=(128, 496, 1, 256) dtype=float32>)
(3, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-5/cnn2/batchnorm/add_1:0' shape=(128, 492, 1, 256) dtype=float32>)
(3, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-5/Squeeze:0' shape=(128, 256) dtype=float32>)
('h.concat:', <tf.Tensor 'concat:0' shape=(128, 1024) dtype=float32>)
Initializing Variables
('using pre-trained word emebedding.started.word2vec_model_path:', './data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5')
Traceback (most recent call last):
  File "train.py", line 288, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "train.py", line 100, in main
    assign_pretrained_word_embedding(sess, vocabulary_index2word, vocab_size, model,FLAGS.word2vec_model_path,model.Embedding)
  File "train.py", line 248, in assign_pretrained_word_embedding
    word2vec_model = KeyedVectors.load_word2vec_format(word2vec_model_path, binary=binary_flag,unicode_errors='ignore')
  File "/usr/local/lib/python2.7/dist-packages/gensim/models/keyedvectors.py", line 1436, in load_word2vec_format
    limit=limit, datatype=datatype)
  File "/usr/local/lib/python2.7/dist-packages/gensim/models/utils_any2vec.py", line 171, in _load_word2vec_format
    with utils.smart_open(fname) as fin:
  File "/usr/local/lib/python2.7/dist-packages/smart_open/smart_open_lib.py", line 181, in smart_open
    fobj = _shortcut_open(uri, mode, **kw)
  File "/usr/local/lib/python2.7/dist-packages/smart_open/smart_open_lib.py", line 287, in _shortcut_open
    return io.open(parsed_uri.uri_path, mode, **open_kwargs)
IOError: [Errno 2] No such file or directory: './data/sgns.target.word-word.dynwin5.thr10.neg5.dim300.iter5'
('model:', 'text_cnn')
('cache_path:', 'cache_text_cnn/vocab_label.pik', 'file_exists:', True)
going to load cache file.vocab of words and labels
('cnn_model.vocab_size:', 100002)
('accusation_num_classes:', 202)
('article_num_clasess:', 183)
('cache_path:', 'cache_text_cnn/train_valid_test.h5', 'train_valid_test_file_exists:', True)
going to load cache file from file system and return
('length of training data:', 699696, ';valid data:', 13094, ';test data:', 32508, ';feature_length:', 28)
('trainX_[0]:', array([    0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
          29,    28,    18,     2,    98,     9,    58,  5770,    38,
          98,     9,    80,    10,   247,    12,   204,     2,     6,
        3114,     7,     7,    11,    26,   423,     5,  3648,  3648,
        1008,  3648,  3648,   153,  3648,  3648,  5417,    70,     2,
       17091,    52,   681, 13903,  3219, 13903,    53,  3993,   528,
           3,     1,  7168,  2079,   206,   617,     2,  1048,   670,
          15,   415,     4,    29,    28,    64,     2,     6,  3114,
           7,     7,     5,    61,    66,   130,     7,     7,     2,
         327,  2089,    26,   114,     4]))
('train_feature_X[0]:', array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        ,  0.05263158,  0.04545455,
        0.        ,  0.        ,  0.        ,  0.05882353,  0.        ,
        0.        ,  0.08333333,  0.        ,  0.        ,  0.08333333,
        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.        ,  0.        ,  0.        ]))
('train_Y_accusation_short:', [6], [191], [124], [87], [87], ';train_Y_article_short:', [74])
('train_Y_deathpenalty:', array([ 1.,  0.]), ';train_Y_lifeimprisonment:', array([ 1.,  0.]), ';train_Y_imprisonment:', 12.0)
2018-07-14 18:14:21.339936: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:14:21.339978: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:14:21.339986: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:14:21.339991: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:14:21.339997: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:14:21.503540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-07-14 18:14:21.504412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:00:08.0
Total memory: 15.89GiB
Free memory: 15.60GiB
2018-07-14 18:14:21.504446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-07-14 18:14:21.504472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-07-14 18:14:21.504484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:08.0)
('self.filter_sizes:', [2, 3, 4, 5], ';self.num_filters:', 256, '; self.stride_length:', 1)
('self.single_sequence_length:', 31, ';self.total_sequence_length:', 500, ';self.num_sentences:', 16)
('model====>:', 'text_cnn')
going to use model:text cnn model
(0, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-2/cnn1/batchnorm/add_1:0' shape=(128, 499, 1, 256) dtype=float32>)
(0, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-2/cnn2/batchnorm/add_1:0' shape=(128, 498, 1, 256) dtype=float32>)
(0, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-2/Squeeze:0' shape=(128, 256) dtype=float32>)
(1, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-3/cnn1/batchnorm/add_1:0' shape=(128, 498, 1, 256) dtype=float32>)
(1, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-3/cnn2/batchnorm/add_1:0' shape=(128, 496, 1, 256) dtype=float32>)
(1, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-3/Squeeze:0' shape=(128, 256) dtype=float32>)
(2, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-4/cnn1/batchnorm/add_1:0' shape=(128, 497, 1, 256) dtype=float32>)
(2, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-4/cnn2/batchnorm/add_1:0' shape=(128, 494, 1, 256) dtype=float32>)
(2, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-4/Squeeze:0' shape=(128, 256) dtype=float32>)
(3, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-5/cnn1/batchnorm/add_1:0' shape=(128, 496, 1, 256) dtype=float32>)
(3, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-5/cnn2/batchnorm/add_1:0' shape=(128, 492, 1, 256) dtype=float32>)
(3, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-5/Squeeze:0' shape=(128, 256) dtype=float32>)
('h.concat:', <tf.Tensor 'concat:0' shape=(128, 1024) dtype=float32>)
Initializing Variables
('using pre-trained word emebedding.started.word2vec_model_path:', './data/sgns.merge.char')
('pretrained word embedding size:', '300')
('====>>>>word. exists embedding:', 72099, ' ;word not exist embedding:', 27901)
using pre-trained word emebedding.ended...
('trainX[start:end]:', array([[   0,    0,    0, ...,   26,  114,    4],
       [   0,    0,    0, ...,  999,  183,    4],
       [   0,    0,    0, ..., 5366, 2108,    4],
       ..., 
       [   0,    0,    0, ...,    7,    7,    4],
       [   0,    0,    0, ...,    2,  132,    4],
       [2937,   53, 1512, ...,    2,  132,    4]]), 'train_X.shape:', (699696, 500))
Epoch 0	Batch 20	Train Loss:311.130	Learning rate:0.00030
Epoch 0	Batch 40	Train Loss:269.449	Learning rate:0.00030
Epoch 0	Batch 60	Train Loss:244.786	Learning rate:0.00030
Loss_accusation:11.390	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:175.760	Current_loss:187.150	
Epoch 0	Batch 80	Train Loss:228.726	Learning rate:0.00030
Epoch 0	Batch 100	Train Loss:216.837	Learning rate:0.00030
Epoch 0	Batch 120	Train Loss:207.261	Learning rate:0.00030
Loss_accusation:9.313	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:146.425	Current_loss:155.738	
Epoch 0	Batch 140	Train Loss:199.131	Learning rate:0.00030
Epoch 0	Batch 160	Train Loss:192.015	Learning rate:0.00030
Epoch 0	Batch 180	Train Loss:185.718	Learning rate:0.00030
Loss_accusation:8.175	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:124.705	Current_loss:132.880	
Epoch 0	Batch 200	Train Loss:180.061	Learning rate:0.00030
Epoch 0	Batch 220	Train Loss:174.930	Learning rate:0.00030
Epoch 0	Batch 240	Train Loss:170.200	Learning rate:0.00030
Loss_accusation:7.453	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:108.707	Current_loss:116.160	
Epoch 0	Batch 260	Train Loss:165.804	Learning rate:0.00030
Epoch 0	Batch 280	Train Loss:161.693	Learning rate:0.00030
Epoch 0	Batch 300	Train Loss:157.839	Learning rate:0.00030
Loss_accusation:6.430	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:95.280	Current_loss:101.710	
Epoch 0	Batch 320	Train Loss:154.195	Learning rate:0.00030
Epoch 0	Batch 340	Train Loss:150.741	Learning rate:0.00030
Epoch 0	Batch 360	Train Loss:147.448	Learning rate:0.00030
Loss_accusation:5.544	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:83.595	Current_loss:89.139	
Epoch 0	Batch 380	Train Loss:144.299	Learning rate:0.00030
Epoch 0	Batch 400	Train Loss:141.284	Learning rate:0.00030
Epoch 0	Batch 420	Train Loss:138.395	Learning rate:0.00030
Loss_accusation:5.716	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:73.414	Current_loss:79.130	
Epoch 0	Batch 440	Train Loss:135.622	Learning rate:0.00030
Epoch 0	Batch 460	Train Loss:132.954	Learning rate:0.00030
Epoch 0	Batch 480	Train Loss:130.377	Learning rate:0.00030
Loss_accusation:5.945	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:64.616	Current_loss:70.560	
Epoch 0	Batch 500	Train Loss:127.899	Learning rate:0.00030
Epoch 0	Batch 520	Train Loss:125.503	Learning rate:0.00030
Epoch 0	Batch 540	Train Loss:123.189	Learning rate:0.00030
Loss_accusation:5.294	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:56.874	Current_loss:62.168	
Epoch 0	Batch 560	Train Loss:120.956	Learning rate:0.00030
Epoch 0	Batch 580	Train Loss:118.796	Learning rate:0.00030
Epoch 0	Batch 600	Train Loss:116.706	Learning rate:0.00030
Loss_accusation:4.537	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:50.226	Current_loss:54.763	
Epoch 0	Batch 620	Train Loss:114.679	Learning rate:0.00030
Epoch 0	Batch 640	Train Loss:112.712	Learning rate:0.00030
Epoch 0	Batch 660	Train Loss:110.806	Learning rate:0.00030
Loss_accusation:4.732	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:44.518	Current_loss:49.249	
Epoch 0	Batch 680	Train Loss:108.959	Learning rate:0.00030
Epoch 0	Batch 700	Train Loss:107.164	Learning rate:0.00030
Epoch 0	Batch 720	Train Loss:105.426	Learning rate:0.00030
Loss_accusation:4.123	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:39.663	Current_loss:43.786	
Epoch 0	Batch 740	Train Loss:103.740	Learning rate:0.00030
Epoch 0	Batch 760	Train Loss:102.104	Learning rate:0.00030
Epoch 0	Batch 780	Train Loss:100.509	Learning rate:0.00030
Loss_accusation:3.464	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:35.417	Current_loss:38.881	
Epoch 0	Batch 800	Train Loss:98.962	Learning rate:0.00030
Epoch 0	Batch 820	Train Loss:97.459	Learning rate:0.00030
Epoch 0	Batch 840	Train Loss:95.997	Learning rate:0.00030
Loss_accusation:3.773	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:31.685	Current_loss:35.457	
Epoch 0	Batch 860	Train Loss:94.574	Learning rate:0.00030
Epoch 0	Batch 880	Train Loss:93.188	Learning rate:0.00030
Epoch 0	Batch 900	Train Loss:91.837	Learning rate:0.00030
Loss_accusation:3.164	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:28.392	Current_loss:31.556	
Epoch 0	Batch 920	Train Loss:90.524	Learning rate:0.00030
Epoch 0	Batch 940	Train Loss:89.247	Learning rate:0.00030
Epoch 0	Batch 960	Train Loss:87.998	Learning rate:0.00030
Loss_accusation:3.225	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:25.510	Current_loss:28.735	
Epoch 0	Batch 980	Train Loss:86.781	Learning rate:0.00030
Epoch 0	Batch 1000	Train Loss:85.594	Learning rate:0.00030
Epoch 0	Batch 1020	Train Loss:84.437	Learning rate:0.00030
Loss_accusation:3.294	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:22.968	Current_loss:26.262	
Epoch 0	Batch 1040	Train Loss:83.306	Learning rate:0.00030
Epoch 0	Batch 1060	Train Loss:82.205	Learning rate:0.00030
Epoch 0	Batch 1080	Train Loss:81.131	Learning rate:0.00030
Loss_accusation:3.270	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:20.730	Current_loss:23.999	
Epoch 0	Batch 1100	Train Loss:80.086	Learning rate:0.00030
Epoch 0	Batch 1120	Train Loss:79.066	Learning rate:0.00030
Epoch 0	Batch 1140	Train Loss:78.067	Learning rate:0.00030
Loss_accusation:3.372	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:18.718	Current_loss:22.090	
Epoch 0	Batch 1160	Train Loss:77.090	Learning rate:0.00030
Epoch 0	Batch 1180	Train Loss:76.137	Learning rate:0.00030
Epoch 0	Batch 1200	Train Loss:75.204	Learning rate:0.00030
Loss_accusation:2.967	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:16.920	Current_loss:19.887	
Epoch 0	Batch 1220	Train Loss:74.292	Learning rate:0.00030
Epoch 0	Batch 1240	Train Loss:73.401	Learning rate:0.00030
Epoch 0	Batch 1260	Train Loss:72.528	Learning rate:0.00030
Loss_accusation:2.468	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:15.321	Current_loss:17.789	
Epoch 0	Batch 1280	Train Loss:71.671	Learning rate:0.00030
Epoch 0	Batch 1300	Train Loss:70.836	Learning rate:0.00030
Epoch 0	Batch 1320	Train Loss:70.017	Learning rate:0.00030
Loss_accusation:2.585	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:13.892	Current_loss:16.478	
Epoch 0	Batch 1340	Train Loss:69.216	Learning rate:0.00030
Epoch 0	Batch 1360	Train Loss:68.431	Learning rate:0.00030
Epoch 0	Batch 1380	Train Loss:67.667	Learning rate:0.00030
Loss_accusation:2.934	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:12.613	Current_loss:15.547	
Epoch 0	Batch 1400	Train Loss:66.917	Learning rate:0.00030
Epoch 0	Batch 1420	Train Loss:66.181	Learning rate:0.00030
Epoch 0	Batch 1440	Train Loss:65.461	Learning rate:0.00030
Loss_accusation:2.434	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:11.457	Current_loss:13.891	
Epoch 0	Batch 1460	Train Loss:64.754	Learning rate:0.00030
Epoch 0	Batch 1480	Train Loss:64.062	Learning rate:0.00030
Epoch 0	Batch 1500	Train Loss:63.383	Learning rate:0.00030
Loss_accusation:2.945	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:10.412	Current_loss:13.356	
Epoch 0	Batch 1520	Train Loss:62.716	Learning rate:0.00030
Epoch 0	Batch 1540	Train Loss:62.063	Learning rate:0.00030
Epoch 0	Batch 1560	Train Loss:61.423	Learning rate:0.00030
Loss_accusation:3.022	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:9.473	Current_loss:12.496	
Epoch 0	Batch 1580	Train Loss:60.793	Learning rate:0.00030
Epoch 0	Batch 1600	Train Loss:60.175	Learning rate:0.00030
Epoch 0	Batch 1620	Train Loss:59.570	Learning rate:0.00030
Loss_accusation:2.471	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:8.626	Current_loss:11.097	
Epoch 0	Batch 1640	Train Loss:58.977	Learning rate:0.00030
Epoch 0	Batch 1660	Train Loss:58.394	Learning rate:0.00030
Epoch 0	Batch 1680	Train Loss:57.823	Learning rate:0.00030
Loss_accusation:1.859	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:7.859	Current_loss:9.717	
Epoch 0	Batch 1700	Train Loss:57.261	Learning rate:0.00030
Epoch 0	Batch 1720	Train Loss:56.708	Learning rate:0.00030
Epoch 0	Batch 1740	Train Loss:56.166	Learning rate:0.00030
Loss_accusation:2.160	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:7.170	Current_loss:9.331	
Epoch 0	Batch 1760	Train Loss:55.634	Learning rate:0.00030
Epoch 0	Batch 1780	Train Loss:55.110	Learning rate:0.00030
Epoch 0	Batch 1800	Train Loss:54.596	Learning rate:0.00030
Loss_accusation:2.384	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:6.549	Current_loss:8.933	
Epoch 0	Batch 1820	Train Loss:54.091	Learning rate:0.00030
Epoch 0	Batch 1840	Train Loss:53.594	Learning rate:0.00030
Epoch 0	Batch 1860	Train Loss:53.105	Learning rate:0.00030
Loss_accusation:1.794	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:5.991	Current_loss:7.785	
Epoch 0	Batch 1880	Train Loss:52.625	Learning rate:0.00030
Epoch 0	Batch 1900	Train Loss:52.154	Learning rate:0.00030
Epoch 0	Batch 1920	Train Loss:51.692	Learning rate:0.00030
Loss_accusation:2.021	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:5.485	Current_loss:7.506	
Epoch 0	Batch 1940	Train Loss:51.237	Learning rate:0.00030
Epoch 0	Batch 1960	Train Loss:50.789	Learning rate:0.00030
Epoch 0	Batch 1980	Train Loss:50.348	Learning rate:0.00030
Loss_accusation:2.035	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:5.026	Current_loss:7.060	
Epoch 0	Batch 2000	Train Loss:49.914	Learning rate:0.00030
Epoch 0	Batch 2020	Train Loss:49.487	Learning rate:0.00030
Epoch 0	Batch 2040	Train Loss:49.065	Learning rate:0.00030
Loss_accusation:1.948	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:4.607	Current_loss:6.555	
Epoch 0	Batch 2060	Train Loss:48.652	Learning rate:0.00030
Epoch 0	Batch 2080	Train Loss:48.244	Learning rate:0.00030
Epoch 0	Batch 2100	Train Loss:47.844	Learning rate:0.00030
Loss_accusation:1.969	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:4.231	Current_loss:6.200	
Epoch 0	Batch 2120	Train Loss:47.449	Learning rate:0.00030
Epoch 0	Batch 2140	Train Loss:47.060	Learning rate:0.00030
Epoch 0	Batch 2160	Train Loss:46.678	Learning rate:0.00030
Loss_accusation:1.888	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:3.892	Current_loss:5.780	
Epoch 0	Batch 2180	Train Loss:46.303	Learning rate:0.00030
Epoch 0	Batch 2200	Train Loss:45.935	Learning rate:0.00030
Epoch 0	Batch 2220	Train Loss:45.572	Learning rate:0.00030
Loss_accusation:1.508	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:3.586	Current_loss:5.094	
Epoch 0	Batch 2240	Train Loss:45.214	Learning rate:0.00030
Epoch 0	Batch 2260	Train Loss:44.863	Learning rate:0.00030
Epoch 0	Batch 2280	Train Loss:44.515	Learning rate:0.00030
Loss_accusation:2.018	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:3.307	Current_loss:5.325	
Epoch 0	Batch 2300	Train Loss:44.172	Learning rate:0.00030
Epoch 0	Batch 2320	Train Loss:43.835	Learning rate:0.00030
Epoch 0	Batch 2340	Train Loss:43.502	Learning rate:0.00030
Loss_accusation:1.807	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:3.055	Current_loss:4.862	
Epoch 0	Batch 2360	Train Loss:43.174	Learning rate:0.00030
Epoch 0	Batch 2380	Train Loss:42.850	Learning rate:0.00030
Epoch 0	Batch 2400	Train Loss:42.531	Learning rate:0.00030
Loss_accusation:1.944	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.829	Current_loss:4.773	
Epoch 0	Batch 2420	Train Loss:42.217	Learning rate:0.00030
Epoch 0	Batch 2440	Train Loss:41.908	Learning rate:0.00030
Epoch 0	Batch 2460	Train Loss:41.605	Learning rate:0.00030
Loss_accusation:1.587	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.625	Current_loss:4.212	
Epoch 0	Batch 2480	Train Loss:41.305	Learning rate:0.00030
Epoch 0	Batch 2500	Train Loss:41.009	Learning rate:0.00030
Epoch 0	Batch 2520	Train Loss:40.717	Learning rate:0.00030
Loss_accusation:1.634	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.438	Current_loss:4.072	
Epoch 0	Batch 2540	Train Loss:40.429	Learning rate:0.00030
Epoch 0	Batch 2560	Train Loss:40.145	Learning rate:0.00030
Epoch 0	Batch 2580	Train Loss:39.864	Learning rate:0.00030
Loss_accusation:1.776	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.269	Current_loss:4.045	
Epoch 0	Batch 2600	Train Loss:39.587	Learning rate:0.00030
Epoch 0	Batch 2620	Train Loss:39.314	Learning rate:0.00030
Epoch 0	Batch 2640	Train Loss:39.044	Learning rate:0.00030
Loss_accusation:1.320	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.116	Current_loss:3.436	
Epoch 0	Batch 2660	Train Loss:38.778	Learning rate:0.00030
Epoch 0	Batch 2680	Train Loss:38.515	Learning rate:0.00030
Epoch 0	Batch 2700	Train Loss:38.256	Learning rate:0.00030
Loss_accusation:1.282	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.977	Current_loss:3.259	
Epoch 0	Batch 2720	Train Loss:38.003	Learning rate:0.00030
Epoch 0	Batch 2740	Train Loss:37.752	Learning rate:0.00030
Epoch 0	Batch 2760	Train Loss:37.504	Learning rate:0.00030
Loss_accusation:1.630	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.852	Current_loss:3.482	
Epoch 0	Batch 2780	Train Loss:37.260	Learning rate:0.00030
Epoch 0	Batch 2800	Train Loss:37.018	Learning rate:0.00030
Epoch 0	Batch 2820	Train Loss:36.780	Learning rate:0.00030
Loss_accusation:1.813	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.737	Current_loss:3.549	
Epoch 0	Batch 2840	Train Loss:36.543	Learning rate:0.00030
Epoch 0	Batch 2860	Train Loss:36.311	Learning rate:0.00030
Epoch 0	Batch 2880	Train Loss:36.081	Learning rate:0.00030
Loss_accusation:1.458	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.634	Current_loss:3.091	
Epoch 0	Batch 2900	Train Loss:35.854	Learning rate:0.00030
Epoch 0	Batch 2920	Train Loss:35.629	Learning rate:0.00030
Epoch 0	Batch 2940	Train Loss:35.407	Learning rate:0.00030
Loss_accusation:1.256	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.539	Current_loss:2.795	
Epoch 0	Batch 2960	Train Loss:35.187	Learning rate:0.00030
Epoch 0	Batch 2980	Train Loss:34.973	Learning rate:0.00030
Epoch 0	Batch 3000	Train Loss:34.761	Learning rate:0.00030
Loss_accusation:1.497	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.454	Current_loss:2.951	
Epoch 0	Batch 3020	Train Loss:34.551	Learning rate:0.00030
Epoch 0	Batch 3040	Train Loss:34.344	Learning rate:0.00030
Epoch 0	Batch 3060	Train Loss:34.140	Learning rate:0.00030
Loss_accusation:1.378	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.376	Current_loss:2.754	
Epoch 0	Batch 3080	Train Loss:33.937	Learning rate:0.00030
Epoch 0	Batch 3100	Train Loss:33.737	Learning rate:0.00030
Epoch 0	Batch 3120	Train Loss:33.539	Learning rate:0.00030
Loss_accusation:1.398	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.307	Current_loss:2.704	
Epoch 0	Batch 3140	Train Loss:33.343	Learning rate:0.00030
Epoch 0	Batch 3160	Train Loss:33.150	Learning rate:0.00030
Epoch 0	Batch 3180	Train Loss:32.959	Learning rate:0.00030
Loss_accusation:1.438	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.244	Current_loss:2.682	
Epoch 0	Batch 3200	Train Loss:32.770	Learning rate:0.00030
Epoch 0	Batch 3220	Train Loss:32.583	Learning rate:0.00030
Epoch 0	Batch 3240	Train Loss:32.398	Learning rate:0.00030
Loss_accusation:1.605	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.186	Current_loss:2.791	
Epoch 0	Batch 3260	Train Loss:32.217	Learning rate:0.00030
Epoch 0	Batch 3280	Train Loss:32.037	Learning rate:0.00030
Epoch 0	Batch 3300	Train Loss:31.860	Learning rate:0.00030
Loss_accusation:1.602	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.133	Current_loss:2.735	
Epoch 0	Batch 3320	Train Loss:31.684	Learning rate:0.00030
Epoch 0	Batch 3340	Train Loss:31.510	Learning rate:0.00030
Epoch 0	Batch 3360	Train Loss:31.338	Learning rate:0.00030
Loss_accusation:2.167	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.084	Current_loss:3.251	
Epoch 0	Batch 3380	Train Loss:31.168	Learning rate:0.00030
Epoch 0	Batch 3400	Train Loss:30.999	Learning rate:0.00030
Epoch 0	Batch 3420	Train Loss:30.832	Learning rate:0.00030
Loss_accusation:1.265	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.039	Current_loss:2.304	
Epoch 0	Batch 3440	Train Loss:30.666	Learning rate:0.00030
Epoch 0	Batch 3460	Train Loss:30.503	Learning rate:0.00030
Epoch 0	Batch 3480	Train Loss:30.341	Learning rate:0.00030
Loss_accusation:1.344	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.999	Current_loss:2.344	
Epoch 0	Batch 3500	Train Loss:30.181	Learning rate:0.00030
Epoch 0	Batch 3520	Train Loss:30.024	Learning rate:0.00030
Epoch 0	Batch 3540	Train Loss:29.869	Learning rate:0.00030
Loss_accusation:1.613	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.963	Current_loss:2.577	
Epoch 0	Batch 3560	Train Loss:29.715	Learning rate:0.00030
Epoch 0	Batch 3580	Train Loss:29.563	Learning rate:0.00030
Epoch 0	Batch 3600	Train Loss:29.412	Learning rate:0.00030
Loss_accusation:1.374	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.930	Current_loss:2.303	
Epoch 0	Batch 3620	Train Loss:29.262	Learning rate:0.00030
Epoch 0	Batch 3640	Train Loss:29.115	Learning rate:0.00030
Epoch 0	Batch 3660	Train Loss:28.969	Learning rate:0.00030
Loss_accusation:1.464	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.900	Current_loss:2.364	
Epoch 0	Batch 3680	Train Loss:28.824	Learning rate:0.00030
Epoch 0	Batch 3700	Train Loss:28.681	Learning rate:0.00030
Epoch 0	Batch 3720	Train Loss:28.538	Learning rate:0.00030
Loss_accusation:1.325	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.873	Current_loss:2.198	
Epoch 0	Batch 3740	Train Loss:28.397	Learning rate:0.00030
Epoch 0	Batch 3760	Train Loss:28.258	Learning rate:0.00030
Epoch 0	Batch 3780	Train Loss:28.121	Learning rate:0.00030
Loss_accusation:1.408	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.848	Current_loss:2.256	
Epoch 0	Batch 3800	Train Loss:27.985	Learning rate:0.00030
Epoch 0	Batch 3820	Train Loss:27.851	Learning rate:0.00030
Epoch 0	Batch 3840	Train Loss:27.718	Learning rate:0.00030
Loss_accusation:1.299	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.825	Current_loss:2.123	
Epoch 0	Batch 3860	Train Loss:27.586	Learning rate:0.00030
Epoch 0	Batch 3880	Train Loss:27.456	Learning rate:0.00030
Epoch 0	Batch 3900	Train Loss:27.326	Learning rate:0.00030
Loss_accusation:1.583	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.803	Current_loss:2.386	
('number_examples:', 13094)
('x.imprisonment_score.target_value:', 24.0, ';predict_value:', 0.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score:', 1.0)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score:', 1.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('imprisonment_score:', 0.0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score:', 1.0)
('accusation_normal_f1_score', 'precison:', '0.0', ';recall:', '0.0', ';f1_score:', 0.0)
('macro', 'precison:', '0.000306372548785', ';recall:', '0.999997500006', ';f1_score:', 0.0006125513026685221)
('f1_micro_accusation:', 0.815494623123336, ';f1_macro_accusation:', 0.6001948066813642)
Epoch 0 ValidLoss:2.472	Macro_f1_accasation:0.600	Micro_f1_accsastion:0.815	Macro_f1_article:0.012 Micro_f1_article:0.012 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 70.784471490235, ';2.Article Score:', 1.241833479839026, ';3.Penalty Score:', 68.86386171269332, ';Score ALL:', 140.89016668276736)
going to save check point.
Epoch 0	Batch 3920	Train Loss:27.198	Learning rate:0.00030
Epoch 0	Batch 3940	Train Loss:27.071	Learning rate:0.00030
Epoch 0	Batch 3960	Train Loss:26.945	Learning rate:0.00030
Loss_accusation:1.254	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.784	Current_loss:2.038	
Epoch 0	Batch 3980	Train Loss:26.820	Learning rate:0.00030
Epoch 0	Batch 4000	Train Loss:26.696	Learning rate:0.00030
Epoch 0	Batch 4020	Train Loss:26.574	Learning rate:0.00030
Loss_accusation:1.298	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.766	Current_loss:2.065	
Epoch 0	Batch 4040	Train Loss:26.453	Learning rate:0.00030
Epoch 0	Batch 4060	Train Loss:26.334	Learning rate:0.00030
Epoch 0	Batch 4080	Train Loss:26.216	Learning rate:0.00030
Loss_accusation:1.336	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.751	Current_loss:2.087	
Epoch 0	Batch 4100	Train Loss:26.099	Learning rate:0.00030
Epoch 0	Batch 4120	Train Loss:25.982	Learning rate:0.00030
Epoch 0	Batch 4140	Train Loss:25.867	Learning rate:0.00030
Loss_accusation:1.258	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.737	Current_loss:1.995	
Epoch 0	Batch 4160	Train Loss:25.752	Learning rate:0.00030
('model:', 'text_cnn')
('cache_path:', 'cache_text_cnn/vocab_label.pik', 'file_exists:', True)
going to load cache file.vocab of words and labels
('cnn_model.vocab_size:', 100002)
('accusation_num_classes:', 202)
('article_num_clasess:', 183)
('cache_path:', 'cache_text_cnn/train_valid_test.h5', 'train_valid_test_file_exists:', False)
('length of train_lines:', 496560, ';length of valid_lines:', 13094, ';length of test_lines:', 32508)
('start multi-processing:', 0, 'cache_text_cnn/training_data_temp_0.pik')
('start multi-processing:', 1, 'cache_text_cnn/training_data_temp_1.pik')
('start multi-processing:', 2, 'cache_text_cnn/training_data_temp_2.pik')
('start multi-processing:', 3, 'cache_text_cnn/training_data_temp_3.pik')
('start multi-processing:', 4, 'cache_text_cnn/training_data_temp_4.pik')
('start multi-processing:', 5, 'cache_text_cnn/training_data_temp_5.pik')
('start multi-processing:', 6, 'cache_text_cnn/training_data_temp_6.pik')
('start multi-processing:', 7, 'cache_text_cnn/training_data_temp_7.pik')
('start multi-processing:', 8, 'cache_text_cnn/training_data_temp_8.pik')
('start multi-processing:', 9, 'cache_text_cnn/training_data_temp_9.pik')
('start multi-processing:', 10, 'cache_text_cnn/training_data_temp_10.pik')
('start multi-processing:', 11, 'cache_text_cnn/training_data_temp_11.pik')
('start multi-processing:', 12, 'cache_text_cnn/training_data_temp_12.pik')
('start multi-processing:', 13, 'cache_text_cnn/training_data_temp_13.pik')
('start multi-processing:', 14, 'cache_text_cnn/training_data_temp_14.pik')
('start multi-processing:', 15, 'cache_text_cnn/training_data_temp_15.pik')
('start multi-processing:', 16, 'cache_text_cnn/training_data_temp_16.pik')
('start multi-processing:', 17, 'cache_text_cnn/training_data_temp_17.pik')
('start multi-processing:', 18, 'cache_text_cnn/training_data_temp_18.pik')
('start multi-processing:', 19, 'cache_text_cnn/training_data_temp_19.pik')
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.271 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 30, 98, 9, 97, 10, 143, 12, 143, 39, 2, 6, 63, 14, 13, 11, 26, 441, 3868, 10207, 341, 341, 341, 341, 341, 341, 341, 341, 5, 226, 1990, 2, 16, 90, 54, 3069, 26, 980, 1083, 2, 369, 2416, 613, 4, 63, 14, 13, 64, 90, 54, 246, 496, 61706, 2, 15328, 12238, 9069, 771, 155, 1990, 2, 428, 1, 3592, 582, 155, 2, 18566, 1, 4, 2581, 2, 63, 14, 13, 120, 980, 254, 675, 536, 1930, 1787, 2144, 90, 54, 5, 543, 12220, 7494, 2, 33, 147, 146, 3765, 11, 559, 4, 2112, 666, 8, 2117, 11, 155, 226, 3292, 23694, 438, 5893, 3093, 2, 1056, 90, 54, 2132, 11, 63, 14, 625, 2241, 2, 438, 1099, 21, 90, 54, 5, 3072, 90, 27872, 7013, 90, 533, 4, 455, 63, 14, 6282, 90, 533, 22, 82, 2048, 1697, 2, 438, 1306, 21, 65, 4, 90, 54, 1215, 37, 1586, 228, 2194, 2, 17, 516, 2, 108, 684, 216, 158, 4, 17, 32, 2, 90, 5256, 5245, 2230, 4766, 5400, 543, 320, 722, 1126, 141, 158, 2, 158, 5067, 25, 43857, 4, 6, 63, 14, 13, 1254, 4576, 7726, 3, 2011, 8775, 9107, 23, 8241, 24, 2, 76, 5181, 114, 1280, 4, 29, 28, 2675, 47, 140, 94, 5, 34, 76, 67, 69, 3, 65, 290, 282, 60, 3, 447, 795, 135, 453, 3, 328, 60, 3, 843, 1787, 3, 424, 222, 3, 734, 43, 6, 63, 14, 13, 5, 44, 62, 214, 22, 4, 29, 28, 64, 2, 6, 63, 14, 2155, 10639, 2, 562, 4350, 2, 317, 4154, 206, 5494, 2, 1232, 158, 2, 26, 61, 66, 130, 7, 7, 4, 6, 63, 14, 13, 633, 13842, 5181, 114, 1280, 82, 2, 116, 804, 74, 26, 278, 789, 933, 183, 4, 194, 115, 116, 104, 4, 627, 674, 858, 90, 3381, 82, 439, 6, 63, 14, 13, 6909, 170, 4026, 2, 22955, 15, 4, 627, 674, 858, 84, 376, 443, 21, 334, 5, 87, 3, 706, 22, 173, 2, 47, 87, 26, 41, 90, 54, 5, 17837, 22, 175, 4])
(0, 'x_feature:', [0.2857142857142857, 0.0, 0.07142857142857142, 0.0, 0.05263157894736842, 0.1875, 0.058823529411764705, 0.10526315789473684, 0.10526315789473684, 0.045454545454545456, 0.08333333333333333, 0.0, 0.15384615384615385, 0.11764705882352941, 0.0625, 0.06666666666666667, 0.08333333333333333, 0.1, 0.09090909090909091, 0.08333333333333333, 0.0625, 0.14285714285714285, 0.08333333333333333, 0.2, 0.09090909090909091, 0.2, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u6545\u610f\u6740\u4eba'])
(0, '#######transform_data_to_index.accusation_list(index):', [187])
(0, '#######transform_data_to_index.article_list(string):', [u'232'])
(0, '#######transform_data_to_index.article_list(index):', [156])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.276 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1587, 7675, 10826, 45, 18, 30, 57, 9, 83, 10, 233, 12, 248, 39, 2, 6, 575, 11, 7675, 10826, 8133, 13, 169, 213, 2, 47, 2215, 685, 117, 347, 592, 15, 5, 112, 344, 129, 275, 209, 178, 2, 20, 37, 489, 180, 91, 2, 27, 120, 178, 4195, 471, 117, 347, 14, 685, 23, 14, 151, 24, 2, 120, 575, 4195, 471, 910, 592, 15, 4, 17, 32, 30, 120, 178, 4195, 471, 117, 796, 1, 42, 303, 347, 363, 4, 74, 18, 5, 188, 2, 29, 28, 84, 376, 150, 173, 252, 3, 67, 69, 3, 6, 5, 44, 43, 214, 3, 135, 32, 197, 22, 34, 4, 29, 28, 64, 6, 575, 47, 2135, 25, 433, 2, 553, 246, 117, 445, 317, 344, 2, 26, 61, 271, 51, 68, 78, 50, 7, 7, 5, 71, 2, 124, 47, 348, 450, 137, 114, 4, 194, 115, 116, 104, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.07142857142857142, 0.0, 0.05263157894736842, 0.1875, 0.0, 0.2631578947368421, 0.15789473684210525, 0.09090909090909091, 0.08333333333333333, 0.0, 0.23076923076923078, 0.11764705882352941, 0.0625, 0.06666666666666667, 0.3333333333333333, 0.2, 0.0, 0.08333333333333333, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u8d70\u79c1\u3001\u8d29\u5356\u3001\u8fd0\u8f93\u3001\u5236\u9020\u6bd2\u54c1'])
(0, '#######transform_data_to_index.accusation_list(index):', [72])
(0, '#######transform_data_to_index.article_list(string):', [u'356', u'347'])
(0, '#######transform_data_to_index.article_list(index):', [96, 136])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Loading model cost 0.277 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [2342, 7505, 45, 18, 30, 6, 1756, 13, 164, 1849, 54324, 1547, 21, 1440, 5, 4676, 4, 73, 9, 58, 10, 242, 12, 216, 2, 6, 3827, 35, 120, 673, 249, 9998, 5, 122, 227, 2342, 7505, 10157, 1839, 1440, 2723, 2, 20, 26, 3420, 62, 577, 213, 2159, 16, 126, 8, 38, 2342, 7505, 20849, 195, 41, 20104, 195, 1098, 1142, 371, 1030, 2, 4895, 27, 47, 6058, 5677, 2, 1440, 16, 126, 8, 1377, 5, 481, 149, 5343, 103, 293, 4, 17, 3178, 32, 2, 37, 1301, 103, 5, 56, 25, 31, 1, 15, 4, 142, 2, 105, 1507, 37, 1301, 103, 668, 428, 16, 4])
(0, 'x_feature:', [0.0, 0.0, 0.0, 0.0, 0.0, 0.0625, 0.058823529411764705, 0.05263157894736842, 0.05263157894736842, 0.0, 0.0, 0.0, 0.0, 0.058823529411764705, 0.125, 0.0, 0.16666666666666666, 0.1, 0.18181818181818182, 0.0, 0.125, 0.21428571428571427, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u62a2\u52ab'])
(0, '#######transform_data_to_index.accusation_list(index):', [18])
(0, '#######transform_data_to_index.article_list(string):', [u'263'])
(0, '#######transform_data_to_index.article_list(index):', [159])
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.394 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [3400, 7522, 45, 18, 30, 2129, 9, 100, 10, 83, 12, 250, 39, 2, 3400, 77, 25247, 408, 1, 334, 111, 11, 3400, 7522, 774, 6, 63, 14, 13, 834, 33, 26, 91, 2, 455, 120, 26, 834, 2241, 4690, 144, 125, 2231, 1522, 1860, 581, 3476, 2775, 3643, 117, 1350, 556, 743, 46, 1573, 3, 2231, 1522, 1860, 311, 725, 2775, 117, 225, 556, 743, 14, 451, 3, 11, 17869, 654, 1717, 4908, 40666, 125, 2231, 1522, 1860, 581, 3476, 2775, 3643, 117, 1350, 556, 743, 14, 1573, 3, 2231, 1522, 1860, 581, 3476, 2775, 3643, 117, 1350, 556, 743, 19, 1573, 3, 2231, 1522, 1860, 311, 725, 2775, 117, 225, 556, 743, 14, 451, 3, 256, 1315, 1522, 70, 1803, 2231, 1522, 1860, 311, 725, 2775, 117, 225, 556, 743, 14, 451, 3, 2231, 8779, 1860, 581, 3476, 2775, 3643, 117, 1350, 556, 743, 58, 30681, 1, 2332, 3, 8777, 1860, 311, 725, 2775, 117, 225, 556, 743, 2332, 3, 256, 581, 1522, 70, 1803, 57253, 4321, 117, 1350, 225, 9822, 556, 743, 2332, 3, 2231, 8779, 1860, 581, 3476, 2775, 3643, 117, 1350, 556, 743, 179, 1573, 4, 17, 1106, 2, 120, 6, 63, 14, 13, 834, 125, 5, 225, 556, 743, 382, 170, 179, 151, 2, 125, 5, 1350, 556, 743, 382, 170, 49, 151, 2, 125, 5, 117, 1350, 225, 9822, 556, 743, 382, 14, 151, 4, 17, 3400, 77, 252, 32, 169, 135, 2, 120, 6, 63, 14, 13, 834, 125, 5, 109, 311, 725, 2775, 117, 225, 556, 3000, 303, 190, 363, 2, 125, 5, 581, 9621, 117, 1350, 556, 3000, 303, 190, 62, 2407, 363, 2, 125, 5, 57253, 4321, 117, 1350, 225, 9822, 556, 3000, 303, 190, 3, 2407, 3, 14347, 5171, 9943, 3, 5171, 9943, 3, 5171, 25667, 363, 4, 29, 28, 64, 2, 6, 63, 14, 13, 317, 798, 190, 8209, 330, 2037, 10136, 2, 118, 312, 2, 34, 302, 3, 297, 2, 124, 47, 7, 7, 137, 114, 4, 6, 63, 14, 880, 762, 2786, 117, 1390, 2, 194, 115, 116, 104, 4])
('train', 'transform_data_to_index.####################.start.')
(0, 'x_feature:', [0.0, 0.0, 0.07142857142857142, 0.0, 0.05263157894736842, 0.0625, 0.0, 0.3157894736842105, 0.21052631578947367, 0.09090909090909091, 0.08333333333333333, 0.0, 0.15384615384615385, 0.23529411764705882, 0.0625, 0.06666666666666667, 0.25, 0.0, 0.0, 0.08333333333333333, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.18181818181818182, 0.1, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u6301\u6709\u6bd2\u54c1'])
(0, '#######transform_data_to_index.accusation_list(index):', [9])
(0, '#######transform_data_to_index.article_list(string):', [u'356', u'348'])
(0, '#######transform_data_to_index.article_list(index):', [96, 65])
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.406 seconds.
Prefix dict has been built succesfully.
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
(0, '#######transform_data_to_index.x:', [17, 106, 99, 2, 365, 9, 75, 10, 2, 6, 825, 8, 3404, 256, 1603, 19535, 5, 617, 2575, 52, 8648, 2575, 53, 2, 13116, 25, 17339, 367, 1, 367, 12632, 2, 5570, 123, 2575, 5, 294, 2570, 2, 27, 6263, 26, 9955, 92, 25, 26, 187, 2064, 1273, 62, 508, 4, 455, 2, 11, 92, 5, 1273, 273, 2, 6, 825, 8, 71246, 19535, 209, 1137, 8, 3, 646, 3, 90, 3, 594, 8, 3, 324, 8, 22, 82, 11, 123, 2575, 144, 19535, 2, 13755, 25, 14, 30, 14, 789, 14, 30, 14, 2, 13226, 175, 291, 92, 941, 1688, 209, 47, 429, 1097, 789, 18249, 5, 262, 7846, 367, 2575, 4077, 6, 825, 8, 5, 4619, 246, 1688, 209, 1927, 895, 5, 9477, 367, 6, 825, 8, 1603, 123, 2575, 617, 38, 220, 9, 58, 10, 2, 442, 547, 1927, 895, 1033, 349, 257, 2, 1014, 2216, 5883, 4, 94, 2, 76, 6, 825, 8, 5, 44, 2, 67, 92, 3, 1137, 8, 3, 646, 22, 82, 5, 69, 2, 177, 60, 3, 1935, 11852, 3, 103, 11852, 22, 235, 34, 191, 87, 4, 166, 34, 3158, 322, 928, 3, 468, 2, 6, 131, 2, 132, 4])
(0, 'x_feature:', [0.047619047619047616, 0.125, 0.07142857142857142, 0.0, 0.15789473684210525, 0.1875, 0.0, 0.0, 0.05263157894736842, 0.045454545454545456, 0.0, 0.0, 0.07692307692307693, 0.058823529411764705, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u5f00\u8bbe\u8d4c\u573a'])
(0, '#######transform_data_to_index.accusation_list(index):', [6])
(0, '#######transform_data_to_index.article_list(string):', [u'303'])
(0, '#######transform_data_to_index.article_list(index):', [74])
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.413 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 30, 73, 9, 86, 10, 239, 12, 201, 39, 2, 6, 126, 8, 93, 12645, 15174, 4638, 1, 3780, 469, 168, 265, 5881, 2, 469, 209, 63, 8, 607, 126, 8, 93, 12645, 15174, 1, 469, 145, 213, 26923, 229, 3176, 3775, 2052, 2, 827, 369, 26923, 182, 93, 12645, 15174, 20757, 251, 256, 2531, 213, 36, 2, 6, 126, 8, 9773, 8, 1184, 7430, 6304, 644, 494, 2, 44391, 6760, 39983, 2, 33, 2052, 84, 1, 379, 5057, 4, 37, 1301, 5, 2052, 246, 229, 1315, 3176, 3775, 1, 662, 662, 662, 662, 3904, 171, 2, 6378, 25, 791, 47883, 662, 662, 662, 662, 2, 3934, 30, 1, 662, 662, 662, 662, 2, 3368, 48, 30, 1, 662, 662, 662, 662, 2, 486, 17, 12645, 1365, 62, 3562, 1569, 112, 315, 145, 140, 2, 2391, 112, 25, 11208, 15, 4, 6, 126, 8, 108, 181, 9, 58, 10, 321, 12, 11, 1197, 1368, 10035, 48175, 244, 256, 1553, 505, 37, 489, 91, 4])
(0, 'x_feature:', [0.0, 0.0, 0.07142857142857142, 0.0, 0.0, 0.0625, 0.058823529411764705, 0.10526315789473684, 0.05263157894736842, 0.045454545454545456, 0.08333333333333333, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.16666666666666666, 0.4, 0.0, 0.0, 0.125, 0.21428571428571427, 0.0, 0.2, 0.0, 0.0, 0.09090909090909091, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u62a2\u593a'])
(0, '#######transform_data_to_index.accusation_list(index):', [103])
(0, '#######transform_data_to_index.article_list(string):', [u'267'])
(0, '#######transform_data_to_index.article_list(index):', [78])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.427 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1984, 13540, 45, 940, 18, 2, 57, 9, 416, 10, 215, 12, 248, 36, 200, 154, 2, 6, 72, 11, 1984, 13540, 215, 2014, 213, 4647, 2, 84, 275, 209, 79, 8, 348, 36, 2, 37, 535, 91, 4, 180, 125, 117, 796, 743, 1218, 2, 910, 601, 15, 4, 17, 1984, 333, 162, 145, 32, 2, 125, 5, 117, 796, 3000, 303, 190, 1157, 2, 382, 14, 151, 4, 29, 28, 64, 2, 6, 72, 5, 61, 66, 130, 348, 450, 2, 327, 137, 114, 4, 362, 109, 18, 2, 29, 28, 2666, 6, 5, 159, 87, 3, 3708, 3, 495, 107, 3, 156, 189, 3, 4276, 3587, 860, 3, 1186, 245, 3, 67, 69, 3, 32, 197, 3, 177, 60, 43, 102, 3, 6, 44, 22, 34, 191, 1762, 4, 1858, 29, 28, 18, 5, 118, 43, 1802, 2, 6, 72, 568, 3066, 2, 224, 652, 214, 197, 4, 27, 261, 878, 868, 4])
(0, 'x_feature:', [0.09523809523809523, 0.0, 0.0, 0.0, 0.0, 0.1875, 0.0, 0.21052631578947367, 0.15789473684210525, 0.045454545454545456, 0.0, 0.09090909090909091, 0.07692307692307693, 0.058823529411764705, 0.0625, 0.0, 0.25, 0.1, 0.0, 0.08333333333333333, 0.0, 0.14285714285714285, 0.08333333333333333, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u8d70\u79c1\u3001\u8d29\u5356\u3001\u8fd0\u8f93\u3001\u5236\u9020\u6bd2\u54c1'])
(0, '#######transform_data_to_index.accusation_list(index):', [72])
(0, '#######transform_data_to_index.article_list(string):', [u'347', u'357'])
(0, '#######transform_data_to_index.article_list(index):', [136, 54])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Loading model cost 0.425 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [18291, 45, 18, 30, 220, 9, 2, 6, 238, 21499, 1924, 18291, 12942, 83307, 6833, 531, 5, 1140, 2, 7447, 1, 4959, 742, 5, 237, 4800, 714, 4, 57, 9, 14, 10, 89, 12, 2, 238, 54, 1792, 33, 26, 28135, 5, 7104, 15, 3678, 26, 19302, 238, 95, 2, 502, 1850, 238, 95, 11, 423, 1110, 42, 4544, 1640, 5, 1534, 4, 55, 9, 46, 10, 58, 12, 2, 238, 95, 33, 2669, 428, 1621, 4, 18291, 45, 25, 87, 94, 2, 84, 115, 150, 21, 448, 5, 34, 4, 18291, 45, 64, 2, 6, 238, 54, 390, 567, 144, 5, 735, 2, 4374, 590, 2, 187, 2216, 1110, 2, 26, 61, 271, 51, 68, 78, 50, 7, 7, 7, 7, 110, 71, 2, 118, 312, 2, 34, 302, 3, 297, 2, 124, 47, 7, 7, 137, 114, 4, 386, 51, 68, 1007, 50, 7, 7, 5, 71, 2, 194, 115, 116, 104, 4])
(0, 'x_feature:', [0.0, 0.0, 0.07142857142857142, 0.0, 0.10526315789473684, 0.0625, 0.0, 0.0, 0.05263157894736842, 0.045454545454545456, 0.0, 0.18181818181818182, 0.15384615384615385, 0.11764705882352941, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u632a\u7528\u516c\u6b3e'])
(0, '#######transform_data_to_index.accusation_list(index):', [135])
(0, '#######transform_data_to_index.article_list(string):', [u'384'])
(0, '#######transform_data_to_index.article_list(index):', [179])
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.514 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 2, 73, 9, 75, 10, 100, 12, 179, 39, 2, 6, 1466, 19, 13, 41, 19569, 90, 767, 291, 1123, 1097, 5, 262, 742, 910, 2, 291, 1466, 19, 13, 33, 117, 27024, 19932, 717, 20, 1123, 972, 90, 59554, 5, 262, 3464, 117, 4, 1069, 179, 36, 2328, 370, 2, 1466, 19, 13, 291, 1123, 742, 90, 2519, 15, 31, 21556, 2, 108, 233, 36, 143, 154, 352, 1893, 4672, 8570, 14609, 98883, 1, 244, 29497, 349, 1030, 2, 33, 347, 23, 1118, 52, 20339, 53, 2, 382, 14, 151, 24, 1228, 108, 20666, 74472, 144, 27, 33, 26463, 291, 1123, 69863, 5708, 90, 2, 1884, 506, 65, 522, 27401, 249, 37, 9628, 111, 91, 4, 74, 109, 18, 188, 2, 29, 28, 150, 21, 424, 222, 3, 91, 107, 43, 175, 245, 3, 159, 87, 3, 746, 60, 3, 156, 60, 3, 1106, 60, 3, 3558, 60, 3, 328, 60, 43, 102, 3, 1466, 19, 37907, 1441, 3, 504, 236, 3, 1378, 1699, 1705, 236, 3, 267, 395, 2, 67, 90, 5, 69, 2, 6, 1466, 19, 13, 5, 44, 62, 214, 3, 117, 135, 32, 283, 2, 65, 177, 60, 43, 102, 22, 34, 81, 2, 27, 64, 6, 1466, 19, 13, 485, 512, 117, 6490, 2, 348, 347, 14, 151, 2, 26, 61, 271, 21, 51, 68, 78, 50, 7, 7, 7, 7, 3, 7, 7, 2, 118, 312, 2, 34, 302, 297, 2, 124, 47, 348, 450, 548, 6, 114, 4, 6, 1466, 19, 13, 319, 164, 348, 450, 37, 104, 7, 7, 2, 712, 680, 867, 1671, 2, 11, 1100, 3703, 1390, 124, 104, 7, 7, 330, 712, 110, 348, 450, 2, 246, 762, 2, 167, 246, 117, 1390, 2, 124, 999, 183, 4, 194, 115, 116, 104, 4])
(0, 'x_feature:', [0.14285714285714285, 0.0, 0.0, 0.16666666666666666, 0.10526315789473684, 0.25, 0.0, 0.15789473684210525, 0.10526315789473684, 0.045454545454545456, 0.08333333333333333, 0.09090909090909091, 0.07692307692307693, 0.17647058823529413, 0.125, 0.06666666666666667, 0.16666666666666666, 0.2, 0.0, 0.08333333333333333, 0.0625, 0.07142857142857142, 0.08333333333333333, 0.0, 0.09090909090909091, 0.1, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u8d70\u79c1\u3001\u8d29\u5356\u3001\u8fd0\u8f93\u3001\u5236\u9020\u6bd2\u54c1'])
(0, '#######transform_data_to_index.accusation_list(index):', [72])
(0, '#######transform_data_to_index.article_list(string):', [u'356', u'347'])
(0, '#######transform_data_to_index.article_list(index):', [96, 136])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.880 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 2, 55, 9, 49, 10, 143, 750, 73, 9, 19, 10, 233, 12, 2, 6, 418, 1025, 2, 2523, 6112, 95097, 8080, 916, 5, 3606, 10153, 1088, 1854, 475, 2, 3137, 457, 32762, 1992, 5, 7022, 6296, 209, 187, 617, 2, 1014, 1048, 4, 11, 530, 101, 42, 2, 418, 619, 7022, 5, 6738, 3, 10881, 3, 18985, 1688, 209, 5, 20458, 43, 742, 1870, 22, 2672, 7580, 4, 73, 9, 19, 10, 233, 12, 336, 2, 105, 116, 74, 123, 1854, 475, 187, 282, 2, 180, 91, 418, 43, 592, 1745, 1688, 209, 2, 27, 125, 21, 27345, 7022, 4, 17, 4480, 77, 32, 2, 109, 471, 5, 7022, 6215, 4742, 618, 457, 27786, 26240, 3, 10881, 22, 617, 1992, 4, 94, 2, 6, 418, 11, 161, 101, 42, 167, 131, 2, 27, 76, 424, 222, 2, 67, 59, 54, 3, 90, 54, 3, 59, 95, 3, 231, 3, 178, 3, 59, 430, 3, 90, 95, 3, 6778, 3, 90, 430, 3, 59, 533, 3, 59, 1360, 3, 88, 2128, 3, 88, 3220, 3, 59, 3405, 3, 59, 6420, 3, 59, 8423, 3, 702, 146, 3, 88, 9508, 3, 702, 13, 95, 3, 2177, 3, 59, 12651, 3, 223, 3, 88, 17291, 3, 1468, 3, 2120, 54, 3, 59, 15405, 3, 2120, 95, 3, 90, 533, 5, 69, 2, 6112, 77, 260, 5, 282, 60, 2, 156, 199, 189, 43, 102, 2, 6, 418, 43, 67, 59, 54, 3, 231, 3, 178, 3, 59, 430, 3, 90, 95, 3, 6778, 3, 90, 430, 3, 59, 533, 3, 59, 1360, 177, 65, 5, 60, 43, 102, 2, 6, 418, 43, 67, 59, 54, 3, 59, 1360, 3, 90, 95, 3, 59, 533, 3, 90, 430, 3, 6778, 3, 231, 3, 178, 3, 59, 430, 527, 7022, 5, 60, 43, 102, 2, 6, 418, 41, 67, 59, 54, 981, 177, 5, 60, 43, 102, 2, 67, 231, 3, 178, 3, 59, 430, 3, 90, 95, 3, 6778, 3, 90, 430, 3, 59, 533, 3, 59, 1360, 177, 6, 418, 43, 67, 59, 54, 5, 60, 43, 102, 2, 4480, 77, 6323, 2889, 1512, 453, 2, 6112, 77, 504, 236, 43, 3344, 504, 236, 2, 6112, 77, 1075, 28776, 274, 260, 5, 495, 107, 22, 34, 81, 2, 132, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.0, 0.0, 0.05263157894736842, 0.3125, 0.058823529411764705, 0.05263157894736842, 0.0, 0.045454545454545456, 0.0, 0.0, 0.07692307692307693, 0.23529411764705882, 0.0625, 0.0, 0.16666666666666666, 0.1, 0.0, 0.0, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.09090909090909091, 0.1, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u5f00\u8bbe\u8d4c\u573a'])
(0, '#######transform_data_to_index.accusation_list(index):', [6])
(0, '#######transform_data_to_index.article_list(string):', [u'303'])
(0, '#######transform_data_to_index.article_list(index):', [74])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.559 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 30, 73, 9, 80, 10, 38, 89, 817, 2, 6, 1347, 8, 357, 38, 2586, 7687, 22687, 22, 559, 2, 127, 633, 83, 536, 2, 258, 148, 170, 31, 1, 15, 4, 616, 1579, 520, 30, 19, 9, 80, 10, 321, 12, 216, 2, 6, 1347, 8, 38, 2586, 7687, 153, 37803, 9525, 48, 52, 7687, 2134, 53, 19546, 2, 2312, 826, 2, 258, 16, 231, 14, 5, 148, 31, 601, 15, 62, 2586, 7687, 153, 7687, 2134, 19546, 5, 14141, 31, 492, 15, 4, 49, 9, 80, 10, 403, 12, 216, 2, 6, 1347, 8, 38, 2586, 7687, 153, 3812, 1034, 3003, 48, 52, 1, 10456, 53, 23952, 697, 2, 2312, 826, 2, 258, 148, 31, 66388, 15, 4, 49, 9, 80, 10, 398, 12, 216, 2, 6, 1347, 8, 45753, 7035, 423, 5, 2586, 7687, 153, 83067, 8463, 195, 6363, 48, 52, 7035, 53, 295, 122, 4187, 3736, 2, 2016, 826, 2, 258, 148, 31, 2905, 15, 4, 49, 9, 80, 10, 398, 12, 216, 2, 6, 1347, 8, 38, 255, 13, 423, 5, 2586, 7687, 153, 37803, 4612, 48, 52, 1, 53, 295, 697, 2, 299, 622, 779, 2, 1217, 2185, 1083, 826, 2, 691, 4724, 422, 2, 258, 148, 31, 9004, 15, 4, 37, 422, 4724, 56, 31, 492, 15, 4, 80, 9, 89, 10, 14, 12, 216, 2, 6, 1347, 8, 38, 14896, 13311, 7282, 52, 91248, 21316, 53, 7543, 2, 299, 622, 779, 2, 930, 1695, 4238, 826, 2, 224, 258, 383, 4, 80, 9, 89, 10, 19, 12, 216, 2, 6, 1347, 8, 38, 2586, 7687, 153, 3812, 1034, 17756, 48, 2586, 56725, 168, 7687, 1366, 3996, 1713, 2, 3839, 826, 2, 930, 15920, 1135, 3743, 5, 25231, 2, 258, 16, 90, 5, 148, 31, 34262, 15, 4, 6, 1347, 8, 276, 20, 2, 128, 44, 21, 109, 366, 118, 4, 330, 188, 2, 6, 1347, 8, 11, 161, 101, 42, 167, 131, 2, 27, 76, 16, 231, 14, 3, 1032, 3, 231, 19, 3, 92, 3, 90, 5, 133, 3, 67, 231, 19, 3, 603, 3, 384, 19, 3, 786, 5, 69, 3, 3996, 747, 5711, 3, 838, 1080, 3, 734, 6969, 3, 49759, 8152, 3, 860, 3, 65, 290, 282, 60, 3, 102, 3, 772, 495, 107, 3, 125, 107, 3, 6, 1347, 8, 5, 44, 3, 177, 60, 3, 267, 395, 3, 1427, 816, 3, 504, 236, 3, 709, 184, 22, 34, 81, 2, 132, 4])
(0, 'x_feature:', [0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.045454545454545456, 0.08333333333333333, 0.09090909090909091, 0.07692307692307693, 0.0, 0.0625, 0.0, 0.16666666666666666, 0.2, 0.0, 0.08333333333333333, 0.0625, 0.14285714285714285, 0.08333333333333333, 0.2, 0.09090909090909091, 0.2, 0.09090909090909091, 0.09090909090909091])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u76d7\u7a83'])
(0, '#######transform_data_to_index.accusation_list(index):', [189])
(0, '#######transform_data_to_index.article_list(string):', [u'264'])
(0, '#######transform_data_to_index.article_list(index):', [57])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.694 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [3037, 45, 18, 2, 98, 9, 75, 961, 2, 842, 13, 3, 238, 23, 234, 66, 598, 24, 2444, 11, 3037, 5423, 212, 20, 8193, 4606, 21, 2249, 510, 12815, 2, 1603, 12188, 22, 5995, 2348, 4, 6, 238, 23, 238, 5, 1341, 24, 11, 553, 3115, 25, 510, 423, 2, 166, 33, 5995, 2348, 42, 1547, 5, 4655, 1403, 483, 1358, 3594, 3860, 5, 175, 273, 2, 17638, 7083, 108, 3115, 2, 27, 809, 3115, 6938, 43, 150, 5995, 2347, 5, 47459, 4, 98, 9, 86, 10, 143, 12, 2, 3037, 77, 125, 21, 123, 510, 12815, 2, 27, 328, 21, 5995, 1956, 4655, 21739, 3, 5995, 13080, 22, 249, 5, 5866, 187, 269, 4, 1103, 2, 123, 5995, 1956, 4655, 21739, 328, 5, 15748, 42, 8013, 5, 139, 25, 1, 196, 2315, 2, 1127, 512, 5866, 1744, 3860, 848, 5, 17854, 330, 4])
(0, 'x_feature:', [0.0, 0.0, 0.0, 0.0, 0.05263157894736842, 0.0625, 0.0, 0.0, 0.05263157894736842, 0.045454545454545456, 0.0, 0.18181818181818182, 0.0, 0.17647058823529413, 0.0, 0.06666666666666667, 0.4166666666666667, 0.1, 0.0, 0.08333333333333333, 0.0625, 0.07142857142857142, 0.0, 0.0, 0.09090909090909091, 0.1, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u6c61\u67d3\u73af\u5883'])
(0, '#######transform_data_to_index.accusation_list(index):', [194])
(0, '#######transform_data_to_index.article_list(string):', [u'338'])
(0, '#######transform_data_to_index.article_list(index):', [90])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.886 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 897, 2, 220, 9, 49, 10, 5, 240, 2, 6, 614, 11, 1368, 10035, 1, 23916, 2251, 1, 2630, 14953, 599, 3264, 93, 19, 2045, 581, 12221, 199, 62, 14, 1700, 2760, 11519, 199, 2, 27, 33, 109, 199, 6812, 26, 955, 5, 441, 10035, 7443, 1034, 3027, 48, 3213, 806, 980, 20146, 144, 4, 55, 9, 58, 10, 46, 12, 2839, 2, 111, 386, 33764, 74, 614, 5, 2884, 187, 746, 2, 11, 980, 5, 20146, 144, 2532, 19, 16116, 11519, 199, 3, 14, 1700, 2760, 11519, 199, 4, 17, 32, 2, 831, 5, 19, 16116, 11519, 199, 234, 246, 1408, 24392, 2, 47, 1625, 25, 71001, 2102, 3506, 2, 140, 25, 621, 4, 831, 5, 2760, 11519, 199, 246, 100, 48, 2573, 4604, 2, 140, 25, 5573, 4, 25, 1062, 109, 18, 2, 29, 28, 84, 376, 309, 21, 520, 34, 30, 14, 1042, 927, 2660, 13, 5, 69, 2, 81, 105, 11, 1307, 2884, 20146, 144, 2532, 19, 2045, 1408, 24392, 62, 14, 1573, 5573, 2, 1307, 3349, 27, 5700, 4, 19, 1042, 65, 325, 60, 3, 638, 3, 65, 102, 2, 81, 1697, 1368, 10035, 7443, 1034, 3027, 48, 3213, 806, 5, 752, 175, 4, 17, 325, 2, 65, 328, 19, 16116, 11519, 199, 3, 14, 1700, 2760, 11519, 199, 4, 46, 1042, 1675, 135, 453, 2, 81, 831, 5, 19, 16116, 11519, 199, 234, 246, 1408, 24392, 2, 47, 1625, 25, 71001, 2102, 3506, 2, 358, 2102, 100, 48, 2573, 4604, 2, 140, 25, 621, 40, 831, 5, 2760, 11519, 199, 246, 100, 48, 2573, 4604, 2, 140, 25, 5573, 4, 58, 1042, 186, 107, 2, 55, 9, 58, 10, 46, 12, 2839, 2, 37730, 3355, 111, 386, 42431, 4844, 5, 2352, 11, 1368, 10035, 7443, 1034, 3027, 48, 74, 9328, 703, 279, 256, 1136, 317, 5438, 5, 756, 23, 614, 24, 2, 20, 11, 614, 2441, 5, 7443, 1034, 3027, 48, 3213, 806, 20146, 144, 125, 19, 604, 556, 1408, 3560, 5, 4766, 62, 14, 772, 402, 2760, 4, 49, 1042, 156, 189, 3, 199, 102, 2, 81, 105, 108, 887, 846, 156, 21, 19, 2045, 1408, 24392, 3, 14, 1573, 5573, 23, 77667, 527, 24, 4, 83, 1042, 159, 87, 2, 81, 6, 614, 5, 15829, 663, 184, 43, 2826, 4, 80, 1042, 245, 270, 3, 3203, 2, 87, 10884, 856, 4844, 614, 317, 798, 14415, 5, 188, 4, 89, 1042, 471, 5, 1408, 24392, 19, 2045, 3, 5573, 14, 1573, 4, 97, 1042, 6, 614, 5, 44, 3, 214, 43, 177, 60, 2, 128, 44, 26, 33, 1, 5, 19, 604, 621, 62, 14, 1700, 2760, 6812, 980, 20146, 144, 2, 1884, 55, 9, 58, 10, 46, 12, 2839, 37, 111, 471, 4, 27, 3516, 441, 1368, 10035, 7443, 1034, 3027, 48, 3213, 806, 980, 1449, 659, 9127, 20146, 2756, 243, 29479, 3, 2760, 5, 717, 4, 461, 2, 29, 28, 64, 6, 614, 317, 798, 621, 19, 2045, 2, 1765, 2, 26, 61, 271, 21, 51, 68, 78, 50, 7, 7, 7, 7, 5, 71, 2, 130, 21, 317, 798, 2301, 4, 27, 210, 11, 7, 7, 38, 1100, 5, 1263, 70, 498, 4, 194, 115, 116, 460, 4, 11, 376, 144, 2, 6, 614, 214, 243, 3264, 93, 5, 246, 6467, 5, 21031, 199, 2, 74807, 6049, 2, 237, 327, 140, 25, 621, 2, 2416, 237, 9817, 40, 29, 28, 5, 498, 210, 11497, 4, 985, 652, 520, 1809, 197, 30, 14, 3, 471, 5, 4473, 12221, 199, 63973, 22164, 20, 2947, 4765, 5573, 2, 2102, 14484, 2760, 2, 397, 6049, 2, 2416, 237, 705, 621, 40, 19, 3, 22594, 140, 246, 621, 2, 6, 614, 694, 246, 868, 3, 2467, 6078, 713, 2, 4014, 17547, 237, 696, 2, 394, 1715, 40, 46, 3, 614, 246, 2861, 2, 2098, 813, 2, 22491, 24970, 40, 58, 3, 210, 11, 1620, 343, 498, 2, 27, 574, 7, 7, 4])
(0, 'x_feature:', [0.14285714285714285, 0.0, 0.07142857142857142, 0.16666666666666666, 0.05263157894736842, 0.3125, 0.0, 0.15789473684210525, 0.10526315789473684, 0.09090909090909091, 0.16666666666666666, 0.09090909090909091, 0.15384615384615385, 0.17647058823529413, 0.0625, 0.06666666666666667, 0.3333333333333333, 0.0, 0.0, 0.0, 0.125, 0.07142857142857142, 0.16666666666666666, 0.0, 0.18181818181818182, 0.1, 0.09090909090909091, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u6301\u6709\u3001\u79c1\u85cf\u67aa\u652f\u3001\u5f39\u836f'])
(0, '#######transform_data_to_index.accusation_list(index):', [119])
(0, '#######transform_data_to_index.article_list(string):', [u'128'])
(0, '#######transform_data_to_index.article_list(index):', [7])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.845 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 2, 73, 9, 83, 10, 38, 181, 9, 19, 817, 2, 6, 411, 10673, 937, 1, 2, 11, 5968, 144, 265, 5163, 19410, 2838, 62, 776, 4665, 22217, 3082, 4, 181, 9, 83, 10, 143, 12, 2, 6, 558, 1091, 111, 313, 972, 2, 306, 602, 109, 621, 93, 1780, 77, 8731, 408, 281, 4, 17, 32, 30, 109, 5163, 19410, 37757, 6689, 1625, 25, 1686, 2102, 3506, 5, 621, 40, 4665, 22217, 3082, 6689, 3303, 25, 1686, 2102, 3506, 5, 621, 4, 276, 20, 2, 6, 411, 128, 44, 109, 118, 4, 815, 64, 2, 6, 411, 485, 621, 508, 71, 2, 317, 798, 621, 2, 1765, 2, 26, 61, 327, 47, 317, 798, 2301, 548, 114, 4, 6, 411, 276, 20, 874, 281, 2, 128, 44, 155, 5, 360, 2, 298, 470, 2, 358, 278, 789, 933, 183, 4, 194, 115, 116, 104, 4, 94, 2, 6, 411, 11, 161, 101, 42, 167, 131, 2, 166, 1108, 322, 928, 3, 468, 5, 67, 753, 5, 69, 40, 621, 22, 252, 40, 159, 87, 3, 186, 107, 3, 156, 236, 3, 156, 189, 3, 2666, 199, 189, 3, 175, 245, 40, 1780, 77, 252, 32, 169, 453, 40, 328, 60, 3, 156, 60, 3, 746, 60, 3, 102, 573, 6, 411, 5, 44, 41, 214, 22, 34, 81, 2, 132, 4, 985, 652, 6, 411, 5, 61, 130, 470, 2, 116, 7728, 26, 278, 923, 933, 183, 40, 265, 621, 5, 19977, 7103, 42846, 2, 4014, 6026, 1451, 647, 40, 2658, 208, 621, 2, 76, 1451, 713, 5, 2467, 2043, 40, 298, 2861, 3, 5197, 40, 394, 399, 1451, 5565, 2, 805, 574, 7, 7, 1703, 2, 569, 74, 6, 411, 933, 789, 278, 183, 27, 574, 7, 7, 22, 1809, 197, 4])
(0, 'x_feature:', [0.42857142857142855, 0.0, 0.07142857142857142, 0.08333333333333333, 0.10526315789473684, 0.25, 0.0, 0.15789473684210525, 0.05263157894736842, 0.045454545454545456, 0.08333333333333333, 0.09090909090909091, 0.15384615384615385, 0.11764705882352941, 0.125, 0.06666666666666667, 0.16666666666666666, 0.2, 0.0, 0.08333333333333333, 0.0625, 0.07142857142857142, 0.08333333333333333, 0.0, 0.0, 0.1, 0.09090909090909091, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u6301\u6709\u3001\u79c1\u85cf\u67aa\u652f\u3001\u5f39\u836f'])
(0, '#######transform_data_to_index.accusation_list(index):', [119])
(0, '#######transform_data_to_index.article_list(string):', [u'128'])
(0, '#######transform_data_to_index.article_list(index):', [7])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.832 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1020, 4914, 45, 18, 30, 1049, 9, 49, 10, 2, 6, 223, 7181, 268, 1694, 1, 91319, 207, 23, 343, 897, 30, 1694, 168, 24, 413, 2, 809, 13220, 27888, 20809, 2, 619, 1694, 168, 7715, 5, 12495, 11644, 1415, 5, 9363, 10979, 3, 1534, 10245, 2, 27, 11, 84, 1381, 13, 168, 61921, 20, 2, 33, 12495, 1415, 5, 8232, 62, 1534, 1144, 16003, 1, 1281, 784, 820, 2258, 168, 23, 343, 897, 30, 1, 168, 24, 2, 174, 1, 168, 84, 109, 1694, 5250, 1850, 1534, 4, 365, 9, 86, 10, 38, 98, 9, 100, 817, 2, 6, 223, 390, 10245, 12495, 11599, 3, 9363, 5, 567, 735, 2, 291, 6520, 521, 1415, 9363, 895, 2, 27, 33, 26, 1592, 385, 8, 1028, 25, 1381, 13, 168, 7716, 47417, 209, 5, 262, 2, 33, 109, 6520, 5, 895, 291, 1, 168, 1850, 38, 385, 8, 2604, 5, 484, 70, 2, 4394, 4082, 168, 5, 714, 4, 57, 9, 14, 10, 38, 57, 9, 97, 817, 2, 6, 223, 1028, 21, 327, 174, 12495, 1415, 937, 374, 5, 6453, 521, 234, 174, 1381, 13, 168, 374, 5, 188, 2, 3379, 11, 10245, 12495, 11599, 101, 42, 2, 6520, 168, 25, 1415, 2814, 5, 6453, 895, 2, 27, 33, 26, 1592, 385, 8, 3, 1341, 324, 8, 1028, 25, 1381, 13, 168, 7716, 47417, 209, 2, 33, 1381, 13, 168, 109, 895, 1055, 1534, 291, 1, 168, 1850, 38, 385, 8, 3, 324, 8, 2604, 5, 484, 70, 2, 4394, 4082, 168, 5, 714, 4, 17, 6246, 2, 6, 223, 291, 109, 262, 4082, 1694, 168, 714, 170, 31, 30122, 2, 932, 15, 4, 142, 2, 223, 306, 84, 1381, 13, 168, 235, 209, 3066, 21, 109, 118, 2, 2298, 57, 9, 100, 10, 452, 750, 105, 281, 2, 109, 1312, 223, 66, 6523, 1185, 4, 29, 28, 140, 6, 223, 5, 61, 202, 21, 51, 68, 78, 50, 7, 7, 7, 7, 110, 71, 2, 124, 47, 7, 7, 137, 114, 4, 6, 324, 880, 470, 2, 386, 78, 7, 7, 7, 7, 110, 71, 2, 358, 933, 183, 4, 223, 66, 1185, 208, 351, 2, 358, 2015, 278, 183, 4, 194, 116, 3474, 4])
(0, 'x_feature:', [0.3333333333333333, 0.0, 0.14285714285714285, 0.08333333333333333, 0.10526315789473684, 0.0625, 0.0, 0.0, 0.05263157894736842, 0.13636363636363635, 0.0, 0.2727272727272727, 0.15384615384615385, 0.11764705882352941, 0.0625, 0.0, 0.3333333333333333, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.18181818181818182, 0.09090909090909091])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u804c\u52a1\u4fb5\u5360'])
(0, '#######transform_data_to_index.accusation_list(index):', [201])
(0, '#######transform_data_to_index.article_list(string):', [u'271'])
(0, '#######transform_data_to_index.article_list(index):', [176])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.862 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 30, 365, 9, 80, 3, 89, 304, 5, 240, 2, 377, 41, 126, 14, 13, 23, 234, 37, 514, 24, 34655, 36, 2, 377, 652, 2137, 265, 621, 2, 126, 14, 13, 539, 63, 14, 13, 23, 66, 514, 24, 1179, 4, 63, 14, 13, 18547, 27, 539, 6, 1756, 13, 2078, 26, 440, 621, 10627, 2, 20, 6, 1756, 13, 539, 223, 23, 66, 514, 24, 1179, 1, 4, 223, 440, 93, 3581, 6808, 621, 10627, 2, 1099, 10627, 6, 1756, 13, 22, 82, 835, 265, 621, 2, 27, 150, 10627, 2059, 129, 6, 1756, 13, 539, 26, 4909, 112, 4, 6, 3827, 291, 313, 41, 10627, 440, 20, 2, 33, 4909, 5, 112, 21853, 63, 14, 13, 2, 63, 14, 13, 568, 518, 4, 2750, 14, 13, 2311, 6, 3827, 3, 6646, 23, 663, 3546, 24, 596, 1102, 3581, 265, 621, 4, 6, 1756, 13, 41, 10627, 440, 2208, 421, 4983, 2, 2750, 14, 13, 11, 3581, 6808, 78502, 783, 47, 31, 4165, 15, 5, 112, 2200, 3560, 4473, 62, 2760, 1, 4, 126, 14, 13, 33, 497, 1345, 3560, 62, 62914, 2760, 801, 377, 20, 742, 1, 31, 2270, 15, 2, 391, 1345, 2838, 3678, 524, 20, 16927, 4, 20, 1756, 13, 292, 741, 440, 10627, 2, 150, 11919, 4983, 2, 10627, 292, 4737, 1, 2760, 2, 63, 14, 13, 266, 2760, 20, 801, 377, 4, 220, 9, 46, 10, 49, 12, 2, 377, 602, 3560, 23, 847, 2760, 31855, 24, 11, 1020, 4007, 25733, 195, 25733, 2266, 37, 111, 91, 4, 17, 32, 2, 123, 3560, 47, 1625, 25, 1686, 2, 358, 2102, 91662, 5, 52, 4614, 1094, 53, 75, 10364, 16784, 2, 74, 541, 457, 1641, 3190, 4, 391, 99, 2, 1756, 555, 220, 9, 58, 10, 393, 12, 37, 105, 11, 1343, 8398, 91, 4, 186, 20, 2, 6, 3827, 128, 44, 21, 155, 5, 118, 4, 109, 118, 2, 6, 1756, 13, 11, 161, 101, 42, 167, 131, 2, 27, 76, 1343, 8398, 29746, 77, 51726, 334, 260, 5, 6, 1756, 13, 5, 159, 87, 3, 1037, 55424, 667, 267, 395, 3, 1037, 3246, 2261, 1427, 816, 3, 115, 267, 395, 3, 1281, 4905, 957, 267, 395, 22, 173, 40, 287, 5, 894, 9646, 223, 3, 63, 14, 13, 3, 377, 3, 126, 14, 13, 5, 44, 40, 224, 3890, 67, 59, 3, 524, 5, 69, 40, 6, 1756, 13, 5, 44, 40, 2172, 77, 252, 32, 169, 260, 5, 621, 3, 5573, 453, 40, 746, 60, 41, 177, 60, 11820, 495, 107, 3, 91, 107, 3, 175, 245, 3, 156, 199, 3, 1047, 189, 22, 11, 1662, 34, 1762, 2, 132, 4])
(0, 'x_feature:', [0.09523809523809523, 0.0, 0.0, 0.08333333333333333, 0.0, 0.3125, 0.0, 0.15789473684210525, 0.05263157894736842, 0.045454545454545456, 0.25, 0.09090909090909091, 0.07692307692307693, 0.23529411764705882, 0.125, 0.06666666666666667, 0.25, 0.3, 0.0, 0.0, 0.0625, 0.07142857142857142, 0.25, 0.0, 0.0, 0.1, 0.09090909090909091, 0.09090909090909091])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u5236\u9020\u3001\u4e70\u5356\u3001\u8fd0\u8f93\u3001\u90ae\u5bc4\u3001\u50a8\u5b58\u67aa\u652f\u3001\u5f39\u836f\u3001\u7206\u70b8\u7269'])
(0, '#######transform_data_to_index.accusation_list(index):', [22])
(0, '#######transform_data_to_index.article_list(string):', [u'125'])
(0, '#######transform_data_to_index.article_list(index):', [101])
Loading model cost 0.810 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [13115, 45, 18, 2, 6, 310, 54, 120, 57, 9, 49, 10, 1012, 317, 798, 1345, 621, 2, 27, 33, 621, 1746, 108, 26, 441, 1622, 41358, 153, 9171, 244, 5, 226, 4, 57, 9, 89, 10, 232, 12, 2, 41358, 334, 111, 116, 74, 6, 310, 4596, 187, 282, 36, 2, 120, 26, 226, 125, 123, 621, 43, 2760, 1491, 4, 17, 32, 2, 6, 310, 54, 798, 5, 621, 6689, 1625, 25, 1686, 5, 621, 4, 57, 9, 89, 10, 248, 12, 2, 6, 310, 54, 306, 93, 41358, 153, 334, 281, 2, 27, 128, 44, 21, 155, 5, 360, 4])
(0, 'x_feature:', [0.19047619047619047, 0.0, 0.07142857142857142, 0.08333333333333333, 0.05263157894736842, 0.0, 0.0, 0.15789473684210525, 0.05263157894736842, 0.09090909090909091, 0.08333333333333333, 0.0, 0.07692307692307693, 0.17647058823529413, 0.0625, 0.06666666666666667, 0.08333333333333333, 0.0, 0.0, 0.0, 0.0625, 0.07142857142857142, 0.0, 0.0, 0.09090909090909091, 0.0, 0.0, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u975e\u6cd5\u6301\u6709\u3001\u79c1\u85cf\u67aa\u652f\u3001\u5f39\u836f'])
(0, '#######transform_data_to_index.accusation_list(index):', [119])
(0, '#######transform_data_to_index.article_list(string):', [u'128'])
(0, '#######transform_data_to_index.article_list(index):', [7])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 1.224 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [1376, 6527, 45, 18, 30, 57, 9, 100, 10, 398, 12, 336, 2, 6, 1691, 8, 11, 219, 6527, 8065, 12212, 1005, 12814, 14, 945, 723, 475, 16, 3770, 8, 4346, 2, 299, 16, 506, 779, 2, 258, 16, 3770, 8, 3567, 1045, 5, 3479, 6857, 14, 63, 2, 4670, 1938, 38, 219, 6527, 8065, 12212, 4641, 3, 2966, 37243, 2134, 3, 20501, 1879, 22, 559, 5, 2237, 1743, 2, 318, 1906, 3821, 148, 1384, 31, 43566, 15, 2, 27, 38, 219, 6527, 36414, 1, 630, 3, 36414, 1387, 6356, 630, 930, 1938, 2867, 1161, 1384, 31, 932, 15, 4, 29, 28, 64, 2, 6, 1691, 8, 5, 61, 66, 130, 7, 7, 4, 1718, 4278, 470, 2, 358, 278, 183, 4, 25, 81, 109, 18, 5, 188, 43, 29, 197, 2, 883, 261, 1208, 21, 6, 1691, 8, 2, 27, 529, 62, 309, 21, 235, 5, 34, 270, 4])
(0, 'x_feature:', [0.14285714285714285, 0.0, 0.0, 0.0, 0.05263157894736842, 0.125, 0.0, 0.0, 0.05263157894736842, 0.045454545454545456, 0.0, 0.0, 0.07692307692307693, 0.11764705882352941, 0.0625, 0.0, 0.08333333333333333, 0.1, 0.0, 0.0, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.0, 0.0, 0.09090909090909091, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u76d7\u7a83'])
(0, '#######transform_data_to_index.accusation_list(index):', [189])
(0, '#######transform_data_to_index.article_list(string):', [u'264', u'196'])
(0, '#######transform_data_to_index.article_list(index):', [57, 73])
('train', 'transform_data_to_index.####################.start.')
('train', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 1.265 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [29, 28, 18, 2, 579, 2223, 2, 6, 126, 8, 1603, 6561, 814, 6578, 1180, 2, 1068, 3733, 8434, 329, 6561, 814, 580, 2, 6, 126, 8, 318, 84, 1924, 8434, 329, 16881, 1434, 1006, 8, 2597, 4, 98, 9, 1272, 537, 2, 6, 126, 8, 47, 7278, 43, 1978, 1474, 2, 718, 26, 75, 257, 148, 4, 57, 9, 1272, 537, 2, 6, 126, 8, 120, 155, 5117, 5151, 84, 1006, 8, 900, 1188, 8, 150, 5, 484, 42, 5364, 201, 257, 2, 684, 33, 1938, 643, 1188, 8, 2, 27, 33, 5364, 465, 1099, 21, 1006, 8, 3, 1188, 8, 4, 55, 9, 1272, 537, 2, 6, 126, 8, 47, 7278, 43, 1978, 1006, 8, 1474, 2, 11, 1006, 8, 226, 718, 26, 14, 257, 148, 4, 140, 94, 5, 34, 76, 30, 173, 3, 67, 69, 3, 6, 44, 41, 214, 22, 34, 81, 4, 29, 28, 64, 2, 6, 126, 8, 1068, 1330, 237, 2648, 1063, 2, 84, 512, 671, 2597, 403, 257, 2, 26, 61, 271, 51, 68, 78, 50, 7, 7, 3, 7, 7, 110, 71, 2, 118, 312, 2, 34, 302, 3, 297, 2, 124, 47, 7, 7, 137, 114, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.0, 0.0, 0.05263157894736842, 0.25, 0.0, 0.0, 0.10526315789473684, 0.045454545454545456, 0.0, 0.0, 0.07692307692307693, 0.17647058823529413, 0.0, 0.06666666666666667, 0.16666666666666666, 0.0, 0.0, 0.4166666666666667, 0.0, 0.0, 0.08333333333333333, 0.0, 0.0, 0.0, 0.18181818181818182, 0.18181818181818182])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u884c\u8d3f'])
(0, '#######transform_data_to_index.accusation_list(index):', [65])
(0, '#######transform_data_to_index.article_list(string):', [u'390', u'389'])
(0, '#######transform_data_to_index.article_list(index):', [117, 148])
Loading model cost 1.016 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 30, 57, 9, 49, 10, 38, 80, 10, 2, 6, 20950, 13, 11, 6904, 27711, 44019, 21875, 3599, 3854, 48, 26, 226, 2, 357, 58, 664, 350, 72, 3, 20950, 19, 13, 22, 82, 427, 190, 23, 1118, 52, 225, 53, 24, 4, 616, 118, 1579, 520, 30, 14, 3, 57, 9, 49, 10, 1070, 5, 240, 479, 2, 6, 20950, 13, 11, 226, 350, 20950, 19, 13, 3, 20950, 14, 13, 427, 225, 14, 664, 4, 19, 3, 57, 9, 83, 10, 1070, 5, 240, 479, 2, 6, 20950, 13, 11, 226, 350, 20950, 19, 13, 3, 20950, 14, 13, 3, 72, 427, 225, 14, 664, 4, 46, 3, 57, 9, 83, 10, 1560, 5, 240, 479, 2, 6, 20950, 13, 11, 226, 350, 20950, 19, 13, 3, 20950, 14, 13, 3, 72, 427, 225, 14, 664, 4, 58, 3, 57, 9, 80, 10, 19, 12, 479, 2, 6, 20950, 13, 11, 226, 350, 79, 1, 225, 14, 664, 4, 57, 9, 80, 10, 83, 12, 2, 6, 20950, 13, 164, 275, 2655, 37, 105, 2252, 204, 2, 128, 44, 21, 3561, 1642, 2299, 5, 26, 350, 206, 275, 5, 188, 4, 74, 94, 2, 6, 20950, 13, 11, 161, 101, 42, 167, 131, 2, 166, 76, 6, 20950, 13, 5, 44, 40, 67, 72, 3, 20950, 19, 13, 3, 20950, 14, 13, 22, 82, 5, 69, 40, 173, 1173, 184, 950, 3, 276, 175, 245, 3, 504, 236, 3, 65, 269, 546, 40, 177, 60, 43, 235, 102, 22, 34, 191, 81, 2, 132, 4])
(0, 'x_feature:', [0.14285714285714285, 0.0, 0.0, 0.0, 0.05263157894736842, 0.3125, 0.0, 0.05263157894736842, 0.10526315789473684, 0.0, 0.0, 0.09090909090909091, 0.07692307692307693, 0.058823529411764705, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.0, 0.1, 0.09090909090909091, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u5bb9\u7559\u4ed6\u4eba\u5438\u6bd2'])
(0, '#######transform_data_to_index.accusation_list(index):', [11])
(0, '#######transform_data_to_index.article_list(string):', [u'357', u'354'])
(0, '#######transform_data_to_index.article_list(index):', [54, 105])
('####################freq_accusation:', 781, 'freq_article:', 749, ';num_copy:', 3)
('####################freq_accusation:', 550, 'freq_article:', 6520, ';num_copy:', 3)
('####################freq_accusation:', 1325, 'freq_article:', 8091, ';num_copy:', 3)
('####################freq_accusation:', 1037, 'freq_article:', 1819, ';num_copy:', 3)
('####################freq_accusation:', 530, 'freq_article:', 470, ';num_copy:', 4)
('####################freq_accusation:', 148, 'freq_article:', 301, ';num_copy:', 8)
('####################freq_accusation:', 1003, 'freq_article:', 1007, ';num_copy:', 3)
('####################freq_accusation:', 313, 'freq_article:', 312, ';num_copy:', 6)
('####################freq_accusation:', 1003, 'freq_article:', 1007, ';num_copy:', 3)
('####################freq_accusation:', 123320, 'freq_article:', 985, ';num_copy:', 3)
('####################freq_accusation:', 1037, 'freq_article:', 1819, ';num_copy:', 3)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('####################freq_accusation:', 460, 'freq_article:', 462, ';num_copy:', 4)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('####################freq_accusation:', 919, 'freq_article:', 985, ';num_copy:', 3)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('####################freq_accusation:', 158, 'freq_article:', 363, ';num_copy:', 7)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('train', 'i:', 10000)
('####################freq_accusation:', 1430, 'freq_article:', 1473, ';num_copy:', 3)
('train', 'i:', 10000)
('####################freq_accusation:', 1037, 'freq_article:', 1819, ';num_copy:', 3)
('train', 'i:', 10000)
('####################freq_accusation:', 851, 'freq_article:', 849, ';num_copy:', 3)
('train', 'i:', 10000)
('####################freq_accusation:', 287, 'freq_article:', 498310, ';num_copy:', 3)
('####################freq_accusation:', 461, 'freq_article:', 471, ';num_copy:', 4)
('####################freq_accusation:', 76, 'freq_article:', 78, ';num_copy:', 10)
('####################freq_accusation:', 919, 'freq_article:', 985, ';num_copy:', 3)
('####################freq_accusation:', 550, 'freq_article:', 6520, ';num_copy:', 3)
('####################freq_accusation:', 1140, 'freq_article:', 1146, ';num_copy:', 3)
('####################freq_accusation:', 1003, 'freq_article:', 1007, ';num_copy:', 3)
('####################freq_accusation:', 252, 'freq_article:', 259, ';num_copy:', 7)
('####################freq_accusation:', 427, 'freq_article:', 5514, ';num_copy:', 3)
('####################freq_accusation:', 1140, 'freq_article:', 1146, ';num_copy:', 3)
('####################freq_accusation:', 530, 'freq_article:', 2538, ';num_copy:', 3)
('####################freq_accusation:', 1140, 'freq_article:', 1146, ';num_copy:', 3)
('####################freq_accusation:', 698, 'freq_article:', 976, ';num_copy:', 3)
('####################freq_accusation:', 1096, 'freq_article:', 5514, ';num_copy:', 3)
('####################freq_accusation:', 400, 'freq_article:', 388, ';num_copy:', 5)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('####################freq_accusation:', 792, 'freq_article:', 3693, ';num_copy:', 3)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('####################freq_accusation:', 1359, 'freq_article:', 1348, ';num_copy:', 3)
(('train', 'i:', 20000)
'train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('train', 'i:', 20000)
('####################freq_accusation:', 1096, 'freq_article:', 5514, ';num_copy:', 3)
('train', 'i:', 20000)
('####################freq_accusation:', 948, 'freq_article:', 933, ';num_copy:', 3)
('####################freq_accusation:', 285, 'freq_article:', 357, ';num_copy:', 6)
('train', 'i:', 20000)
('train', 'i:', 20000)
('####################freq_accusation:', 431, 'freq_article:', 478, ';num_copy:', 4)
('####################freq_accusation:', 158, 'freq_article:', 363, ';num_copy:', 7)
('####################freq_accusation:', 948, 'freq_article:', 933, ';num_copy:', 3)
('####################freq_accusation:', 851, 'freq_article:', 849, ';num_copy:', 3)
('####################freq_accusation:', 767, 'freq_article:', 817, ';num_copy:', 3)
('####################freq_accusation:', 1589, 'freq_article:', 1597, ';num_copy:', 3)
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_6.pik')
('####################freq_accusation:', 7476, 'freq_article:', 121, ';num_copy:', 3)
('####################freq_accusation:', 1470, 'freq_article:', 1098, ';num_copy:', 3)
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_8.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_1.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_5.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_11.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_12.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_2.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_19.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_16.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_13.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_3.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_9.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_0.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_14.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_15.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_4.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_17.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_10.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_18.pik')
('train', '#########################finished.transform_data_to_index')
('train', '####################going to dump file:', 'cache_text_cnn/training_data_temp_7.pik')
finish reduce stage...
('valid', 'transform_data_to_index.####################.start.')
('valid', 'i:', 0)
Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
Loading model cost 0.243 seconds.
Prefix dict has been built succesfully.
(0, '#######transform_data_to_index.x:', [17, 106, 99, 30, 57, 9, 75, 304, 1576, 2, 6, 853, 54, 291, 9021, 3, 23032, 3, 1123, 22, 262, 33, 4561, 16457, 70, 5, 2471, 765, 469, 129, 2606, 30898, 4, 497, 2, 55, 9, 14, 10, 201, 12, 2, 853, 54, 291, 9021, 2049, 47, 200, 15, 5, 112, 33, 1746, 2471, 765, 5, 4561, 16457, 10286, 62, 1950, 469, 129, 30898, 231, 8892, 2, 20, 292, 291, 23032, 1, 30898, 150, 2471, 765, 12969, 2, 2079, 30898, 328, 6170, 11, 155, 5, 4561, 16457, 42, 4, 11, 255, 13, 5, 4561, 16457, 42, 2, 105, 7949, 21, 497, 5, 1413, 496, 7667, 2, 17, 32, 497, 32491, 496, 7667, 305, 4075, 4, 391, 99, 2, 6, 853, 54, 186, 20, 128, 44, 21, 155, 5, 360, 4, 330, 188, 2, 6, 853, 54, 11, 322, 101, 42, 167, 131, 2, 27, 76, 67, 853, 95, 3, 72, 3, 603, 3, 231, 5, 69, 2, 746, 60, 43, 102, 2, 421, 406, 2, 518, 34, 189, 2, 10940, 290, 282, 413, 406, 2, 4075, 2252, 453, 2, 91, 107, 2, 175, 245, 2, 709, 752, 184, 2, 156, 236, 43, 189, 2, 1833, 2952, 22, 34, 81, 2, 132, 4])
(0, 'x_feature:', [0.09523809523809523, 0.0, 0.07142857142857142, 0.0, 0.0, 0.3125, 0.0, 0.10526315789473684, 0.05263157894736842, 0.045454545454545456, 0.0, 0.09090909090909091, 0.07692307692307693, 0.11764705882352941, 0.0625, 0.0, 0.16666666666666666, 0.1, 0.0, 0.0, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.0, 0.2, 0.18181818181818182, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u5236\u9020\u3001\u8d29\u5356\u3001\u4f20\u64ad\u6deb\u79fd\u7269\u54c1', u'\u5236\u4f5c\u3001\u590d\u5236\u3001\u51fa\u7248\u3001\u8d29\u5356\u3001\u4f20\u64ad\u6deb\u79fd\u7269\u54c1\u725f\u5229'])
(0, '#######transform_data_to_index.accusation_list(index):', [35, 107])
(0, '#######transform_data_to_index.article_list(string):', [363])
(0, '#######transform_data_to_index.article_list(index):', [131])
('valid', 'i:', 10000)
('valid', '#########################finished.transform_data_to_index')
('test', 'transform_data_to_index.####################.start.')
('test', 'i:', 0)
(0, '#######transform_data_to_index.x:', [17, 106, 99, 2, 55, 9, 46, 10, 73, 9, 83, 10, 2, 6, 524, 291, 3528, 423, 6743, 25, 52, 1958, 19684, 53, 62, 52, 7470, 1644, 2880, 6965, 30661, 53, 5, 4563, 9021, 2514, 2, 2606, 469, 4651, 79467, 5, 19684, 4282, 62, 2471, 4282, 2135, 4, 55, 9, 100, 10, 2, 6, 524, 291, 52, 7470, 1644, 2880, 6965, 30661, 53, 84, 16855, 5, 912, 13, 832, 21, 2471, 4282, 1629, 63, 62, 52, 1, 53, 4282, 1764, 63, 4, 73, 9, 46, 10, 4, 6, 524, 292, 291, 52, 1958, 19684, 53, 20844, 13, 832, 21, 1764, 63, 2471, 4282, 4, 736, 15827, 846, 33410, 21, 2471, 4282, 20, 4, 33, 1392, 1167, 12383, 93, 155, 5, 8956, 144, 502, 2357, 469, 4, 80885, 13, 177, 62, 105, 32, 2, 524, 442, 832, 129, 912, 13, 6524, 63, 2471, 27237, 4, 55, 9, 46, 10, 38, 73, 9, 83, 10, 2, 6, 524, 291, 5838, 41, 3098, 9592, 5, 549, 440, 2, 27, 318, 832, 2471, 1392, 129, 549, 4, 73, 9, 83, 10, 2, 105, 74, 549, 169, 265, 5, 2471, 1392, 187, 32, 2, 140, 497, 12048, 29997, 2471, 1392, 4, 330, 188, 2, 6, 524, 11, 161, 101, 42, 167, 131, 2, 166, 76, 709, 184, 3, 276, 245, 3, 103, 4209, 3, 9717, 421, 189, 22, 173, 40, 67, 736, 3, 549, 5, 69, 2798, 6, 524, 5, 44, 41, 214, 2798, 4075, 32, 197, 2798, 1208, 1392, 22, 34, 81, 2, 132, 4])
(0, 'x_feature:', [0.047619047619047616, 0.0, 0.21428571428571427, 0.0, 0.05263157894736842, 0.3125, 0.058823529411764705, 0.15789473684210525, 0.05263157894736842, 0.045454545454545456, 0.0, 0.09090909090909091, 0.15384615384615385, 0.11764705882352941, 0.0625, 0.13333333333333333, 0.16666666666666666, 0.3, 0.0, 0.0, 0.0, 0.07142857142857142, 0.08333333333333333, 0.0, 0.0, 0.1, 0.18181818181818182, 0.0])
(0, '#######transform_data_to_index.accusation_list(string):', [u'\u5236\u9020\u3001\u8d29\u5356\u3001\u4f20\u64ad\u6deb\u79fd\u7269\u54c1', u'\u5236\u4f5c\u3001\u590d\u5236\u3001\u51fa\u7248\u3001\u8d29\u5356\u3001\u4f20\u64ad\u6deb\u79fd\u7269\u54c1\u725f\u5229'])
(0, '#######transform_data_to_index.accusation_list(index):', [35, 107])
(0, '#######transform_data_to_index.article_list(string):', [363])
(0, '#######transform_data_to_index.article_list(index):', [131])
('test', 'i:', 10000)
('test', 'i:', 20000)
('test', 'i:', 30000)
('test', '#########################finished.transform_data_to_index')
going to dump train/valid/test data to file sytem!
('length of training data:', 646126, ';valid data:', 13094, ';test data:', 32508, ';feature_length:', 28)
('trainX_[0]:', array([    0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,     0,     0,
           0,     0,     0,     0,     0,     0,     0,  2227, 16480,
          45,    18,     2,   855,     9,    14,    10,    38,   220,
           9,    14,    10,     2,     6,    63,     8,    11,   809,
        2227,  3193,  1569, 16480,   408,  4869,  2489,   204,     2,
         108,   579,     9,    58,    10,   279, 16480, 62894,   153,
        6716,   169,  5064,    79,     8,    23,    66,   514,    24,
        5695,  1258,  1850,    51,  8325,  6297,    50,     5,    61,
          20,     2,  3781,    58,    13,   483,     4,   365,     9,
          89,    10,     2,     6,    63,     8,  4862,  1429,   585,
        4755, 36011,     5,   686,  1434,    96,    33,    79,     8,
         317,   493,     5,  4818,  5391,   946, 11268, 50617,     2,
       22655,   521,  4818,  1283,    37, 15590,    93, 30647,  1083,
           5, 48558,    70,     2, 66837,     1,     4,     6,    63,
           8,   261,   568, 15192,   957,   598,    40,    26,   985,
         261,  3642,     2,    14,     3,     6,    63,     8,  3781,
           8,     1, 97563,  1501,  4818,  6297,     5,  2393, 65245,
       20905,     2,    63,     8, 10673,    74,   413,   619,  4639,
           2,   972, 36011,    33,    79,     8,     5, 27119,  4517,
        3198,  1746,     2,  9850, 22786, 18289,  2653,     3,  4801,
         483,     4,    19,     3,     6,    63,     8,  3781,     8,
         317,  2321,  8325,  6297,     5,    61,  8335,   397, 34883,
        2084,  3727,     2,    11,     6,  2026,  2633,    20,     2,
          33,    79,     8,     1, 97563,     5, 11268, 65004, 50617,
         694,   246,  9067,  1976,  3205,     4,    46,     3,    79,
           8,     5,    61,   169,   198,     5,  4598,    41,     6,
          63,     8,   397, 10896,     4,  1078,     2,    29,    28,
          18,     6,    63,     8,  1134, 13456,     1,     1,     2,
       22594,     6,    63,     8,  2036, 13456,     5,    61,     2,
         694,   305,   399,  4290,     2,   804,    74,     6,    63,
           8,  7182,   267,   183,     4]))
('train_feature_X[0]:', array([ 0.04761905,  0.        ,  0.07142857,  0.        ,  0.10526316,
        0.125     ,  0.        ,  0.05263158,  0.05263158,  0.04545455,
        0.08333333,  0.09090909,  0.07692308,  0.11764706,  0.        ,
        0.06666667,  0.25      ,  0.        ,  0.        ,  0.16666667,
        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,
        0.1       ,  0.        ,  0.        ]))
('train_Y_accusation_short:', [58], [160], [155], [127], [127], ';train_Y_article_short:', [100])
('train_Y_deathpenalty:', array([ 1.,  0.]), ';train_Y_lifeimprisonment:', array([ 1.,  0.]), ';train_Y_imprisonment:', 0.0)
2018-07-14 18:48:38.089106: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:48:38.089153: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:48:38.089161: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:48:38.089167: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:48:38.089173: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-07-14 18:48:38.268430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-07-14 18:48:38.269431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.3285
pciBusID 0000:00:08.0
Total memory: 15.89GiB
Free memory: 15.60GiB
2018-07-14 18:48:38.269470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2018-07-14 18:48:38.269484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2018-07-14 18:48:38.269504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:08.0)
('self.filter_sizes:', [2, 3, 4, 5], ';self.num_filters:', 256, '; self.stride_length:', 1)
('self.single_sequence_length:', 31, ';self.total_sequence_length:', 500, ';self.num_sentences:', 16)
('model====>:', 'text_cnn')
going to use model:text cnn model
(0, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-2/cnn1/batchnorm/add_1:0' shape=(128, 499, 1, 256) dtype=float32>)
(0, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-2/cnn2/batchnorm/add_1:0' shape=(128, 498, 1, 256) dtype=float32>)
(0, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-2/Squeeze:0' shape=(128, 256) dtype=float32>)
(1, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-3/cnn1/batchnorm/add_1:0' shape=(128, 498, 1, 256) dtype=float32>)
(1, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-3/cnn2/batchnorm/add_1:0' shape=(128, 496, 1, 256) dtype=float32>)
(1, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-3/Squeeze:0' shape=(128, 256) dtype=float32>)
(2, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-4/cnn1/batchnorm/add_1:0' shape=(128, 497, 1, 256) dtype=float32>)
(2, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-4/cnn2/batchnorm/add_1:0' shape=(128, 494, 1, 256) dtype=float32>)
(2, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-4/Squeeze:0' shape=(128, 256) dtype=float32>)
(3, 'conv1:', <tf.Tensor 'conv_layerconvolution-pooling-5/cnn1/batchnorm/add_1:0' shape=(128, 496, 1, 256) dtype=float32>)
(3, 'conv2:', <tf.Tensor 'conv_layerconvolution-pooling-5/cnn2/batchnorm/add_1:0' shape=(128, 492, 1, 256) dtype=float32>)
(3, 'pooling:', <tf.Tensor 'conv_layerconvolution-pooling-5/Squeeze:0' shape=(128, 256) dtype=float32>)
('h.concat:', <tf.Tensor 'concat:0' shape=(128, 1024) dtype=float32>)
Initializing Variables
('using pre-trained word emebedding.started.word2vec_model_path:', './data/sgns.merge.char')
('pretrained word embedding size:', '300')
('====>>>>word. exists embedding:', 72099, ' ;word not exist embedding:', 27901)
using pre-trained word emebedding.ended...
('trainX[start:end]:', array([[   0,    0,    0, ...,  267,  183,    4],
       [   0,    0,    0, ...,  116,  104,    4],
       [   0,    0,    0, ...,    2,  132,    4],
       ..., 
       [   0,    0,    0, ..., 1871,   15,    4],
       [   0,    0,    0, ...,  191,  183,    4],
       [   0,    0,    0, ...,  116,  104,    4]]), 'train_X.shape:', (646126, 500))
Epoch 0	Batch 20	Train Loss:318.624	Learning rate:0.00030
Epoch 0	Batch 40	Train Loss:273.893	Learning rate:0.00030
Epoch 0	Batch 60	Train Loss:247.531	Learning rate:0.00030
Loss_accusation:11.613	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:175.725	Current_loss:187.338	
Epoch 0	Batch 80	Train Loss:230.795	Learning rate:0.00030
Epoch 0	Batch 100	Train Loss:218.427	Learning rate:0.00030
Epoch 0	Batch 120	Train Loss:208.508	Learning rate:0.00030
Loss_accusation:7.978	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:146.246	Current_loss:154.224	
Epoch 0	Batch 140	Train Loss:200.197	Learning rate:0.00030
Epoch 0	Batch 160	Train Loss:193.035	Learning rate:0.00030
Epoch 0	Batch 180	Train Loss:186.717	Learning rate:0.00030
Loss_accusation:8.061	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:125.518	Current_loss:133.580	
Epoch 0	Batch 200	Train Loss:181.002	Learning rate:0.00030
Epoch 0	Batch 220	Train Loss:175.805	Learning rate:0.00030
Epoch 0	Batch 240	Train Loss:171.043	Learning rate:0.00030
Loss_accusation:6.622	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:109.320	Current_loss:115.941	
Epoch 0	Batch 260	Train Loss:166.626	Learning rate:0.00030
Epoch 0	Batch 280	Train Loss:162.516	Learning rate:0.00030
Epoch 0	Batch 300	Train Loss:158.644	Learning rate:0.00030
Loss_accusation:6.867	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:96.064	Current_loss:102.931	
Epoch 0	Batch 320	Train Loss:155.002	Learning rate:0.00030
Epoch 0	Batch 340	Train Loss:151.549	Learning rate:0.00030
Epoch 0	Batch 360	Train Loss:148.263	Learning rate:0.00030
Loss_accusation:5.661	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:84.817	Current_loss:90.478	
Epoch 0	Batch 380	Train Loss:145.143	Learning rate:0.00030
Epoch 0	Batch 400	Train Loss:142.159	Learning rate:0.00030
Epoch 0	Batch 420	Train Loss:139.300	Learning rate:0.00030
Loss_accusation:6.019	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:74.931	Current_loss:80.950	
Epoch 0	Batch 440	Train Loss:136.555	Learning rate:0.00030
Epoch 0	Batch 460	Train Loss:133.926	Learning rate:0.00030
Epoch 0	Batch 480	Train Loss:131.393	Learning rate:0.00030
Loss_accusation:5.129	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:66.443	Current_loss:71.572	
Epoch 0	Batch 500	Train Loss:128.948	Learning rate:0.00030
Epoch 0	Batch 520	Train Loss:126.597	Learning rate:0.00030
Epoch 0	Batch 540	Train Loss:124.334	Learning rate:0.00030
Loss_accusation:5.157	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:58.995	Current_loss:64.152	
Epoch 0	Batch 560	Train Loss:122.140	Learning rate:0.00030
Epoch 0	Batch 580	Train Loss:120.019	Learning rate:0.00030
Epoch 0	Batch 600	Train Loss:117.968	Learning rate:0.00030
Loss_accusation:4.351	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:52.462	Current_loss:56.814	
Epoch 0	Batch 620	Train Loss:115.975	Learning rate:0.00030
Epoch 0	Batch 640	Train Loss:114.047	Learning rate:0.00030
Epoch 0	Batch 660	Train Loss:112.176	Learning rate:0.00030
Loss_accusation:4.497	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:46.786	Current_loss:51.284	
Epoch 0	Batch 680	Train Loss:110.363	Learning rate:0.00030
Epoch 0	Batch 700	Train Loss:108.604	Learning rate:0.00030
Epoch 0	Batch 720	Train Loss:106.895	Learning rate:0.00030
Loss_accusation:4.537	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:41.823	Current_loss:46.359	
Epoch 0	Batch 740	Train Loss:105.235	Learning rate:0.00030
Epoch 0	Batch 760	Train Loss:103.622	Learning rate:0.00030
Epoch 0	Batch 780	Train Loss:102.059	Learning rate:0.00030
Loss_accusation:4.189	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:37.495	Current_loss:41.684	
Epoch 0	Batch 800	Train Loss:100.533	Learning rate:0.00030
Epoch 0	Batch 820	Train Loss:99.047	Learning rate:0.00030
Epoch 0	Batch 840	Train Loss:97.600	Learning rate:0.00030
Loss_accusation:4.264	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:33.577	Current_loss:37.841	
Epoch 0	Batch 860	Train Loss:96.191	Learning rate:0.00030
Epoch 0	Batch 880	Train Loss:94.816	Learning rate:0.00030
Epoch 0	Batch 900	Train Loss:93.477	Learning rate:0.00030
Loss_accusation:3.620	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:30.174	Current_loss:33.794	
Epoch 0	Batch 920	Train Loss:92.173	Learning rate:0.00030
Epoch 0	Batch 940	Train Loss:90.902	Learning rate:0.00030
Epoch 0	Batch 960	Train Loss:89.660	Learning rate:0.00030
Loss_accusation:3.502	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:27.196	Current_loss:30.698	
Epoch 0	Batch 980	Train Loss:88.450	Learning rate:0.00030
Epoch 0	Batch 1000	Train Loss:87.269	Learning rate:0.00030
Epoch 0	Batch 1020	Train Loss:86.117	Learning rate:0.00030
Loss_accusation:3.687	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:24.556	Current_loss:28.243	
Epoch 0	Batch 1040	Train Loss:84.992	Learning rate:0.00030
Epoch 0	Batch 1060	Train Loss:83.893	Learning rate:0.00030
Epoch 0	Batch 1080	Train Loss:82.820	Learning rate:0.00030
Loss_accusation:3.272	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:22.125	Current_loss:25.397	
Epoch 0	Batch 1100	Train Loss:81.771	Learning rate:0.00030
Epoch 0	Batch 1120	Train Loss:80.744	Learning rate:0.00030
Epoch 0	Batch 1140	Train Loss:79.738	Learning rate:0.00030
Loss_accusation:3.097	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:19.974	Current_loss:23.071	
Epoch 0	Batch 1160	Train Loss:78.757	Learning rate:0.00030
Epoch 0	Batch 1180	Train Loss:77.797	Learning rate:0.00030
Epoch 0	Batch 1200	Train Loss:76.855	Learning rate:0.00030
Loss_accusation:3.406	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:18.043	Current_loss:21.449	
Epoch 0	Batch 1220	Train Loss:75.936	Learning rate:0.00030
Epoch 0	Batch 1240	Train Loss:75.035	Learning rate:0.00030
Epoch 0	Batch 1260	Train Loss:74.154	Learning rate:0.00030
Loss_accusation:3.594	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:16.327	Current_loss:19.921	
Epoch 0	Batch 1280	Train Loss:73.295	Learning rate:0.00030
Epoch 0	Batch 1300	Train Loss:72.456	Learning rate:0.00030
Epoch 0	Batch 1320	Train Loss:71.630	Learning rate:0.00030
Loss_accusation:2.649	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:14.788	Current_loss:17.437	
Epoch 0	Batch 1340	Train Loss:70.820	Learning rate:0.00030
Epoch 0	Batch 1360	Train Loss:70.027	Learning rate:0.00030
Epoch 0	Batch 1380	Train Loss:69.250	Learning rate:0.00030
Loss_accusation:2.934	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:13.372	Current_loss:16.305	
Epoch 0	Batch 1400	Train Loss:68.489	Learning rate:0.00030
Epoch 0	Batch 1420	Train Loss:67.742	Learning rate:0.00030
Epoch 0	Batch 1440	Train Loss:67.010	Learning rate:0.00030
Loss_accusation:2.766	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:12.118	Current_loss:14.884	
Epoch 0	Batch 1460	Train Loss:66.290	Learning rate:0.00030
Epoch 0	Batch 1480	Train Loss:65.586	Learning rate:0.00030
Epoch 0	Batch 1500	Train Loss:64.895	Learning rate:0.00030
Loss_accusation:2.478	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:11.018	Current_loss:13.497	
Epoch 0	Batch 1520	Train Loss:64.218	Learning rate:0.00030
Epoch 0	Batch 1540	Train Loss:63.556	Learning rate:0.00030
Epoch 0	Batch 1560	Train Loss:62.906	Learning rate:0.00030
Loss_accusation:2.732	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:10.006	Current_loss:12.738	
Epoch 0	Batch 1580	Train Loss:62.267	Learning rate:0.00030
Epoch 0	Batch 1600	Train Loss:61.641	Learning rate:0.00030
Epoch 0	Batch 1620	Train Loss:61.025	Learning rate:0.00030
Loss_accusation:2.488	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:9.086	Current_loss:11.574	
Epoch 0	Batch 1640	Train Loss:60.420	Learning rate:0.00030
Epoch 0	Batch 1660	Train Loss:59.827	Learning rate:0.00030
Epoch 0	Batch 1680	Train Loss:59.242	Learning rate:0.00030
Loss_accusation:2.661	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:8.264	Current_loss:10.925	
Epoch 0	Batch 1700	Train Loss:58.669	Learning rate:0.00030
Epoch 0	Batch 1720	Train Loss:58.105	Learning rate:0.00030
Epoch 0	Batch 1740	Train Loss:57.552	Learning rate:0.00030
Loss_accusation:2.142	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:7.533	Current_loss:9.675	
Epoch 0	Batch 1760	Train Loss:57.008	Learning rate:0.00030
Epoch 0	Batch 1780	Train Loss:56.475	Learning rate:0.00030
Epoch 0	Batch 1800	Train Loss:55.952	Learning rate:0.00030
Loss_accusation:2.408	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:6.871	Current_loss:9.280	
Epoch 0	Batch 1820	Train Loss:55.437	Learning rate:0.00030
Epoch 0	Batch 1840	Train Loss:54.931	Learning rate:0.00030
Epoch 0	Batch 1860	Train Loss:54.433	Learning rate:0.00030
Loss_accusation:2.397	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:6.262	Current_loss:8.659	
Epoch 0	Batch 1880	Train Loss:53.943	Learning rate:0.00030
Epoch 0	Batch 1900	Train Loss:53.463	Learning rate:0.00030
Epoch 0	Batch 1920	Train Loss:52.989	Learning rate:0.00030
Loss_accusation:1.999	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:5.712	Current_loss:7.711	
Epoch 0	Batch 1940	Train Loss:52.523	Learning rate:0.00030
Epoch 0	Batch 1960	Train Loss:52.065	Learning rate:0.00030
Epoch 0	Batch 1980	Train Loss:51.613	Learning rate:0.00030
Loss_accusation:2.188	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:5.217	Current_loss:7.406	
Epoch 0	Batch 2000	Train Loss:51.169	Learning rate:0.00030
Epoch 0	Batch 2020	Train Loss:50.733	Learning rate:0.00030
Epoch 0	Batch 2040	Train Loss:50.306	Learning rate:0.00030
Loss_accusation:1.924	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:4.777	Current_loss:6.702	
Epoch 0	Batch 2060	Train Loss:49.886	Learning rate:0.00030
Epoch 0	Batch 2080	Train Loss:49.471	Learning rate:0.00030
Epoch 0	Batch 2100	Train Loss:49.062	Learning rate:0.00030
Loss_accusation:2.262	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:4.373	Current_loss:6.634	
Epoch 0	Batch 2120	Train Loss:48.660	Learning rate:0.00030
Epoch 0	Batch 2140	Train Loss:48.264	Learning rate:0.00030
Epoch 0	Batch 2160	Train Loss:47.873	Learning rate:0.00030
Loss_accusation:1.849	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:4.011	Current_loss:5.860	
Epoch 0	Batch 2180	Train Loss:47.490	Learning rate:0.00030
Epoch 0	Batch 2200	Train Loss:47.112	Learning rate:0.00030
Epoch 0	Batch 2220	Train Loss:46.740	Learning rate:0.00030
Loss_accusation:1.864	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:3.685	Current_loss:5.549	
Epoch 0	Batch 2240	Train Loss:46.372	Learning rate:0.00030
Epoch 0	Batch 2260	Train Loss:46.010	Learning rate:0.00030
Epoch 0	Batch 2280	Train Loss:45.654	Learning rate:0.00030
Loss_accusation:2.195	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:3.389	Current_loss:5.584	
Epoch 0	Batch 2300	Train Loss:45.304	Learning rate:0.00030
Epoch 0	Batch 2320	Train Loss:44.961	Learning rate:0.00030
Epoch 0	Batch 2340	Train Loss:44.621	Learning rate:0.00030
Loss_accusation:2.182	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:3.127	Current_loss:5.308	
Epoch 0	Batch 2360	Train Loss:44.285	Learning rate:0.00030
Epoch 0	Batch 2380	Train Loss:43.954	Learning rate:0.00030
Epoch 0	Batch 2400	Train Loss:43.628	Learning rate:0.00030
Loss_accusation:1.697	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.883	Current_loss:4.580	
Epoch 0	Batch 2420	Train Loss:43.306	Learning rate:0.00030
Epoch 0	Batch 2440	Train Loss:42.988	Learning rate:0.00030
Epoch 0	Batch 2460	Train Loss:42.676	Learning rate:0.00030
Loss_accusation:1.638	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.660	Current_loss:4.299	
Epoch 0	Batch 2480	Train Loss:42.367	Learning rate:0.00030
Epoch 0	Batch 2500	Train Loss:42.061	Learning rate:0.00030
Epoch 0	Batch 2520	Train Loss:41.761	Learning rate:0.00030
Loss_accusation:1.942	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.459	Current_loss:4.402	
Epoch 0	Batch 2540	Train Loss:41.467	Learning rate:0.00030
Epoch 0	Batch 2560	Train Loss:41.177	Learning rate:0.00030
Epoch 0	Batch 2580	Train Loss:40.891	Learning rate:0.00030
Loss_accusation:2.587	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.280	Current_loss:4.868	
Epoch 0	Batch 2600	Train Loss:40.609	Learning rate:0.00030
Epoch 0	Batch 2620	Train Loss:40.330	Learning rate:0.00030
Epoch 0	Batch 2640	Train Loss:40.053	Learning rate:0.00030
Loss_accusation:1.752	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:2.118	Current_loss:3.870	
Epoch 0	Batch 2660	Train Loss:39.782	Learning rate:0.00030
Epoch 0	Batch 2680	Train Loss:39.513	Learning rate:0.00030
Epoch 0	Batch 2700	Train Loss:39.247	Learning rate:0.00030
Loss_accusation:1.334	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.972	Current_loss:3.306	
Epoch 0	Batch 2720	Train Loss:38.986	Learning rate:0.00030
Epoch 0	Batch 2740	Train Loss:38.728	Learning rate:0.00030
Epoch 0	Batch 2760	Train Loss:38.473	Learning rate:0.00030
Loss_accusation:1.419	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.842	Current_loss:3.261	
Epoch 0	Batch 2780	Train Loss:38.221	Learning rate:0.00030
Epoch 0	Batch 2800	Train Loss:37.974	Learning rate:0.00030
Epoch 0	Batch 2820	Train Loss:37.731	Learning rate:0.00030
Loss_accusation:1.703	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.725	Current_loss:3.428	
Epoch 0	Batch 2840	Train Loss:37.490	Learning rate:0.00030
Epoch 0	Batch 2860	Train Loss:37.252	Learning rate:0.00030
Epoch 0	Batch 2880	Train Loss:37.017	Learning rate:0.00030
Loss_accusation:1.522	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.618	Current_loss:3.140	
Epoch 0	Batch 2900	Train Loss:36.785	Learning rate:0.00030
Epoch 0	Batch 2920	Train Loss:36.555	Learning rate:0.00030
Epoch 0	Batch 2940	Train Loss:36.327	Learning rate:0.00030
Loss_accusation:1.437	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.521	Current_loss:2.958	
Epoch 0	Batch 2960	Train Loss:36.103	Learning rate:0.00030
Epoch 0	Batch 2980	Train Loss:35.881	Learning rate:0.00030
Epoch 0	Batch 3000	Train Loss:35.662	Learning rate:0.00030
Loss_accusation:1.578	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.433	Current_loss:3.011	
Epoch 0	Batch 3020	Train Loss:35.446	Learning rate:0.00030
Epoch 0	Batch 3040	Train Loss:35.233	Learning rate:0.00030
Epoch 0	Batch 3060	Train Loss:35.024	Learning rate:0.00030
Loss_accusation:1.632	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.356	Current_loss:2.988	
Epoch 0	Batch 3080	Train Loss:34.817	Learning rate:0.00030
Epoch 0	Batch 3100	Train Loss:34.612	Learning rate:0.00030
Epoch 0	Batch 3120	Train Loss:34.409	Learning rate:0.00030
Loss_accusation:1.810	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.285	Current_loss:3.096	
Epoch 0	Batch 3140	Train Loss:34.209	Learning rate:0.00030
Epoch 0	Batch 3160	Train Loss:34.011	Learning rate:0.00030
Epoch 0	Batch 3180	Train Loss:33.815	Learning rate:0.00030
Loss_accusation:1.410	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.221	Current_loss:2.631	
Epoch 0	Batch 3200	Train Loss:33.621	Learning rate:0.00030
Epoch 0	Batch 3220	Train Loss:33.429	Learning rate:0.00030
Epoch 0	Batch 3240	Train Loss:33.239	Learning rate:0.00030
Loss_accusation:1.805	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.163	Current_loss:2.968	
Epoch 0	Batch 3260	Train Loss:33.052	Learning rate:0.00030
Epoch 0	Batch 3280	Train Loss:32.866	Learning rate:0.00030
Epoch 0	Batch 3300	Train Loss:32.685	Learning rate:0.00030
Loss_accusation:1.475	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.111	Current_loss:2.586	
Epoch 0	Batch 3320	Train Loss:32.506	Learning rate:0.00030
Epoch 0	Batch 3340	Train Loss:32.328	Learning rate:0.00030
Epoch 0	Batch 3360	Train Loss:32.152	Learning rate:0.00030
Loss_accusation:1.970	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.064	Current_loss:3.034	
Epoch 0	Batch 3380	Train Loss:31.978	Learning rate:0.00030
Epoch 0	Batch 3400	Train Loss:31.805	Learning rate:0.00030
Epoch 0	Batch 3420	Train Loss:31.634	Learning rate:0.00030
Loss_accusation:1.412	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:1.020	Current_loss:2.432	
Epoch 0	Batch 3440	Train Loss:31.464	Learning rate:0.00030
Epoch 0	Batch 3460	Train Loss:31.297	Learning rate:0.00030
Epoch 0	Batch 3480	Train Loss:31.131	Learning rate:0.00030
Loss_accusation:1.397	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.982	Current_loss:2.378	
Epoch 0	Batch 3500	Train Loss:30.967	Learning rate:0.00030
Epoch 0	Batch 3520	Train Loss:30.805	Learning rate:0.00030
Epoch 0	Batch 3540	Train Loss:30.645	Learning rate:0.00030
Loss_accusation:1.900	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.945	Current_loss:2.845	
Epoch 0	Batch 3560	Train Loss:30.488	Learning rate:0.00030
Epoch 0	Batch 3580	Train Loss:30.332	Learning rate:0.00030
Epoch 0	Batch 3600	Train Loss:30.178	Learning rate:0.00030
Loss_accusation:1.869	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.912	Current_loss:2.781	
Epoch 0	Batch 3620	Train Loss:30.025	Learning rate:0.00030
Epoch 0	Batch 3640	Train Loss:29.873	Learning rate:0.00030
Epoch 0	Batch 3660	Train Loss:29.722	Learning rate:0.00030
Loss_accusation:1.588	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.882	Current_loss:2.470	
Epoch 0	Batch 3680	Train Loss:29.573	Learning rate:0.00030
Epoch 0	Batch 3700	Train Loss:29.425	Learning rate:0.00030
Epoch 0	Batch 3720	Train Loss:29.279	Learning rate:0.00030
Loss_accusation:1.240	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.854	Current_loss:2.094	
Epoch 0	Batch 3740	Train Loss:29.135	Learning rate:0.00030
Epoch 0	Batch 3760	Train Loss:28.992	Learning rate:0.00030
Epoch 0	Batch 3780	Train Loss:28.851	Learning rate:0.00030
Loss_accusation:1.324	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.829	Current_loss:2.153	
Epoch 0	Batch 3800	Train Loss:28.712	Learning rate:0.00030
Epoch 0	Batch 3820	Train Loss:28.574	Learning rate:0.00030
Epoch 0	Batch 3840	Train Loss:28.438	Learning rate:0.00030
Loss_accusation:1.807	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.807	Current_loss:2.614	
Epoch 0	Batch 3860	Train Loss:28.302	Learning rate:0.00030
Epoch 0	Batch 3880	Train Loss:28.169	Learning rate:0.00030
Epoch 0	Batch 3900	Train Loss:28.036	Learning rate:0.00030
Loss_accusation:1.209	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.787	Current_loss:1.996	
('number_examples:', 13094)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('imprisonment_score:', 0.0)
('imprisonment_score:', 0.0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('accusation.y_target_labels:', [200], ';y_predict_labels:', [200])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score:', 1.0)
('article.y_target_labels:', [16], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('death_lifeimprisonment_score:', 1.0)
('x.imprisonment_score.target_value:', 24.0, ';predict_value:', 0.0)
('article.y_target_labels:', [88, 111, 130], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('accusation.y_target_labels:', [120], ';y_predict_labels:', [67])
('death_lifeimprisonment_score:', 1.0)
('x.imprisonment_score.target_value:', 6.0, ';predict_value:', 0.0)
('x.imprisonment_score.target_value:', 24.0, ';predict_value:', 0.0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score:', 1.0)
('x.imprisonment_score.target_value:', 66.0, ';predict_value:', 0.0)
('accusation_normal_f1_score', 'precison:', '0.714285673469', ';recall:', '0.954198400443', ';f1_score:', 0.8169885140624018)
('f1_micro_accusation:', 0.7997629344309602, ';f1_macro_accusation:', 0.6080145721638908)
Epoch 0 ValidLoss:2.582	Macro_f1_accasation:0.608	Micro_f1_accsastion:0.800	Macro_f1_article:0.012 Micro_f1_article:0.013 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 70.38887532974255, ';2.Article Score:', 1.24225301944427, ';3.Penalty Score:', 69.23099811460806, ';Score ALL:', 140.86212646379488)
going to save check point.
Epoch 0	Batch 3920	Train Loss:27.904	Learning rate:0.00030
Epoch 0	Batch 3940	Train Loss:27.774	Learning rate:0.00030
Epoch 0	Batch 3960	Train Loss:27.645	Learning rate:0.00030
Loss_accusation:1.382	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.768	Current_loss:2.151	
Epoch 0	Batch 3980	Train Loss:27.516	Learning rate:0.00030
Epoch 0	Batch 4000	Train Loss:27.389	Learning rate:0.00030
Epoch 0	Batch 4020	Train Loss:27.263	Learning rate:0.00030
Loss_accusation:1.588	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.752	Current_loss:2.340	
Epoch 0	Batch 4040	Train Loss:27.138	Learning rate:0.00030
Epoch 0	Batch 4060	Train Loss:27.016	Learning rate:0.00030
Epoch 0	Batch 4080	Train Loss:26.895	Learning rate:0.00030
Loss_accusation:1.472	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.737	Current_loss:2.209	
Epoch 0	Batch 4100	Train Loss:26.775	Learning rate:0.00030
Epoch 0	Batch 4120	Train Loss:26.655	Learning rate:0.00030
Epoch 0	Batch 4140	Train Loss:26.537	Learning rate:0.00030
Loss_accusation:1.132	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.723	Current_loss:1.855	
Epoch 0	Batch 4160	Train Loss:26.419	Learning rate:0.00030
Epoch 0	Batch 4180	Train Loss:26.303	Learning rate:0.00030
Epoch 0	Batch 4200	Train Loss:26.187	Learning rate:0.00030
Loss_accusation:1.716	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.709	Current_loss:2.425	
Epoch 0	Batch 4220	Train Loss:26.072	Learning rate:0.00030
Epoch 0	Batch 4240	Train Loss:25.959	Learning rate:0.00030
Epoch 0	Batch 4260	Train Loss:25.846	Learning rate:0.00030
Loss_accusation:1.318	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.697	Current_loss:2.015	
Epoch 0	Batch 4280	Train Loss:25.734	Learning rate:0.00030
Epoch 0	Batch 4300	Train Loss:25.625	Learning rate:0.00030
Epoch 0	Batch 4320	Train Loss:25.517	Learning rate:0.00030
Loss_accusation:1.565	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.687	Current_loss:2.252	
Epoch 0	Batch 4340	Train Loss:25.409	Learning rate:0.00030
Epoch 0	Batch 4360	Train Loss:25.302	Learning rate:0.00030
Epoch 0	Batch 4380	Train Loss:25.196	Learning rate:0.00030
Loss_accusation:1.375	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.677	Current_loss:2.052	
Epoch 0	Batch 4400	Train Loss:25.091	Learning rate:0.00030
Epoch 0	Batch 4420	Train Loss:24.987	Learning rate:0.00030
Epoch 0	Batch 4440	Train Loss:24.883	Learning rate:0.00030
Loss_accusation:1.174	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.667	Current_loss:1.841	
Epoch 0	Batch 4460	Train Loss:24.780	Learning rate:0.00030
Epoch 0	Batch 4480	Train Loss:24.678	Learning rate:0.00030
Epoch 0	Batch 4500	Train Loss:24.577	Learning rate:0.00030
Loss_accusation:1.254	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.659	Current_loss:1.913	
Epoch 0	Batch 4520	Train Loss:24.477	Learning rate:0.00030
Epoch 0	Batch 4540	Train Loss:24.377	Learning rate:0.00030
Epoch 0	Batch 4560	Train Loss:24.280	Learning rate:0.00030
Loss_accusation:1.365	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.651	Current_loss:2.015	
Epoch 0	Batch 4580	Train Loss:24.183	Learning rate:0.00030
Epoch 0	Batch 4600	Train Loss:24.087	Learning rate:0.00030
Epoch 0	Batch 4620	Train Loss:23.991	Learning rate:0.00030
Loss_accusation:1.284	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.644	Current_loss:1.928	
Epoch 0	Batch 4640	Train Loss:23.897	Learning rate:0.00030
Epoch 0	Batch 4660	Train Loss:23.803	Learning rate:0.00030
Epoch 0	Batch 4680	Train Loss:23.710	Learning rate:0.00030
Loss_accusation:1.316	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.637	Current_loss:1.954	
Epoch 0	Batch 4700	Train Loss:23.617	Learning rate:0.00030
Epoch 0	Batch 4720	Train Loss:23.525	Learning rate:0.00030
Epoch 0	Batch 4740	Train Loss:23.433	Learning rate:0.00030
Loss_accusation:1.327	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.630	Current_loss:1.956	
Epoch 0	Batch 4760	Train Loss:23.343	Learning rate:0.00030
Epoch 0	Batch 4780	Train Loss:23.253	Learning rate:0.00030
Epoch 0	Batch 4800	Train Loss:23.164	Learning rate:0.00030
Loss_accusation:1.553	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.623	Current_loss:2.176	
Epoch 0	Batch 4820	Train Loss:23.077	Learning rate:0.00030
Epoch 0	Batch 4840	Train Loss:22.991	Learning rate:0.00030
Epoch 0	Batch 4860	Train Loss:22.905	Learning rate:0.00030
Loss_accusation:1.265	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.619	Current_loss:1.884	
Epoch 0	Batch 4880	Train Loss:22.819	Learning rate:0.00030
Epoch 0	Batch 4900	Train Loss:22.734	Learning rate:0.00030
Epoch 0	Batch 4920	Train Loss:22.649	Learning rate:0.00030
Loss_accusation:1.332	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.614	Current_loss:1.946	
Epoch 0	Batch 4940	Train Loss:22.565	Learning rate:0.00030
Epoch 0	Batch 4960	Train Loss:22.482	Learning rate:0.00030
Epoch 0	Batch 4980	Train Loss:22.399	Learning rate:0.00030
Loss_accusation:1.329	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.609	Current_loss:1.938	
Epoch 0	Batch 5000	Train Loss:22.317	Learning rate:0.00030
Epoch 0	Batch 5020	Train Loss:22.235	Learning rate:0.00030
Epoch 0	Batch 5040	Train Loss:22.154	Learning rate:0.00030
Loss_accusation:1.212	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.604	Current_loss:1.816	
going to increment epoch counter....
(0, 1, True)
('number_examples:', 13094)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('accusation.y_target_labels:', [189], ';y_predict_labels:', [189])
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('imprisonment_score:', 0.0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('macro', 'precison:', '0.00168504901832', ';recall:', '0.999999545455', ';f1_score:', 0.0033643952192286496)
('f1_micro_accusation:', 0.8508319229456256, ';f1_macro_accusation:', 0.736631409823197)
()
Epoch 0 ValidLoss:1.760	Macro_f1_accasation:0.737	Micro_f1_accsastion:0.851	Macro_f1_article:0.012	Micro_f1_article:0.013	Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('===>1.Accasation Score:', 79.37316663844113, ';2.Article Score:', 1.242078601668158, ';3.Penalty Score:', 68.34558153474691, ';Score ALL:', 148.9608267748562)
going to save check point.
(0, 'Going to decay learning rate by half.')
(1, 'Going to decay learning rate by half.')
Epoch 1	Batch 20	Train Loss:2.130	Learning rate:0.00011
Epoch 1	Batch 40	Train Loss:2.098	Learning rate:0.00011
Epoch 1	Batch 60	Train Loss:2.062	Learning rate:0.00011
Loss_accusation:1.024	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.599	Current_loss:1.623	
Epoch 1	Batch 80	Train Loss:2.047	Learning rate:0.00011
Epoch 1	Batch 100	Train Loss:2.016	Learning rate:0.00011
Epoch 1	Batch 120	Train Loss:2.012	Learning rate:0.00011
Loss_accusation:1.344	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.595	Current_loss:1.938	
Epoch 1	Batch 140	Train Loss:1.989	Learning rate:0.00011
Epoch 1	Batch 160	Train Loss:1.972	Learning rate:0.00011
Epoch 1	Batch 180	Train Loss:1.955	Learning rate:0.00011
Loss_accusation:1.419	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.591	Current_loss:2.010	
Epoch 1	Batch 200	Train Loss:1.930	Learning rate:0.00011
Epoch 1	Batch 220	Train Loss:1.915	Learning rate:0.00011
Epoch 1	Batch 240	Train Loss:1.910	Learning rate:0.00011
Loss_accusation:1.035	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.587	Current_loss:1.622	
Epoch 1	Batch 260	Train Loss:1.906	Learning rate:0.00011
Epoch 1	Batch 280	Train Loss:1.919	Learning rate:0.00011
Epoch 1	Batch 300	Train Loss:1.923	Learning rate:0.00011
Loss_accusation:1.636	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.583	Current_loss:2.219	
Epoch 1	Batch 320	Train Loss:1.922	Learning rate:0.00011
Epoch 1	Batch 340	Train Loss:1.917	Learning rate:0.00011
Epoch 1	Batch 360	Train Loss:1.916	Learning rate:0.00011
Loss_accusation:1.274	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.580	Current_loss:1.854	
Epoch 1	Batch 380	Train Loss:1.914	Learning rate:0.00011
Epoch 1	Batch 400	Train Loss:1.915	Learning rate:0.00011
Epoch 1	Batch 420	Train Loss:1.909	Learning rate:0.00011
Loss_accusation:0.951	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.577	Current_loss:1.528	
Epoch 1	Batch 440	Train Loss:1.905	Learning rate:0.00011
Epoch 1	Batch 460	Train Loss:1.903	Learning rate:0.00011
Epoch 1	Batch 480	Train Loss:1.897	Learning rate:0.00011
Loss_accusation:1.197	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.574	Current_loss:1.771	
Epoch 1	Batch 500	Train Loss:1.891	Learning rate:0.00011
Epoch 1	Batch 520	Train Loss:1.893	Learning rate:0.00011
Epoch 1	Batch 540	Train Loss:1.900	Learning rate:0.00011
Loss_accusation:1.261	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.571	Current_loss:1.832	
Epoch 1	Batch 560	Train Loss:1.902	Learning rate:0.00011
Epoch 1	Batch 580	Train Loss:1.901	Learning rate:0.00011
Epoch 1	Batch 600	Train Loss:1.903	Learning rate:0.00011
Loss_accusation:1.135	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.568	Current_loss:1.703	
Epoch 1	Batch 620	Train Loss:1.903	Learning rate:0.00011
Epoch 1	Batch 640	Train Loss:1.902	Learning rate:0.00011
Epoch 1	Batch 660	Train Loss:1.899	Learning rate:0.00011
Loss_accusation:1.271	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.566	Current_loss:1.837	
Epoch 1	Batch 680	Train Loss:1.896	Learning rate:0.00011
Epoch 1	Batch 700	Train Loss:1.891	Learning rate:0.00011
Epoch 1	Batch 720	Train Loss:1.889	Learning rate:0.00011
Loss_accusation:1.230	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.563	Current_loss:1.793	
Epoch 1	Batch 740	Train Loss:1.886	Learning rate:0.00011
Epoch 1	Batch 760	Train Loss:1.884	Learning rate:0.00011
Epoch 1	Batch 780	Train Loss:1.889	Learning rate:0.00011
Loss_accusation:1.415	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.561	Current_loss:1.975	
Epoch 1	Batch 800	Train Loss:1.891	Learning rate:0.00011
Epoch 1	Batch 820	Train Loss:1.893	Learning rate:0.00011
Epoch 1	Batch 840	Train Loss:1.893	Learning rate:0.00011
Loss_accusation:1.370	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.558	Current_loss:1.928	
Epoch 1	Batch 860	Train Loss:1.892	Learning rate:0.00011
Epoch 1	Batch 880	Train Loss:1.889	Learning rate:0.00011
Epoch 1	Batch 900	Train Loss:1.888	Learning rate:0.00011
Loss_accusation:1.017	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.555	Current_loss:1.573	
Epoch 1	Batch 920	Train Loss:1.886	Learning rate:0.00011
Epoch 1	Batch 940	Train Loss:1.884	Learning rate:0.00011
Epoch 1	Batch 960	Train Loss:1.881	Learning rate:0.00011
Loss_accusation:1.045	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.553	Current_loss:1.598	
Epoch 1	Batch 980	Train Loss:1.878	Learning rate:0.00011
Epoch 1	Batch 1000	Train Loss:1.875	Learning rate:0.00011
Epoch 1	Batch 1020	Train Loss:1.874	Learning rate:0.00011
Loss_accusation:1.319	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.551	Current_loss:1.870	
Epoch 1	Batch 1040	Train Loss:1.873	Learning rate:0.00011
Epoch 1	Batch 1060	Train Loss:1.872	Learning rate:0.00011
Epoch 1	Batch 1080	Train Loss:1.871	Learning rate:0.00011
Loss_accusation:1.118	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.549	Current_loss:1.666	
Epoch 1	Batch 1100	Train Loss:1.871	Learning rate:0.00011
Epoch 1	Batch 1120	Train Loss:1.868	Learning rate:0.00011
Epoch 1	Batch 1140	Train Loss:1.866	Learning rate:0.00011
Loss_accusation:1.368	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.546	Current_loss:1.914	
Epoch 1	Batch 1160	Train Loss:1.864	Learning rate:0.00011
Epoch 1	Batch 1180	Train Loss:1.861	Learning rate:0.00011
Epoch 1	Batch 1200	Train Loss:1.858	Learning rate:0.00011
Loss_accusation:1.494	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.544	Current_loss:2.038	
Epoch 1	Batch 1220	Train Loss:1.856	Learning rate:0.00011
Epoch 1	Batch 1240	Train Loss:1.853	Learning rate:0.00011
Epoch 1	Batch 1260	Train Loss:1.851	Learning rate:0.00011
Loss_accusation:1.840	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.542	Current_loss:2.382	
Epoch 1	Batch 1280	Train Loss:1.852	Learning rate:0.00011
Epoch 1	Batch 1300	Train Loss:1.853	Learning rate:0.00011
Epoch 1	Batch 1320	Train Loss:1.852	Learning rate:0.00011
Loss_accusation:1.121	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.540	Current_loss:1.661	
Epoch 1	Batch 1340	Train Loss:1.850	Learning rate:0.00011
Epoch 1	Batch 1360	Train Loss:1.850	Learning rate:0.00011
Epoch 1	Batch 1380	Train Loss:1.848	Learning rate:0.00011
Loss_accusation:1.326	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.538	Current_loss:1.864	
Epoch 1	Batch 1400	Train Loss:1.847	Learning rate:0.00011
Epoch 1	Batch 1420	Train Loss:1.845	Learning rate:0.00011
Epoch 1	Batch 1440	Train Loss:1.844	Learning rate:0.00011
Loss_accusation:1.082	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.536	Current_loss:1.617	
Epoch 1	Batch 1460	Train Loss:1.840	Learning rate:0.00011
Epoch 1	Batch 1480	Train Loss:1.838	Learning rate:0.00011
Epoch 1	Batch 1500	Train Loss:1.836	Learning rate:0.00011
Loss_accusation:1.096	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.534	Current_loss:1.629	
Epoch 1	Batch 1520	Train Loss:1.834	Learning rate:0.00011
Epoch 1	Batch 1540	Train Loss:1.834	Learning rate:0.00011
Epoch 1	Batch 1560	Train Loss:1.835	Learning rate:0.00011
Loss_accusation:1.449	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.532	Current_loss:1.981	
Epoch 1	Batch 1580	Train Loss:1.834	Learning rate:0.00011
Epoch 1	Batch 1600	Train Loss:1.833	Learning rate:0.00011
Epoch 1	Batch 1620	Train Loss:1.833	Learning rate:0.00011
Loss_accusation:1.384	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.530	Current_loss:1.915	
Epoch 1	Batch 1640	Train Loss:1.832	Learning rate:0.00011
Epoch 1	Batch 1660	Train Loss:1.830	Learning rate:0.00011
Epoch 1	Batch 1680	Train Loss:1.828	Learning rate:0.00011
Loss_accusation:1.399	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.529	Current_loss:1.928	
Epoch 1	Batch 1700	Train Loss:1.826	Learning rate:0.00011
Epoch 1	Batch 1720	Train Loss:1.824	Learning rate:0.00011
Epoch 1	Batch 1740	Train Loss:1.822	Learning rate:0.00011
Loss_accusation:0.986	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.527	Current_loss:1.513	
Epoch 1	Batch 1760	Train Loss:1.819	Learning rate:0.00011
Epoch 1	Batch 1780	Train Loss:1.818	Learning rate:0.00011
Epoch 1	Batch 1800	Train Loss:1.818	Learning rate:0.00011
Loss_accusation:1.327	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.525	Current_loss:1.852	
Epoch 1	Batch 1820	Train Loss:1.817	Learning rate:0.00011
Epoch 1	Batch 1840	Train Loss:1.816	Learning rate:0.00011
Epoch 1	Batch 1860	Train Loss:1.816	Learning rate:0.00011
Loss_accusation:1.336	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.523	Current_loss:1.860	
Epoch 1	Batch 1880	Train Loss:1.814	Learning rate:0.00011
Epoch 1	Batch 1900	Train Loss:1.814	Learning rate:0.00011
Epoch 1	Batch 1920	Train Loss:1.813	Learning rate:0.00011
Loss_accusation:1.287	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.522	Current_loss:1.808	
Epoch 1	Batch 1940	Train Loss:1.810	Learning rate:0.00011
Epoch 1	Batch 1960	Train Loss:1.809	Learning rate:0.00011
Epoch 1	Batch 1980	Train Loss:1.807	Learning rate:0.00011
Loss_accusation:1.152	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.520	Current_loss:1.672	
Epoch 1	Batch 2000	Train Loss:1.805	Learning rate:0.00011
Epoch 1	Batch 2020	Train Loss:1.803	Learning rate:0.00011
Epoch 1	Batch 2040	Train Loss:1.804	Learning rate:0.00011
Loss_accusation:1.080	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.518	Current_loss:1.599	
Epoch 1	Batch 2060	Train Loss:1.804	Learning rate:0.00011
Epoch 1	Batch 2080	Train Loss:1.804	Learning rate:0.00011
Epoch 1	Batch 2100	Train Loss:1.803	Learning rate:0.00011
Loss_accusation:1.245	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.517	Current_loss:1.762	
Epoch 1	Batch 2120	Train Loss:1.802	Learning rate:0.00011
Epoch 1	Batch 2140	Train Loss:1.801	Learning rate:0.00011
Epoch 1	Batch 2160	Train Loss:1.799	Learning rate:0.00011
Loss_accusation:1.159	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.515	Current_loss:1.675	
Epoch 1	Batch 2180	Train Loss:1.799	Learning rate:0.00011
Epoch 1	Batch 2200	Train Loss:1.797	Learning rate:0.00011
Epoch 1	Batch 2220	Train Loss:1.796	Learning rate:0.00011
Loss_accusation:0.838	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.514	Current_loss:1.352	
Epoch 1	Batch 2240	Train Loss:1.794	Learning rate:0.00011
Epoch 1	Batch 2260	Train Loss:1.792	Learning rate:0.00011
Epoch 1	Batch 2280	Train Loss:1.791	Learning rate:0.00011
Loss_accusation:1.255	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.513	Current_loss:1.768	
Epoch 1	Batch 2300	Train Loss:1.792	Learning rate:0.00011
Epoch 1	Batch 2320	Train Loss:1.792	Learning rate:0.00011
Epoch 1	Batch 2340	Train Loss:1.792	Learning rate:0.00011
Loss_accusation:1.243	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.511	Current_loss:1.755	
Epoch 1	Batch 2360	Train Loss:1.790	Learning rate:0.00011
Epoch 1	Batch 2380	Train Loss:1.789	Learning rate:0.00011
Epoch 1	Batch 2400	Train Loss:1.788	Learning rate:0.00011
Loss_accusation:0.882	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.510	Current_loss:1.392	
Epoch 1	Batch 2420	Train Loss:1.786	Learning rate:0.00011
Epoch 1	Batch 2440	Train Loss:1.784	Learning rate:0.00011
Epoch 1	Batch 2460	Train Loss:1.782	Learning rate:0.00011
Loss_accusation:1.027	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.508	Current_loss:1.535	
Epoch 1	Batch 2480	Train Loss:1.780	Learning rate:0.00011
Epoch 1	Batch 2500	Train Loss:1.778	Learning rate:0.00011
Epoch 1	Batch 2520	Train Loss:1.776	Learning rate:0.00011
Loss_accusation:0.952	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.507	Current_loss:1.459	
Epoch 1	Batch 2540	Train Loss:1.775	Learning rate:0.00011
Epoch 1	Batch 2560	Train Loss:1.775	Learning rate:0.00011
Epoch 1	Batch 2580	Train Loss:1.775	Learning rate:0.00011
Loss_accusation:1.678	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.506	Current_loss:2.184	
Epoch 1	Batch 2600	Train Loss:1.775	Learning rate:0.00011
Epoch 1	Batch 2620	Train Loss:1.774	Learning rate:0.00011
Epoch 1	Batch 2640	Train Loss:1.772	Learning rate:0.00011
Loss_accusation:0.978	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.504	Current_loss:1.483	
Epoch 1	Batch 2660	Train Loss:1.772	Learning rate:0.00011
Epoch 1	Batch 2680	Train Loss:1.770	Learning rate:0.00011
Epoch 1	Batch 2700	Train Loss:1.768	Learning rate:0.00011
Loss_accusation:0.713	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.503	Current_loss:1.217	
Epoch 1	Batch 2720	Train Loss:1.767	Learning rate:0.00011
Epoch 1	Batch 2740	Train Loss:1.765	Learning rate:0.00011
Epoch 1	Batch 2760	Train Loss:1.764	Learning rate:0.00011
Loss_accusation:0.625	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.502	Current_loss:1.127	
Epoch 1	Batch 2780	Train Loss:1.762	Learning rate:0.00011
Epoch 1	Batch 2800	Train Loss:1.761	Learning rate:0.00011
Epoch 1	Batch 2820	Train Loss:1.761	Learning rate:0.00011
Loss_accusation:1.202	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.501	Current_loss:1.703	
Epoch 1	Batch 2840	Train Loss:1.761	Learning rate:0.00011
Epoch 1	Batch 2860	Train Loss:1.760	Learning rate:0.00011
Epoch 1	Batch 2880	Train Loss:1.759	Learning rate:0.00011
Loss_accusation:1.000	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.500	Current_loss:1.500	
Epoch 1	Batch 2900	Train Loss:1.758	Learning rate:0.00011
Epoch 1	Batch 2920	Train Loss:1.757	Learning rate:0.00011
Epoch 1	Batch 2940	Train Loss:1.756	Learning rate:0.00011
Loss_accusation:1.130	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.499	Current_loss:1.628	
Epoch 1	Batch 2960	Train Loss:1.754	Learning rate:0.00011
Epoch 1	Batch 2980	Train Loss:1.752	Learning rate:0.00011
Epoch 1	Batch 3000	Train Loss:1.751	Learning rate:0.00011
Loss_accusation:0.939	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.497	Current_loss:1.436	
Epoch 1	Batch 3020	Train Loss:1.750	Learning rate:0.00011
Epoch 1	Batch 3040	Train Loss:1.749	Learning rate:0.00011
Epoch 1	Batch 3060	Train Loss:1.749	Learning rate:0.00011
Loss_accusation:1.251	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.496	Current_loss:1.747	
Epoch 1	Batch 3080	Train Loss:1.749	Learning rate:0.00011
Epoch 1	Batch 3100	Train Loss:1.748	Learning rate:0.00011
Epoch 1	Batch 3120	Train Loss:1.747	Learning rate:0.00011
Loss_accusation:1.172	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.495	Current_loss:1.667	
Epoch 1	Batch 3140	Train Loss:1.747	Learning rate:0.00011
Epoch 1	Batch 3160	Train Loss:1.746	Learning rate:0.00011
Epoch 1	Batch 3180	Train Loss:1.745	Learning rate:0.00011
Loss_accusation:0.956	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.494	Current_loss:1.450	
Epoch 1	Batch 3200	Train Loss:1.743	Learning rate:0.00011
Epoch 1	Batch 3220	Train Loss:1.742	Learning rate:0.00011
Epoch 1	Batch 3240	Train Loss:1.741	Learning rate:0.00011
Loss_accusation:1.038	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.493	Current_loss:1.530	
Epoch 1	Batch 3260	Train Loss:1.740	Learning rate:0.00011
Epoch 1	Batch 3280	Train Loss:1.738	Learning rate:0.00011
Epoch 1	Batch 3300	Train Loss:1.739	Learning rate:0.00011
Loss_accusation:1.103	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.491	Current_loss:1.594	
Epoch 1	Batch 3320	Train Loss:1.738	Learning rate:0.00011
Epoch 1	Batch 3340	Train Loss:1.738	Learning rate:0.00011
Epoch 1	Batch 3360	Train Loss:1.737	Learning rate:0.00011
Loss_accusation:1.172	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.491	Current_loss:1.663	
Epoch 1	Batch 3380	Train Loss:1.736	Learning rate:0.00011
Epoch 1	Batch 3400	Train Loss:1.735	Learning rate:0.00011
Epoch 1	Batch 3420	Train Loss:1.734	Learning rate:0.00011
Loss_accusation:1.085	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.490	Current_loss:1.574	
Epoch 1	Batch 3440	Train Loss:1.733	Learning rate:0.00011
Epoch 1	Batch 3460	Train Loss:1.732	Learning rate:0.00011
Epoch 1	Batch 3480	Train Loss:1.731	Learning rate:0.00011
Loss_accusation:0.865	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.488	Current_loss:1.354	
Epoch 1	Batch 3500	Train Loss:1.729	Learning rate:0.00011
Epoch 1	Batch 3520	Train Loss:1.728	Learning rate:0.00011
Epoch 1	Batch 3540	Train Loss:1.727	Learning rate:0.00011
Loss_accusation:1.165	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.487	Current_loss:1.652	
Epoch 1	Batch 3560	Train Loss:1.727	Learning rate:0.00011
Epoch 1	Batch 3580	Train Loss:1.726	Learning rate:0.00011
Epoch 1	Batch 3600	Train Loss:1.726	Learning rate:0.00011
Loss_accusation:1.429	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.486	Current_loss:1.915	
Epoch 1	Batch 3620	Train Loss:1.726	Learning rate:0.00011
Epoch 1	Batch 3640	Train Loss:1.725	Learning rate:0.00011
Epoch 1	Batch 3660	Train Loss:1.723	Learning rate:0.00011
Loss_accusation:0.890	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.485	Current_loss:1.376	
Epoch 1	Batch 3680	Train Loss:1.722	Learning rate:0.00011
Epoch 1	Batch 3700	Train Loss:1.721	Learning rate:0.00011
Epoch 1	Batch 3720	Train Loss:1.719	Learning rate:0.00011
Loss_accusation:0.833	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.484	Current_loss:1.317	
Epoch 1	Batch 3740	Train Loss:1.718	Learning rate:0.00011
Epoch 1	Batch 3760	Train Loss:1.717	Learning rate:0.00011
Epoch 1	Batch 3780	Train Loss:1.716	Learning rate:0.00011
Loss_accusation:1.217	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.483	Current_loss:1.701	
Epoch 1	Batch 3800	Train Loss:1.716	Learning rate:0.00011
Epoch 1	Batch 3820	Train Loss:1.715	Learning rate:0.00011
Epoch 1	Batch 3840	Train Loss:1.715	Learning rate:0.00011
Loss_accusation:1.005	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.482	Current_loss:1.487	
Epoch 1	Batch 3860	Train Loss:1.714	Learning rate:0.00011
Epoch 1	Batch 3880	Train Loss:1.713	Learning rate:0.00011
Epoch 1	Batch 3900	Train Loss:1.712	Learning rate:0.00011
Loss_accusation:0.857	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.481	Current_loss:1.338	
('number_examples:', 13094)
('article.y_target_labels:', [137], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('death_lifeimprisonment_score:', 1.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('x.imprisonment_score.target_value:', 0.0, ';predict_value:', 0.0)
('death_lifeimprisonment_score:', 1.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('accusation.y_target_labels:', [97], ';y_predict_labels:', [97])
('death_lifeimprisonment_score:', 1.0)
('macro', 'precison:', '0.944444386145', ';recall:', '0.950310499981', ';f1_score:', 0.9473633624663653)
('accusation_normal_f1_score', 'precison:', '0.954545237603', ';recall:', '0.976743958897', ';f1_score:', 0.9655120201078495)
('accusation_normal_f1_score', 'precison:', '0.979166598669', ';recall:', '0.986013917062', ';f1_score:', 0.982573328826331)
('f1_micro_accusation:', 0.8822452966033149, ';f1_macro_accusation:', 0.8003221633614103)
Epoch 1 ValidLoss:1.272	Macro_f1_accasation:0.800	Micro_f1_accsastion:0.882	Macro_f1_article:0.012 Micro_f1_article:0.012 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 84.12837299823626, ';2.Article Score:', 1.2418513323916969, ';3.Penalty Score:', 68.08261178928645, ';Score ALL:', 153.45283611991442)
going to save check point.
Epoch 1	Batch 3920	Train Loss:1.711	Learning rate:0.00011
Epoch 1	Batch 3940	Train Loss:1.710	Learning rate:0.00011
Epoch 1	Batch 3960	Train Loss:1.709	Learning rate:0.00011
Loss_accusation:1.075	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.480	Current_loss:1.555	
Epoch 1	Batch 3980	Train Loss:1.708	Learning rate:0.00011
Epoch 1	Batch 4000	Train Loss:1.707	Learning rate:0.00011
Epoch 1	Batch 4020	Train Loss:1.705	Learning rate:0.00011
Loss_accusation:1.449	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.480	Current_loss:1.929	
Epoch 1	Batch 4040	Train Loss:1.704	Learning rate:0.00011
Epoch 1	Batch 4060	Train Loss:1.703	Learning rate:0.00011
Epoch 1	Batch 4080	Train Loss:1.703	Learning rate:0.00011
Loss_accusation:1.213	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.479	Current_loss:1.691	
Epoch 1	Batch 4100	Train Loss:1.702	Learning rate:0.00011
Epoch 1	Batch 4120	Train Loss:1.701	Learning rate:0.00011
Epoch 1	Batch 4140	Train Loss:1.700	Learning rate:0.00011
Loss_accusation:0.901	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.478	Current_loss:1.379	
Epoch 1	Batch 4160	Train Loss:1.698	Learning rate:0.00011
Epoch 1	Batch 4180	Train Loss:1.697	Learning rate:0.00011
Epoch 1	Batch 4200	Train Loss:1.696	Learning rate:0.00011
Loss_accusation:1.308	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.477	Current_loss:1.785	
Epoch 1	Batch 4220	Train Loss:1.695	Learning rate:0.00011
Epoch 1	Batch 4240	Train Loss:1.693	Learning rate:0.00011
Epoch 1	Batch 4260	Train Loss:1.692	Learning rate:0.00011
Loss_accusation:0.963	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.476	Current_loss:1.439	
Epoch 1	Batch 4280	Train Loss:1.691	Learning rate:0.00011
Epoch 1	Batch 4300	Train Loss:1.690	Learning rate:0.00011
Epoch 1	Batch 4320	Train Loss:1.689	Learning rate:0.00011
Loss_accusation:1.041	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.475	Current_loss:1.516	
Epoch 1	Batch 4340	Train Loss:1.689	Learning rate:0.00011
Epoch 1	Batch 4360	Train Loss:1.688	Learning rate:0.00011
Epoch 1	Batch 4380	Train Loss:1.687	Learning rate:0.00011
Loss_accusation:0.942	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.474	Current_loss:1.416	
Epoch 1	Batch 4400	Train Loss:1.686	Learning rate:0.00011
Epoch 1	Batch 4420	Train Loss:1.685	Learning rate:0.00011
Epoch 1	Batch 4440	Train Loss:1.684	Learning rate:0.00011
Loss_accusation:0.903	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.474	Current_loss:1.377	
Epoch 1	Batch 4460	Train Loss:1.683	Learning rate:0.00011
Epoch 1	Batch 4480	Train Loss:1.681	Learning rate:0.00011
Epoch 1	Batch 4500	Train Loss:1.680	Learning rate:0.00011
Loss_accusation:0.944	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.473	Current_loss:1.417	
Epoch 1	Batch 4520	Train Loss:1.678	Learning rate:0.00011
Epoch 1	Batch 4540	Train Loss:1.677	Learning rate:0.00011
Epoch 1	Batch 4560	Train Loss:1.676	Learning rate:0.00011
Loss_accusation:1.132	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.472	Current_loss:1.603	
Epoch 1	Batch 4580	Train Loss:1.676	Learning rate:0.00011
Epoch 1	Batch 4600	Train Loss:1.675	Learning rate:0.00011
Epoch 1	Batch 4620	Train Loss:1.674	Learning rate:0.00011
Loss_accusation:0.916	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.471	Current_loss:1.387	
Epoch 1	Batch 4640	Train Loss:1.673	Learning rate:0.00011
Epoch 1	Batch 4660	Train Loss:1.673	Learning rate:0.00011
Epoch 1	Batch 4680	Train Loss:1.672	Learning rate:0.00011
Loss_accusation:0.999	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.470	Current_loss:1.469	
Epoch 1	Batch 4700	Train Loss:1.671	Learning rate:0.00011
Epoch 1	Batch 4720	Train Loss:1.670	Learning rate:0.00011
Epoch 1	Batch 4740	Train Loss:1.669	Learning rate:0.00011
Loss_accusation:0.978	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.470	Current_loss:1.448	
Epoch 1	Batch 4760	Train Loss:1.668	Learning rate:0.00011
Epoch 1	Batch 4780	Train Loss:1.667	Learning rate:0.00011
Epoch 1	Batch 4800	Train Loss:1.666	Learning rate:0.00011
Loss_accusation:1.269	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.469	Current_loss:1.738	
Epoch 1	Batch 4820	Train Loss:1.666	Learning rate:0.00011
Epoch 1	Batch 4840	Train Loss:1.665	Learning rate:0.00011
Epoch 1	Batch 4860	Train Loss:1.665	Learning rate:0.00011
Loss_accusation:0.881	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.468	Current_loss:1.350	
Epoch 1	Batch 4880	Train Loss:1.664	Learning rate:0.00011
Epoch 1	Batch 4900	Train Loss:1.663	Learning rate:0.00011
Epoch 1	Batch 4920	Train Loss:1.662	Learning rate:0.00011
Loss_accusation:0.954	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.468	Current_loss:1.422	
Epoch 1	Batch 4940	Train Loss:1.662	Learning rate:0.00011
Epoch 1	Batch 4960	Train Loss:1.661	Learning rate:0.00011
Epoch 1	Batch 4980	Train Loss:1.660	Learning rate:0.00011
Loss_accusation:1.028	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.467	Current_loss:1.495	
Epoch 1	Batch 5000	Train Loss:1.658	Learning rate:0.00011
Epoch 1	Batch 5020	Train Loss:1.657	Learning rate:0.00011
Epoch 1	Batch 5040	Train Loss:1.656	Learning rate:0.00011
Loss_accusation:0.993	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.466	Current_loss:1.459	
going to increment epoch counter....
(1, 1, True)
('number_examples:', 13094)
('death_lifeimprisonment_score:', 1.0)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('accusation.y_target_labels:', [92], ';y_predict_labels:', [92])
('accusation.y_target_labels:', [24], ';y_predict_labels:', [24])
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score:', 1.0)
('accusation.y_target_labels:', [48], ';y_predict_labels:', [48])
('death_lifeimprisonment_score:', 1.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('article.y_target_labels:', [3], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('macro', 'precison:', '0.726744143794', ';recall:', '0.905797035812', ';f1_score:', 0.8064466210500252)
('f1_micro_accusation:', 0.887542538441948, ';f1_macro_accusation:', 0.8084842312673051)
()
Epoch 1 ValidLoss:1.199	Macro_f1_accasation:0.808	Micro_f1_accsastion:0.888	Macro_f1_article:0.012	Micro_f1_article:0.012	Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('===>1.Accasation Score:', 84.80133848546265, ';2.Article Score:', 1.2415920217868668, ';3.Penalty Score:', 69.2830814428352, ';Score ALL:', 155.3260119500847)
going to save check point.
Epoch 2	Batch 20	Train Loss:1.690	Learning rate:0.00011
Epoch 2	Batch 40	Train Loss:1.665	Learning rate:0.00011
Epoch 2	Batch 60	Train Loss:1.625	Learning rate:0.00011
Loss_accusation:0.707	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.466	Current_loss:1.173	
Epoch 2	Batch 80	Train Loss:1.606	Learning rate:0.00011
Epoch 2	Batch 100	Train Loss:1.584	Learning rate:0.00011
Epoch 2	Batch 120	Train Loss:1.578	Learning rate:0.00011
Loss_accusation:0.870	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.465	Current_loss:1.335	
Epoch 2	Batch 140	Train Loss:1.561	Learning rate:0.00011
Epoch 2	Batch 160	Train Loss:1.547	Learning rate:0.00011
Epoch 2	Batch 180	Train Loss:1.536	Learning rate:0.00011
Loss_accusation:1.106	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.464	Current_loss:1.570	
Epoch 2	Batch 200	Train Loss:1.518	Learning rate:0.00011
Epoch 2	Batch 220	Train Loss:1.508	Learning rate:0.00011
Epoch 2	Batch 240	Train Loss:1.501	Learning rate:0.00011
Loss_accusation:0.757	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.463	Current_loss:1.221	
Epoch 2	Batch 260	Train Loss:1.501	Learning rate:0.00011
Epoch 2	Batch 280	Train Loss:1.510	Learning rate:0.00011
Epoch 2	Batch 300	Train Loss:1.515	Learning rate:0.00011
Loss_accusation:1.277	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.463	Current_loss:1.740	
Epoch 2	Batch 320	Train Loss:1.516	Learning rate:0.00011
Epoch 2	Batch 340	Train Loss:1.512	Learning rate:0.00011
Epoch 2	Batch 360	Train Loss:1.512	Learning rate:0.00011
Loss_accusation:1.031	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.462	Current_loss:1.493	
Epoch 2	Batch 380	Train Loss:1.511	Learning rate:0.00011
Epoch 2	Batch 400	Train Loss:1.514	Learning rate:0.00011
Epoch 2	Batch 420	Train Loss:1.511	Learning rate:0.00011
Loss_accusation:0.717	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.462	Current_loss:1.178	
Epoch 2	Batch 440	Train Loss:1.508	Learning rate:0.00011
Epoch 2	Batch 460	Train Loss:1.506	Learning rate:0.00011
Epoch 2	Batch 480	Train Loss:1.502	Learning rate:0.00011
Loss_accusation:0.971	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.461	Current_loss:1.432	
Epoch 2	Batch 500	Train Loss:1.496	Learning rate:0.00011
Epoch 2	Batch 520	Train Loss:1.498	Learning rate:0.00011
Epoch 2	Batch 540	Train Loss:1.506	Learning rate:0.00011
Loss_accusation:0.921	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.460	Current_loss:1.381	
Epoch 2	Batch 560	Train Loss:1.507	Learning rate:0.00011
Epoch 2	Batch 580	Train Loss:1.507	Learning rate:0.00011
Epoch 2	Batch 600	Train Loss:1.508	Learning rate:0.00011
Loss_accusation:0.940	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.460	Current_loss:1.400	
Epoch 2	Batch 620	Train Loss:1.509	Learning rate:0.00011
Epoch 2	Batch 640	Train Loss:1.509	Learning rate:0.00011
Epoch 2	Batch 660	Train Loss:1.508	Learning rate:0.00011
Loss_accusation:1.142	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.459	Current_loss:1.602	
Epoch 2	Batch 680	Train Loss:1.505	Learning rate:0.00011
Epoch 2	Batch 700	Train Loss:1.503	Learning rate:0.00011
Epoch 2	Batch 720	Train Loss:1.501	Learning rate:0.00011
Loss_accusation:0.903	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.459	Current_loss:1.361	
Epoch 2	Batch 740	Train Loss:1.500	Learning rate:0.00011
Epoch 2	Batch 760	Train Loss:1.501	Learning rate:0.00011
Epoch 2	Batch 780	Train Loss:1.507	Learning rate:0.00011
Loss_accusation:1.126	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.458	Current_loss:1.584	
Epoch 2	Batch 800	Train Loss:1.511	Learning rate:0.00011
Epoch 2	Batch 820	Train Loss:1.512	Learning rate:0.00011
Epoch 2	Batch 840	Train Loss:1.513	Learning rate:0.00011
Loss_accusation:1.115	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.458	Current_loss:1.572	
Epoch 2	Batch 860	Train Loss:1.513	Learning rate:0.00011
Epoch 2	Batch 880	Train Loss:1.511	Learning rate:0.00011
Epoch 2	Batch 900	Train Loss:1.511	Learning rate:0.00011
Loss_accusation:0.782	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.457	Current_loss:1.239	
Epoch 2	Batch 920	Train Loss:1.510	Learning rate:0.00011
Epoch 2	Batch 940	Train Loss:1.509	Learning rate:0.00011
Epoch 2	Batch 960	Train Loss:1.507	Learning rate:0.00011
Loss_accusation:0.777	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.457	Current_loss:1.234	
Epoch 2	Batch 980	Train Loss:1.505	Learning rate:0.00011
Epoch 2	Batch 1000	Train Loss:1.503	Learning rate:0.00011
Epoch 2	Batch 1020	Train Loss:1.502	Learning rate:0.00011
Loss_accusation:1.172	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.456	Current_loss:1.628	
Epoch 2	Batch 1040	Train Loss:1.503	Learning rate:0.00011
Epoch 2	Batch 1060	Train Loss:1.504	Learning rate:0.00011
Epoch 2	Batch 1080	Train Loss:1.503	Learning rate:0.00011
Loss_accusation:0.961	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.456	Current_loss:1.417	
Epoch 2	Batch 1100	Train Loss:1.504	Learning rate:0.00011
Epoch 2	Batch 1120	Train Loss:1.502	Learning rate:0.00011
Epoch 2	Batch 1140	Train Loss:1.502	Learning rate:0.00011
Loss_accusation:0.975	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.455	Current_loss:1.430	
Epoch 2	Batch 1160	Train Loss:1.500	Learning rate:0.00011
Epoch 2	Batch 1180	Train Loss:1.499	Learning rate:0.00011
Epoch 2	Batch 1200	Train Loss:1.498	Learning rate:0.00011
Loss_accusation:1.212	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.454	Current_loss:1.667	
Epoch 2	Batch 1220	Train Loss:1.497	Learning rate:0.00011
Epoch 2	Batch 1240	Train Loss:1.496	Learning rate:0.00011
Epoch 2	Batch 1260	Train Loss:1.494	Learning rate:0.00011
Loss_accusation:1.588	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.454	Current_loss:2.042	
Epoch 2	Batch 1280	Train Loss:1.496	Learning rate:0.00011
Epoch 2	Batch 1300	Train Loss:1.498	Learning rate:0.00011
Epoch 2	Batch 1320	Train Loss:1.499	Learning rate:0.00011
Loss_accusation:0.959	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.453	Current_loss:1.412	
Epoch 2	Batch 1340	Train Loss:1.498	Learning rate:0.00011
Epoch 2	Batch 1360	Train Loss:1.498	Learning rate:0.00011
Epoch 2	Batch 1380	Train Loss:1.497	Learning rate:0.00011
Loss_accusation:1.040	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.452	Current_loss:1.492	
Epoch 2	Batch 1400	Train Loss:1.496	Learning rate:0.00011
Epoch 2	Batch 1420	Train Loss:1.496	Learning rate:0.00011
Epoch 2	Batch 1440	Train Loss:1.495	Learning rate:0.00011
Loss_accusation:0.838	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.452	Current_loss:1.290	
Epoch 2	Batch 1460	Train Loss:1.492	Learning rate:0.00011
Epoch 2	Batch 1480	Train Loss:1.491	Learning rate:0.00011
Epoch 2	Batch 1500	Train Loss:1.490	Learning rate:0.00011
Loss_accusation:0.927	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.451	Current_loss:1.378	
Epoch 2	Batch 1520	Train Loss:1.489	Learning rate:0.00011
Epoch 2	Batch 1540	Train Loss:1.489	Learning rate:0.00011
Epoch 2	Batch 1560	Train Loss:1.490	Learning rate:0.00011
Loss_accusation:1.128	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.451	Current_loss:1.579	
Epoch 2	Batch 1580	Train Loss:1.489	Learning rate:0.00011
Epoch 2	Batch 1600	Train Loss:1.489	Learning rate:0.00011
Epoch 2	Batch 1620	Train Loss:1.490	Learning rate:0.00011
Loss_accusation:1.224	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.450	Current_loss:1.674	
Epoch 2	Batch 1640	Train Loss:1.489	Learning rate:0.00011
Epoch 2	Batch 1660	Train Loss:1.488	Learning rate:0.00011
Epoch 2	Batch 1680	Train Loss:1.486	Learning rate:0.00011
Loss_accusation:0.971	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.449	Current_loss:1.420	
Epoch 2	Batch 1700	Train Loss:1.484	Learning rate:0.00011
Epoch 2	Batch 1720	Train Loss:1.483	Learning rate:0.00011
Epoch 2	Batch 1740	Train Loss:1.482	Learning rate:0.00011
Loss_accusation:0.832	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.449	Current_loss:1.281	
Epoch 2	Batch 1760	Train Loss:1.480	Learning rate:0.00011
Epoch 2	Batch 1780	Train Loss:1.480	Learning rate:0.00011
Epoch 2	Batch 1800	Train Loss:1.481	Learning rate:0.00011
Loss_accusation:1.073	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.448	Current_loss:1.522	
Epoch 2	Batch 1820	Train Loss:1.481	Learning rate:0.00011
Epoch 2	Batch 1840	Train Loss:1.481	Learning rate:0.00011
Epoch 2	Batch 1860	Train Loss:1.481	Learning rate:0.00011
Loss_accusation:1.117	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.448	Current_loss:1.565	
Epoch 2	Batch 1880	Train Loss:1.480	Learning rate:0.00011
Epoch 2	Batch 1900	Train Loss:1.480	Learning rate:0.00011
Epoch 2	Batch 1920	Train Loss:1.479	Learning rate:0.00011
Loss_accusation:1.083	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.447	Current_loss:1.530	
Epoch 2	Batch 1940	Train Loss:1.478	Learning rate:0.00011
Epoch 2	Batch 1960	Train Loss:1.477	Learning rate:0.00011
Epoch 2	Batch 1980	Train Loss:1.476	Learning rate:0.00011
Loss_accusation:1.103	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.446	Current_loss:1.549	
Epoch 2	Batch 2000	Train Loss:1.475	Learning rate:0.00011
Epoch 2	Batch 2020	Train Loss:1.474	Learning rate:0.00011
Epoch 2	Batch 2040	Train Loss:1.475	Learning rate:0.00011
Loss_accusation:0.926	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.446	Current_loss:1.372	
Epoch 2	Batch 2060	Train Loss:1.476	Learning rate:0.00011
Epoch 2	Batch 2080	Train Loss:1.477	Learning rate:0.00011
Epoch 2	Batch 2100	Train Loss:1.477	Learning rate:0.00011
Loss_accusation:0.961	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.446	Current_loss:1.406	
Epoch 2	Batch 2120	Train Loss:1.476	Learning rate:0.00011
Epoch 2	Batch 2140	Train Loss:1.475	Learning rate:0.00011
Epoch 2	Batch 2160	Train Loss:1.474	Learning rate:0.00011
Loss_accusation:1.105	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.445	Current_loss:1.550	
Epoch 2	Batch 2180	Train Loss:1.474	Learning rate:0.00011
Epoch 2	Batch 2200	Train Loss:1.474	Learning rate:0.00011
Epoch 2	Batch 2220	Train Loss:1.473	Learning rate:0.00011
Loss_accusation:0.832	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.445	Current_loss:1.276	
Epoch 2	Batch 2240	Train Loss:1.472	Learning rate:0.00011
Epoch 2	Batch 2260	Train Loss:1.470	Learning rate:0.00011
Epoch 2	Batch 2280	Train Loss:1.469	Learning rate:0.00011
Loss_accusation:0.942	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.444	Current_loss:1.386	
Epoch 2	Batch 2300	Train Loss:1.470	Learning rate:0.00011
Epoch 2	Batch 2320	Train Loss:1.471	Learning rate:0.00011
Epoch 2	Batch 2340	Train Loss:1.471	Learning rate:0.00011
Loss_accusation:1.022	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.444	Current_loss:1.466	
Epoch 2	Batch 2360	Train Loss:1.470	Learning rate:0.00011
Epoch 2	Batch 2380	Train Loss:1.470	Learning rate:0.00011
Epoch 2	Batch 2400	Train Loss:1.469	Learning rate:0.00011
Loss_accusation:0.644	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.443	Current_loss:1.087	
Epoch 2	Batch 2420	Train Loss:1.467	Learning rate:0.00011
Epoch 2	Batch 2440	Train Loss:1.466	Learning rate:0.00011
Epoch 2	Batch 2460	Train Loss:1.465	Learning rate:0.00011
Loss_accusation:0.968	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.442	Current_loss:1.410	
Epoch 2	Batch 2480	Train Loss:1.464	Learning rate:0.00011
Epoch 2	Batch 2500	Train Loss:1.462	Learning rate:0.00011
Epoch 2	Batch 2520	Train Loss:1.461	Learning rate:0.00011
Loss_accusation:0.902	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.442	Current_loss:1.344	
Epoch 2	Batch 2540	Train Loss:1.461	Learning rate:0.00011
Epoch 2	Batch 2560	Train Loss:1.462	Learning rate:0.00011
Epoch 2	Batch 2580	Train Loss:1.462	Learning rate:0.00011
Loss_accusation:1.413	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.441	Current_loss:1.855	
Epoch 2	Batch 2600	Train Loss:1.462	Learning rate:0.00011
Epoch 2	Batch 2620	Train Loss:1.462	Learning rate:0.00011
Epoch 2	Batch 2640	Train Loss:1.461	Learning rate:0.00011
Loss_accusation:0.857	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.441	Current_loss:1.298	
Epoch 2	Batch 2660	Train Loss:1.461	Learning rate:0.00011
Epoch 2	Batch 2680	Train Loss:1.460	Learning rate:0.00011
Epoch 2	Batch 2700	Train Loss:1.458	Learning rate:0.00011
Loss_accusation:0.730	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.440	Current_loss:1.170	
Epoch 2	Batch 2720	Train Loss:1.457	Learning rate:0.00011
Epoch 2	Batch 2740	Train Loss:1.456	Learning rate:0.00011
Epoch 2	Batch 2760	Train Loss:1.455	Learning rate:0.00011
Loss_accusation:0.556	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.440	Current_loss:0.996	
Epoch 2	Batch 2780	Train Loss:1.454	Learning rate:0.00011
Epoch 2	Batch 2800	Train Loss:1.454	Learning rate:0.00011
Epoch 2	Batch 2820	Train Loss:1.454	Learning rate:0.00011
Loss_accusation:0.883	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.439	Current_loss:1.322	
Epoch 2	Batch 2840	Train Loss:1.455	Learning rate:0.00011
Epoch 2	Batch 2860	Train Loss:1.454	Learning rate:0.00011
Epoch 2	Batch 2880	Train Loss:1.454	Learning rate:0.00011
Loss_accusation:0.767	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.439	Current_loss:1.206	
Epoch 2	Batch 2900	Train Loss:1.453	Learning rate:0.00011
Epoch 2	Batch 2920	Train Loss:1.452	Learning rate:0.00011
Epoch 2	Batch 2940	Train Loss:1.452	Learning rate:0.00011
Loss_accusation:0.849	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.439	Current_loss:1.287	
Epoch 2	Batch 2960	Train Loss:1.451	Learning rate:0.00011
Epoch 2	Batch 2980	Train Loss:1.450	Learning rate:0.00011
Epoch 2	Batch 3000	Train Loss:1.449	Learning rate:0.00011
Loss_accusation:0.873	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.438	Current_loss:1.311	
Epoch 2	Batch 3020	Train Loss:1.448	Learning rate:0.00011
Epoch 2	Batch 3040	Train Loss:1.448	Learning rate:0.00011
Epoch 2	Batch 3060	Train Loss:1.448	Learning rate:0.00011
Loss_accusation:1.080	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.437	Current_loss:1.518	
Epoch 2	Batch 3080	Train Loss:1.449	Learning rate:0.00011
Epoch 2	Batch 3100	Train Loss:1.448	Learning rate:0.00011
Epoch 2	Batch 3120	Train Loss:1.448	Learning rate:0.00011
Loss_accusation:1.120	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.437	Current_loss:1.557	
Epoch 2	Batch 3140	Train Loss:1.448	Learning rate:0.00011
Epoch 2	Batch 3160	Train Loss:1.447	Learning rate:0.00011
Epoch 2	Batch 3180	Train Loss:1.446	Learning rate:0.00011
Loss_accusation:0.630	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.436	Current_loss:1.066	
Epoch 2	Batch 3200	Train Loss:1.446	Learning rate:0.00011
Epoch 2	Batch 3220	Train Loss:1.445	Learning rate:0.00011
Epoch 2	Batch 3240	Train Loss:1.444	Learning rate:0.00011
Loss_accusation:1.055	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.436	Current_loss:1.490	
Epoch 2	Batch 3260	Train Loss:1.444	Learning rate:0.00011
Epoch 2	Batch 3280	Train Loss:1.442	Learning rate:0.00011
Epoch 2	Batch 3300	Train Loss:1.443	Learning rate:0.00011
Loss_accusation:0.899	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.435	Current_loss:1.334	
Epoch 2	Batch 3320	Train Loss:1.443	Learning rate:0.00011
Epoch 2	Batch 3340	Train Loss:1.443	Learning rate:0.00011
Epoch 2	Batch 3360	Train Loss:1.443	Learning rate:0.00011
Loss_accusation:1.051	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.435	Current_loss:1.486	
Epoch 2	Batch 3380	Train Loss:1.443	Learning rate:0.00011
Epoch 2	Batch 3400	Train Loss:1.443	Learning rate:0.00011
Epoch 2	Batch 3420	Train Loss:1.442	Learning rate:0.00011
Loss_accusation:0.869	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.435	Current_loss:1.304	
Epoch 2	Batch 3440	Train Loss:1.442	Learning rate:0.00011
Epoch 2	Batch 3460	Train Loss:1.441	Learning rate:0.00011
Epoch 2	Batch 3480	Train Loss:1.440	Learning rate:0.00011
Loss_accusation:0.701	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.434	Current_loss:1.136	
Epoch 2	Batch 3500	Train Loss:1.439	Learning rate:0.00011
Epoch 2	Batch 3520	Train Loss:1.439	Learning rate:0.00011
Epoch 2	Batch 3540	Train Loss:1.438	Learning rate:0.00011
Loss_accusation:0.947	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.434	Current_loss:1.380	
Epoch 2	Batch 3560	Train Loss:1.439	Learning rate:0.00011
Epoch 2	Batch 3580	Train Loss:1.439	Learning rate:0.00011
Epoch 2	Batch 3600	Train Loss:1.439	Learning rate:0.00011
Loss_accusation:1.323	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.433	Current_loss:1.756	
Epoch 2	Batch 3620	Train Loss:1.439	Learning rate:0.00011
Epoch 2	Batch 3640	Train Loss:1.438	Learning rate:0.00011
Epoch 2	Batch 3660	Train Loss:1.437	Learning rate:0.00011
Loss_accusation:1.048	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.433	Current_loss:1.481	
Epoch 2	Batch 3680	Train Loss:1.436	Learning rate:0.00011
Epoch 2	Batch 3700	Train Loss:1.436	Learning rate:0.00011
Epoch 2	Batch 3720	Train Loss:1.435	Learning rate:0.00011
Loss_accusation:0.779	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.432	Current_loss:1.211	
Epoch 2	Batch 3740	Train Loss:1.434	Learning rate:0.00011
Epoch 2	Batch 3760	Train Loss:1.433	Learning rate:0.00011
Epoch 2	Batch 3780	Train Loss:1.433	Learning rate:0.00011
Loss_accusation:0.862	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.431	Current_loss:1.294	
Epoch 2	Batch 3800	Train Loss:1.433	Learning rate:0.00011
Epoch 2	Batch 3820	Train Loss:1.433	Learning rate:0.00011
Epoch 2	Batch 3840	Train Loss:1.433	Learning rate:0.00011
Loss_accusation:1.009	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.431	Current_loss:1.441	
Epoch 2	Batch 3860	Train Loss:1.433	Learning rate:0.00011
Epoch 2	Batch 3880	Train Loss:1.432	Learning rate:0.00011
Epoch 2	Batch 3900	Train Loss:1.432	Learning rate:0.00011
Loss_accusation:0.772	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.431	Current_loss:1.203	
('number_examples:', 13094)
('lifeimprisionment.y_target_labels:', [1], ';y_predict_labels:', [0, 1])
('accusation.y_target_labels:', [65], ';y_predict_labels:', [65])
('accusation.y_target_labels:', [58], ';y_predict_labels:', [58, 87])
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score:', 1.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('x.imprisonment_score.target_value:', 4.0, ';predict_value:', 0.0)
('x.imprisonment_score.target_value:', 8.0, ';predict_value:', 0.0)
('imprisonment_score:', 0.0)
('accusation.y_target_labels:', [58], ';y_predict_labels:', [194])
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('accusation.y_target_labels:', [149], ';y_predict_labels:', [149])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('article.y_target_labels:', [137], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('accusation_normal_f1_score', 'precison:', '0.999995000025', ';recall:', '0.666664444452', ';f1_score:', 0.7999920000399998)
('f1_micro_accusation:', 0.8976009188585174, ';f1_macro_accusation:', 0.8447892454293051)
Epoch 2 ValidLoss:1.094	Macro_f1_accasation:0.845	Micro_f1_accsastion:0.898	Macro_f1_article:0.012 Micro_f1_article:0.012 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 87.11950821439113, ';2.Article Score:', 1.2412722962314542, ';3.Penalty Score:', 68.34558153474691, ';Score ALL:', 156.7063620453695)
going to save check point.
Epoch 2	Batch 3920	Train Loss:1.431	Learning rate:0.00011
Epoch 2	Batch 3940	Train Loss:1.431	Learning rate:0.00011
Epoch 2	Batch 3960	Train Loss:1.430	Learning rate:0.00011
Loss_accusation:0.952	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.430	Current_loss:1.382	
Epoch 2	Batch 3980	Train Loss:1.430	Learning rate:0.00011
Epoch 2	Batch 4000	Train Loss:1.429	Learning rate:0.00011
Epoch 2	Batch 4020	Train Loss:1.427	Learning rate:0.00011
Loss_accusation:1.107	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.430	Current_loss:1.537	
Epoch 2	Batch 4040	Train Loss:1.427	Learning rate:0.00011
Epoch 2	Batch 4060	Train Loss:1.426	Learning rate:0.00011
Epoch 2	Batch 4080	Train Loss:1.426	Learning rate:0.00011
Loss_accusation:0.883	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.429	Current_loss:1.312	
Epoch 2	Batch 4100	Train Loss:1.426	Learning rate:0.00011
Epoch 2	Batch 4120	Train Loss:1.426	Learning rate:0.00011
Epoch 2	Batch 4140	Train Loss:1.425	Learning rate:0.00011
Loss_accusation:0.860	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.429	Current_loss:1.289	
Epoch 2	Batch 4160	Train Loss:1.424	Learning rate:0.00011
Epoch 2	Batch 4180	Train Loss:1.423	Learning rate:0.00011
Epoch 2	Batch 4200	Train Loss:1.423	Learning rate:0.00011
Loss_accusation:1.138	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.428	Current_loss:1.566	
Epoch 2	Batch 4220	Train Loss:1.422	Learning rate:0.00011
Epoch 2	Batch 4240	Train Loss:1.421	Learning rate:0.00011
Epoch 2	Batch 4260	Train Loss:1.420	Learning rate:0.00011
Loss_accusation:0.787	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.428	Current_loss:1.214	
Epoch 2	Batch 4280	Train Loss:1.419	Learning rate:0.00011
Epoch 2	Batch 4300	Train Loss:1.419	Learning rate:0.00011
Epoch 2	Batch 4320	Train Loss:1.419	Learning rate:0.00011
Loss_accusation:0.879	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.428	Current_loss:1.307	
Epoch 2	Batch 4340	Train Loss:1.419	Learning rate:0.00011
Epoch 2	Batch 4360	Train Loss:1.418	Learning rate:0.00011
Epoch 2	Batch 4380	Train Loss:1.418	Learning rate:0.00011
Loss_accusation:0.812	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.427	Current_loss:1.239	
Epoch 2	Batch 4400	Train Loss:1.417	Learning rate:0.00011
Epoch 2	Batch 4420	Train Loss:1.417	Learning rate:0.00011
Epoch 2	Batch 4440	Train Loss:1.416	Learning rate:0.00011
Loss_accusation:0.786	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.427	Current_loss:1.213	
Epoch 2	Batch 4460	Train Loss:1.415	Learning rate:0.00011
Epoch 2	Batch 4480	Train Loss:1.415	Learning rate:0.00011
Epoch 2	Batch 4500	Train Loss:1.414	Learning rate:0.00011
Loss_accusation:0.778	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.426	Current_loss:1.205	
Epoch 2	Batch 4520	Train Loss:1.413	Learning rate:0.00011
Epoch 2	Batch 4540	Train Loss:1.412	Learning rate:0.00011
Epoch 2	Batch 4560	Train Loss:1.412	Learning rate:0.00011
Loss_accusation:0.899	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.426	Current_loss:1.325	
Epoch 2	Batch 4580	Train Loss:1.412	Learning rate:0.00011
Epoch 2	Batch 4600	Train Loss:1.412	Learning rate:0.00011
Epoch 2	Batch 4620	Train Loss:1.411	Learning rate:0.00011
Loss_accusation:0.855	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.425	Current_loss:1.280	
Epoch 2	Batch 4640	Train Loss:1.411	Learning rate:0.00011
Epoch 2	Batch 4660	Train Loss:1.411	Learning rate:0.00011
Epoch 2	Batch 4680	Train Loss:1.410	Learning rate:0.00011
Loss_accusation:0.828	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.425	Current_loss:1.253	
Epoch 2	Batch 4700	Train Loss:1.410	Learning rate:0.00011
Epoch 2	Batch 4720	Train Loss:1.409	Learning rate:0.00011
Epoch 2	Batch 4740	Train Loss:1.408	Learning rate:0.00011
Loss_accusation:0.897	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.424	Current_loss:1.322	
Epoch 2	Batch 4760	Train Loss:1.408	Learning rate:0.00011
Epoch 2	Batch 4780	Train Loss:1.407	Learning rate:0.00011
Epoch 2	Batch 4800	Train Loss:1.407	Learning rate:0.00011
Loss_accusation:1.020	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.424	Current_loss:1.444	
Epoch 2	Batch 4820	Train Loss:1.407	Learning rate:0.00011
Epoch 2	Batch 4840	Train Loss:1.407	Learning rate:0.00011
Epoch 2	Batch 4860	Train Loss:1.407	Learning rate:0.00011
Loss_accusation:0.734	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.424	Current_loss:1.158	
Epoch 2	Batch 4880	Train Loss:1.407	Learning rate:0.00011
Epoch 2	Batch 4900	Train Loss:1.406	Learning rate:0.00011
Epoch 2	Batch 4920	Train Loss:1.405	Learning rate:0.00011
Loss_accusation:0.958	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.423	Current_loss:1.382	
Epoch 2	Batch 4940	Train Loss:1.405	Learning rate:0.00011
Epoch 2	Batch 4960	Train Loss:1.405	Learning rate:0.00011
Epoch 2	Batch 4980	Train Loss:1.404	Learning rate:0.00011
Loss_accusation:0.805	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.423	Current_loss:1.228	
Epoch 2	Batch 5000	Train Loss:1.403	Learning rate:0.00011
Epoch 2	Batch 5020	Train Loss:1.402	Learning rate:0.00011
Epoch 2	Batch 5040	Train Loss:1.402	Learning rate:0.00011
Loss_accusation:0.785	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.423	Current_loss:1.208	
going to increment epoch counter....
(2, 1, True)
('number_examples:', 13094)
('death_lifeimprisonment_score:', 1.0)
('imprisonment_score:', 0.0)
('article.y_target_labels:', [131], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('death_lifeimprisonment_score:', 1.0)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score:', 1.0)
('accusation.y_target_labels:', [116], ';y_predict_labels:', [116])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('x.imprisonment_score.target_value:', 24.0, ';predict_value:', 0.0)
('macro', 'precison:', '0.0178462009667', ';recall:', '0.999999957082', ';f1_score:', 0.035066251866102134)
('f1_micro_accusation:', 0.9013335522263902, ';f1_macro_accusation:', 0.8543756972783288)
()
Epoch 2 ValidLoss:1.060	Macro_f1_accasation:0.854	Micro_f1_accsastion:0.901	Macro_f1_article:0.012	Micro_f1_article:0.012	Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('===>1.Accasation Score:', 87.78546247523596, ';2.Article Score:', 1.241667530519186, ';3.Penalty Score:', 68.44719508687633, ';Score ALL:', 157.4743250926315)
going to save check point.
(0, 'Going to decay learning rate by half.')
(1, 'Going to decay learning rate by half.')
Epoch 3	Batch 20	Train Loss:1.475	Learning rate:0.00004
Epoch 3	Batch 40	Train Loss:1.446	Learning rate:0.00004
Epoch 3	Batch 60	Train Loss:1.434	Learning rate:0.00004
Loss_accusation:0.741	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.422	Current_loss:1.163	
Epoch 3	Batch 80	Train Loss:1.423	Learning rate:0.00004
Epoch 3	Batch 100	Train Loss:1.410	Learning rate:0.00004
Epoch 3	Batch 120	Train Loss:1.403	Learning rate:0.00004
Loss_accusation:0.832	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.421	Current_loss:1.253	
Epoch 3	Batch 140	Train Loss:1.392	Learning rate:0.00004
Epoch 3	Batch 160	Train Loss:1.382	Learning rate:0.00004
Epoch 3	Batch 180	Train Loss:1.376	Learning rate:0.00004
Loss_accusation:1.125	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.421	Current_loss:1.546	
Epoch 3	Batch 200	Train Loss:1.360	Learning rate:0.00004
Epoch 3	Batch 220	Train Loss:1.354	Learning rate:0.00004
Epoch 3	Batch 240	Train Loss:1.352	Learning rate:0.00004
Loss_accusation:0.613	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.420	Current_loss:1.033	
Epoch 3	Batch 260	Train Loss:1.349	Learning rate:0.00004
Epoch 3	Batch 280	Train Loss:1.357	Learning rate:0.00004
Epoch 3	Batch 300	Train Loss:1.360	Learning rate:0.00004
Loss_accusation:1.095	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.420	Current_loss:1.515	
Epoch 3	Batch 320	Train Loss:1.357	Learning rate:0.00004
Epoch 3	Batch 340	Train Loss:1.355	Learning rate:0.00004
Epoch 3	Batch 360	Train Loss:1.355	Learning rate:0.00004
Loss_accusation:1.053	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.419	Current_loss:1.473	
Epoch 3	Batch 380	Train Loss:1.355	Learning rate:0.00004
Epoch 3	Batch 400	Train Loss:1.359	Learning rate:0.00004
Epoch 3	Batch 420	Train Loss:1.358	Learning rate:0.00004
Loss_accusation:0.606	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.419	Current_loss:1.025	
Epoch 3	Batch 440	Train Loss:1.356	Learning rate:0.00004
Epoch 3	Batch 460	Train Loss:1.355	Learning rate:0.00004
Epoch 3	Batch 480	Train Loss:1.353	Learning rate:0.00004
Loss_accusation:0.795	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.418	Current_loss:1.213	
Epoch 3	Batch 500	Train Loss:1.349	Learning rate:0.00004
Epoch 3	Batch 520	Train Loss:1.352	Learning rate:0.00004
Epoch 3	Batch 540	Train Loss:1.357	Learning rate:0.00004
Loss_accusation:0.811	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.418	Current_loss:1.229	
Epoch 3	Batch 560	Train Loss:1.358	Learning rate:0.00004
Epoch 3	Batch 580	Train Loss:1.358	Learning rate:0.00004
Epoch 3	Batch 600	Train Loss:1.359	Learning rate:0.00004
Loss_accusation:0.781	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.418	Current_loss:1.199	
Epoch 3	Batch 620	Train Loss:1.359	Learning rate:0.00004
Epoch 3	Batch 640	Train Loss:1.358	Learning rate:0.00004
Epoch 3	Batch 660	Train Loss:1.356	Learning rate:0.00004
Loss_accusation:0.931	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.417	Current_loss:1.348	
Epoch 3	Batch 680	Train Loss:1.354	Learning rate:0.00004
Epoch 3	Batch 700	Train Loss:1.353	Learning rate:0.00004
Epoch 3	Batch 720	Train Loss:1.352	Learning rate:0.00004
Loss_accusation:0.782	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.417	Current_loss:1.198	
Epoch 3	Batch 740	Train Loss:1.352	Learning rate:0.00004
Epoch 3	Batch 760	Train Loss:1.351	Learning rate:0.00004
Epoch 3	Batch 780	Train Loss:1.355	Learning rate:0.00004
Loss_accusation:1.016	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.416	Current_loss:1.432	
Epoch 3	Batch 800	Train Loss:1.357	Learning rate:0.00004
Epoch 3	Batch 820	Train Loss:1.357	Learning rate:0.00004
Epoch 3	Batch 840	Train Loss:1.357	Learning rate:0.00004
Loss_accusation:0.979	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.416	Current_loss:1.394	
Epoch 3	Batch 860	Train Loss:1.357	Learning rate:0.00004
Epoch 3	Batch 880	Train Loss:1.356	Learning rate:0.00004
Epoch 3	Batch 900	Train Loss:1.356	Learning rate:0.00004
Loss_accusation:0.755	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.415	Current_loss:1.170	
Epoch 3	Batch 920	Train Loss:1.356	Learning rate:0.00004
Epoch 3	Batch 940	Train Loss:1.355	Learning rate:0.00004
Epoch 3	Batch 960	Train Loss:1.353	Learning rate:0.00004
Loss_accusation:0.666	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.415	Current_loss:1.081	
Epoch 3	Batch 980	Train Loss:1.351	Learning rate:0.00004
Epoch 3	Batch 1000	Train Loss:1.349	Learning rate:0.00004
Epoch 3	Batch 1020	Train Loss:1.349	Learning rate:0.00004
Loss_accusation:0.925	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.415	Current_loss:1.340	
Epoch 3	Batch 1040	Train Loss:1.348	Learning rate:0.00004
Epoch 3	Batch 1060	Train Loss:1.348	Learning rate:0.00004
Epoch 3	Batch 1080	Train Loss:1.347	Learning rate:0.00004
Loss_accusation:0.826	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.414	Current_loss:1.240	
Epoch 3	Batch 1100	Train Loss:1.348	Learning rate:0.00004
Epoch 3	Batch 1120	Train Loss:1.347	Learning rate:0.00004
Epoch 3	Batch 1140	Train Loss:1.346	Learning rate:0.00004
Loss_accusation:0.995	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.414	Current_loss:1.408	
Epoch 3	Batch 1160	Train Loss:1.344	Learning rate:0.00004
Epoch 3	Batch 1180	Train Loss:1.343	Learning rate:0.00004
Epoch 3	Batch 1200	Train Loss:1.341	Learning rate:0.00004
Loss_accusation:1.048	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.413	Current_loss:1.462	
Epoch 3	Batch 1220	Train Loss:1.341	Learning rate:0.00004
Epoch 3	Batch 1240	Train Loss:1.340	Learning rate:0.00004
Epoch 3	Batch 1260	Train Loss:1.339	Learning rate:0.00004
Loss_accusation:1.386	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.413	Current_loss:1.799	
Epoch 3	Batch 1280	Train Loss:1.340	Learning rate:0.00004
Epoch 3	Batch 1300	Train Loss:1.341	Learning rate:0.00004
Epoch 3	Batch 1320	Train Loss:1.341	Learning rate:0.00004
Loss_accusation:0.894	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.413	Current_loss:1.306	
Epoch 3	Batch 1340	Train Loss:1.341	Learning rate:0.00004
Epoch 3	Batch 1360	Train Loss:1.340	Learning rate:0.00004
Epoch 3	Batch 1380	Train Loss:1.340	Learning rate:0.00004
Loss_accusation:0.861	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.412	Current_loss:1.274	
Epoch 3	Batch 1400	Train Loss:1.339	Learning rate:0.00004
Epoch 3	Batch 1420	Train Loss:1.338	Learning rate:0.00004
Epoch 3	Batch 1440	Train Loss:1.338	Learning rate:0.00004
Loss_accusation:0.715	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.412	Current_loss:1.127	
Epoch 3	Batch 1460	Train Loss:1.337	Learning rate:0.00004
Epoch 3	Batch 1480	Train Loss:1.336	Learning rate:0.00004
Epoch 3	Batch 1500	Train Loss:1.335	Learning rate:0.00004
Loss_accusation:0.800	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.411	Current_loss:1.212	
Epoch 3	Batch 1520	Train Loss:1.333	Learning rate:0.00004
Epoch 3	Batch 1540	Train Loss:1.333	Learning rate:0.00004
Epoch 3	Batch 1560	Train Loss:1.333	Learning rate:0.00004
Loss_accusation:0.964	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.411	Current_loss:1.375	
Epoch 3	Batch 1580	Train Loss:1.333	Learning rate:0.00004
Epoch 3	Batch 1600	Train Loss:1.333	Learning rate:0.00004
Epoch 3	Batch 1620	Train Loss:1.333	Learning rate:0.00004
Loss_accusation:1.031	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.411	Current_loss:1.442	
Epoch 3	Batch 1640	Train Loss:1.332	Learning rate:0.00004
Epoch 3	Batch 1660	Train Loss:1.331	Learning rate:0.00004
Epoch 3	Batch 1680	Train Loss:1.330	Learning rate:0.00004
Loss_accusation:1.009	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.410	Current_loss:1.420	
Epoch 3	Batch 1700	Train Loss:1.328	Learning rate:0.00004
Epoch 3	Batch 1720	Train Loss:1.327	Learning rate:0.00004
Epoch 3	Batch 1740	Train Loss:1.326	Learning rate:0.00004
Loss_accusation:0.652	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.410	Current_loss:1.062	
Epoch 3	Batch 1760	Train Loss:1.324	Learning rate:0.00004
Epoch 3	Batch 1780	Train Loss:1.324	Learning rate:0.00004
Epoch 3	Batch 1800	Train Loss:1.324	Learning rate:0.00004
Loss_accusation:0.991	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.410	Current_loss:1.400	
Epoch 3	Batch 1820	Train Loss:1.324	Learning rate:0.00004
Epoch 3	Batch 1840	Train Loss:1.324	Learning rate:0.00004
Epoch 3	Batch 1860	Train Loss:1.324	Learning rate:0.00004
Loss_accusation:1.180	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.409	Current_loss:1.589	
Epoch 3	Batch 1880	Train Loss:1.323	Learning rate:0.00004
Epoch 3	Batch 1900	Train Loss:1.322	Learning rate:0.00004
Epoch 3	Batch 1920	Train Loss:1.322	Learning rate:0.00004
Loss_accusation:0.925	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.409	Current_loss:1.334	
Epoch 3	Batch 1940	Train Loss:1.321	Learning rate:0.00004
Epoch 3	Batch 1960	Train Loss:1.320	Learning rate:0.00004
Epoch 3	Batch 1980	Train Loss:1.319	Learning rate:0.00004
Loss_accusation:0.972	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.409	Current_loss:1.380	
Epoch 3	Batch 2000	Train Loss:1.318	Learning rate:0.00004
Epoch 3	Batch 2020	Train Loss:1.317	Learning rate:0.00004
Epoch 3	Batch 2040	Train Loss:1.317	Learning rate:0.00004
Loss_accusation:0.681	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.408	Current_loss:1.089	
Epoch 3	Batch 2060	Train Loss:1.318	Learning rate:0.00004
Epoch 3	Batch 2080	Train Loss:1.318	Learning rate:0.00004
Epoch 3	Batch 2100	Train Loss:1.318	Learning rate:0.00004
Loss_accusation:0.830	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.408	Current_loss:1.237	
Epoch 3	Batch 2120	Train Loss:1.317	Learning rate:0.00004
Epoch 3	Batch 2140	Train Loss:1.316	Learning rate:0.00004
Epoch 3	Batch 2160	Train Loss:1.316	Learning rate:0.00004
Loss_accusation:0.912	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.408	Current_loss:1.319	
Epoch 3	Batch 2180	Train Loss:1.316	Learning rate:0.00004
Epoch 3	Batch 2200	Train Loss:1.315	Learning rate:0.00004
Epoch 3	Batch 2220	Train Loss:1.315	Learning rate:0.00004
Loss_accusation:0.727	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.407	Current_loss:1.134	
Epoch 3	Batch 2240	Train Loss:1.314	Learning rate:0.00004
Epoch 3	Batch 2260	Train Loss:1.312	Learning rate:0.00004
Epoch 3	Batch 2280	Train Loss:1.312	Learning rate:0.00004
Loss_accusation:0.938	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.407	Current_loss:1.345	
Epoch 3	Batch 2300	Train Loss:1.312	Learning rate:0.00004
Epoch 3	Batch 2320	Train Loss:1.313	Learning rate:0.00004
Epoch 3	Batch 2340	Train Loss:1.313	Learning rate:0.00004
Loss_accusation:0.863	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.407	Current_loss:1.270	
Epoch 3	Batch 2360	Train Loss:1.312	Learning rate:0.00004
Epoch 3	Batch 2380	Train Loss:1.311	Learning rate:0.00004
Epoch 3	Batch 2400	Train Loss:1.310	Learning rate:0.00004
Loss_accusation:0.559	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.406	Current_loss:0.966	
Epoch 3	Batch 2420	Train Loss:1.309	Learning rate:0.00004
Epoch 3	Batch 2440	Train Loss:1.308	Learning rate:0.00004
Epoch 3	Batch 2460	Train Loss:1.307	Learning rate:0.00004
Loss_accusation:0.850	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.406	Current_loss:1.256	
Epoch 3	Batch 2480	Train Loss:1.306	Learning rate:0.00004
Epoch 3	Batch 2500	Train Loss:1.305	Learning rate:0.00004
Epoch 3	Batch 2520	Train Loss:1.304	Learning rate:0.00004
Loss_accusation:0.775	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.406	Current_loss:1.181	
Epoch 3	Batch 2540	Train Loss:1.303	Learning rate:0.00004
Epoch 3	Batch 2560	Train Loss:1.303	Learning rate:0.00004
Epoch 3	Batch 2580	Train Loss:1.303	Learning rate:0.00004
Loss_accusation:1.022	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.405	Current_loss:1.428	
Epoch 3	Batch 2600	Train Loss:1.303	Learning rate:0.00004
Epoch 3	Batch 2620	Train Loss:1.303	Learning rate:0.00004
Epoch 3	Batch 2640	Train Loss:1.302	Learning rate:0.00004
Loss_accusation:0.728	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.405	Current_loss:1.133	
Epoch 3	Batch 2660	Train Loss:1.302	Learning rate:0.00004
Epoch 3	Batch 2680	Train Loss:1.301	Learning rate:0.00004
Epoch 3	Batch 2700	Train Loss:1.299	Learning rate:0.00004
Loss_accusation:0.578	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.405	Current_loss:0.983	
Epoch 3	Batch 2720	Train Loss:1.299	Learning rate:0.00004
Epoch 3	Batch 2740	Train Loss:1.298	Learning rate:0.00004
Epoch 3	Batch 2760	Train Loss:1.297	Learning rate:0.00004
Loss_accusation:0.501	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.404	Current_loss:0.906	
Epoch 3	Batch 2780	Train Loss:1.296	Learning rate:0.00004
Epoch 3	Batch 2800	Train Loss:1.296	Learning rate:0.00004
Epoch 3	Batch 2820	Train Loss:1.295	Learning rate:0.00004
Loss_accusation:0.753	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.404	Current_loss:1.157	
Epoch 3	Batch 2840	Train Loss:1.295	Learning rate:0.00004
Epoch 3	Batch 2860	Train Loss:1.295	Learning rate:0.00004
Epoch 3	Batch 2880	Train Loss:1.294	Learning rate:0.00004
Loss_accusation:0.622	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.404	Current_loss:1.026	
Epoch 3	Batch 2900	Train Loss:1.294	Learning rate:0.00004
Epoch 3	Batch 2920	Train Loss:1.293	Learning rate:0.00004
Epoch 3	Batch 2940	Train Loss:1.292	Learning rate:0.00004
Loss_accusation:0.784	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.404	Current_loss:1.187	
Epoch 3	Batch 2960	Train Loss:1.292	Learning rate:0.00004
Epoch 3	Batch 2980	Train Loss:1.291	Learning rate:0.00004
Epoch 3	Batch 3000	Train Loss:1.290	Learning rate:0.00004
Loss_accusation:0.748	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.403	Current_loss:1.152	
Epoch 3	Batch 3020	Train Loss:1.289	Learning rate:0.00004
Epoch 3	Batch 3040	Train Loss:1.289	Learning rate:0.00004
Epoch 3	Batch 3060	Train Loss:1.289	Learning rate:0.00004
Loss_accusation:0.926	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.403	Current_loss:1.329	
Epoch 3	Batch 3080	Train Loss:1.289	Learning rate:0.00004
Epoch 3	Batch 3100	Train Loss:1.288	Learning rate:0.00004
Epoch 3	Batch 3120	Train Loss:1.288	Learning rate:0.00004
Loss_accusation:1.032	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.403	Current_loss:1.434	
Epoch 3	Batch 3140	Train Loss:1.288	Learning rate:0.00004
Epoch 3	Batch 3160	Train Loss:1.287	Learning rate:0.00004
Epoch 3	Batch 3180	Train Loss:1.287	Learning rate:0.00004
Loss_accusation:0.650	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.402	Current_loss:1.052	
Epoch 3	Batch 3200	Train Loss:1.286	Learning rate:0.00004
Epoch 3	Batch 3220	Train Loss:1.285	Learning rate:0.00004
Epoch 3	Batch 3240	Train Loss:1.285	Learning rate:0.00004
Loss_accusation:0.823	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.402	Current_loss:1.226	
Epoch 3	Batch 3260	Train Loss:1.284	Learning rate:0.00004
Epoch 3	Batch 3280	Train Loss:1.283	Learning rate:0.00004
Epoch 3	Batch 3300	Train Loss:1.283	Learning rate:0.00004
Loss_accusation:0.764	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.402	Current_loss:1.166	
Epoch 3	Batch 3320	Train Loss:1.283	Learning rate:0.00004
Epoch 3	Batch 3340	Train Loss:1.282	Learning rate:0.00004
Epoch 3	Batch 3360	Train Loss:1.282	Learning rate:0.00004
Loss_accusation:1.013	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.402	Current_loss:1.415	
Epoch 3	Batch 3380	Train Loss:1.282	Learning rate:0.00004
Epoch 3	Batch 3400	Train Loss:1.281	Learning rate:0.00004
Epoch 3	Batch 3420	Train Loss:1.281	Learning rate:0.00004
Loss_accusation:0.704	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.401	Current_loss:1.105	
Epoch 3	Batch 3440	Train Loss:1.280	Learning rate:0.00004
Epoch 3	Batch 3460	Train Loss:1.279	Learning rate:0.00004
Epoch 3	Batch 3480	Train Loss:1.279	Learning rate:0.00004
Loss_accusation:0.604	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.401	Current_loss:1.005	
Epoch 3	Batch 3500	Train Loss:1.278	Learning rate:0.00004
Epoch 3	Batch 3520	Train Loss:1.277	Learning rate:0.00004
Epoch 3	Batch 3540	Train Loss:1.277	Learning rate:0.00004
Loss_accusation:0.713	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.401	Current_loss:1.114	
Epoch 3	Batch 3560	Train Loss:1.277	Learning rate:0.00004
Epoch 3	Batch 3580	Train Loss:1.277	Learning rate:0.00004
Epoch 3	Batch 3600	Train Loss:1.276	Learning rate:0.00004
Loss_accusation:1.024	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.401	Current_loss:1.425	
Epoch 3	Batch 3620	Train Loss:1.276	Learning rate:0.00004
Epoch 3	Batch 3640	Train Loss:1.275	Learning rate:0.00004
Epoch 3	Batch 3660	Train Loss:1.275	Learning rate:0.00004
Loss_accusation:0.689	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.400	Current_loss:1.089	
Epoch 3	Batch 3680	Train Loss:1.274	Learning rate:0.00004
Epoch 3	Batch 3700	Train Loss:1.274	Learning rate:0.00004
Epoch 3	Batch 3720	Train Loss:1.273	Learning rate:0.00004
Loss_accusation:0.682	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.400	Current_loss:1.082	
Epoch 3	Batch 3740	Train Loss:1.272	Learning rate:0.00004
Epoch 3	Batch 3760	Train Loss:1.272	Learning rate:0.00004
Epoch 3	Batch 3780	Train Loss:1.271	Learning rate:0.00004
Loss_accusation:0.849	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.400	Current_loss:1.248	
Epoch 3	Batch 3800	Train Loss:1.271	Learning rate:0.00004
Epoch 3	Batch 3820	Train Loss:1.271	Learning rate:0.00004
Epoch 3	Batch 3840	Train Loss:1.270	Learning rate:0.00004
Loss_accusation:0.827	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.399	Current_loss:1.227	
Epoch 3	Batch 3860	Train Loss:1.270	Learning rate:0.00004
Epoch 3	Batch 3880	Train Loss:1.269	Learning rate:0.00004
Epoch 3	Batch 3900	Train Loss:1.269	Learning rate:0.00004
Loss_accusation:0.658	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.399	Current_loss:1.057	
('number_examples:', 13094)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('accusation.y_target_labels:', [149], ';y_predict_labels:', [149])
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score:', 1.0)
('article.y_target_labels:', [91], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('article.y_target_labels:', [170], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('x.imprisonment_score.target_value:', 120.0, ';predict_value:', 0.0)
('imprisonment_score:', 0.0)
('article.y_target_labels:', [36], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('death_lifeimprisonment_score:', 1.0)
('f1_micro_accusation:', 0.918123040556426, ';f1_macro_accusation:', 0.8899841568037756)
Epoch 3 ValidLoss:0.956	Macro_f1_accasation:0.890	Micro_f1_accsastion:0.918	Macro_f1_article:0.012 Micro_f1_article:0.013 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 90.40535986801008, ';2.Article Score:', 1.2419137098240143, ';3.Penalty Score:', 68.24396798261753, ';Score ALL:', 159.89124156045165)
going to save check point.
Epoch 3	Batch 3920	Train Loss:1.269	Learning rate:0.00004
Epoch 3	Batch 3940	Train Loss:1.268	Learning rate:0.00004
Epoch 3	Batch 3960	Train Loss:1.268	Learning rate:0.00004
Loss_accusation:0.756	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.399	Current_loss:1.155	
Epoch 3	Batch 3980	Train Loss:1.267	Learning rate:0.00004
Epoch 3	Batch 4000	Train Loss:1.266	Learning rate:0.00004
Epoch 3	Batch 4020	Train Loss:1.265	Learning rate:0.00004
Loss_accusation:0.928	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.399	Current_loss:1.327	
Epoch 3	Batch 4040	Train Loss:1.264	Learning rate:0.00004
Epoch 3	Batch 4060	Train Loss:1.264	Learning rate:0.00004
Epoch 3	Batch 4080	Train Loss:1.263	Learning rate:0.00004
Loss_accusation:0.847	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.398	Current_loss:1.246	
Epoch 3	Batch 4100	Train Loss:1.263	Learning rate:0.00004
Epoch 3	Batch 4120	Train Loss:1.262	Learning rate:0.00004
Epoch 3	Batch 4140	Train Loss:1.262	Learning rate:0.00004
Loss_accusation:0.697	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.398	Current_loss:1.096	
Epoch 3	Batch 4160	Train Loss:1.261	Learning rate:0.00004
Epoch 3	Batch 4180	Train Loss:1.260	Learning rate:0.00004
Epoch 3	Batch 4200	Train Loss:1.259	Learning rate:0.00004
Loss_accusation:1.054	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.398	Current_loss:1.452	
Epoch 3	Batch 4220	Train Loss:1.259	Learning rate:0.00004
Epoch 3	Batch 4240	Train Loss:1.258	Learning rate:0.00004
Epoch 3	Batch 4260	Train Loss:1.257	Learning rate:0.00004
Loss_accusation:0.939	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.398	Current_loss:1.337	
Epoch 3	Batch 4280	Train Loss:1.256	Learning rate:0.00004
Epoch 3	Batch 4300	Train Loss:1.256	Learning rate:0.00004
Epoch 3	Batch 4320	Train Loss:1.255	Learning rate:0.00004
Loss_accusation:0.808	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.397	Current_loss:1.205	
Epoch 3	Batch 4340	Train Loss:1.255	Learning rate:0.00004
Epoch 3	Batch 4360	Train Loss:1.254	Learning rate:0.00004
Epoch 3	Batch 4380	Train Loss:1.254	Learning rate:0.00004
Loss_accusation:0.808	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.397	Current_loss:1.205	
Epoch 3	Batch 4400	Train Loss:1.253	Learning rate:0.00004
Epoch 3	Batch 4420	Train Loss:1.253	Learning rate:0.00004
Epoch 3	Batch 4440	Train Loss:1.252	Learning rate:0.00004
Loss_accusation:0.545	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.397	Current_loss:0.942	
Epoch 3	Batch 4460	Train Loss:1.251	Learning rate:0.00004
Epoch 3	Batch 4480	Train Loss:1.250	Learning rate:0.00004
Epoch 3	Batch 4500	Train Loss:1.250	Learning rate:0.00004
Loss_accusation:0.728	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.397	Current_loss:1.125	
Epoch 3	Batch 4520	Train Loss:1.249	Learning rate:0.00004
Epoch 3	Batch 4540	Train Loss:1.248	Learning rate:0.00004
Epoch 3	Batch 4560	Train Loss:1.248	Learning rate:0.00004
Loss_accusation:0.729	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.396	Current_loss:1.126	
Epoch 3	Batch 4580	Train Loss:1.247	Learning rate:0.00004
Epoch 3	Batch 4600	Train Loss:1.247	Learning rate:0.00004
Epoch 3	Batch 4620	Train Loss:1.246	Learning rate:0.00004
Loss_accusation:0.706	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.396	Current_loss:1.102	
Epoch 3	Batch 4640	Train Loss:1.246	Learning rate:0.00004
Epoch 3	Batch 4660	Train Loss:1.245	Learning rate:0.00004
Epoch 3	Batch 4680	Train Loss:1.245	Learning rate:0.00004
Loss_accusation:0.579	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.396	Current_loss:0.975	
Epoch 3	Batch 4700	Train Loss:1.245	Learning rate:0.00004
Epoch 3	Batch 4720	Train Loss:1.244	Learning rate:0.00004
Epoch 3	Batch 4740	Train Loss:1.243	Learning rate:0.00004
Loss_accusation:0.752	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.396	Current_loss:1.147	
Epoch 3	Batch 4760	Train Loss:1.243	Learning rate:0.00004
Epoch 3	Batch 4780	Train Loss:1.242	Learning rate:0.00004
Epoch 3	Batch 4800	Train Loss:1.242	Learning rate:0.00004
Loss_accusation:0.764	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.396	Current_loss:1.160	
Epoch 3	Batch 4820	Train Loss:1.241	Learning rate:0.00004
Epoch 3	Batch 4840	Train Loss:1.241	Learning rate:0.00004
Epoch 3	Batch 4860	Train Loss:1.241	Learning rate:0.00004
Loss_accusation:0.564	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.395	Current_loss:0.960	
Epoch 3	Batch 4880	Train Loss:1.241	Learning rate:0.00004
Epoch 3	Batch 4900	Train Loss:1.240	Learning rate:0.00004
Epoch 3	Batch 4920	Train Loss:1.239	Learning rate:0.00004
Loss_accusation:0.731	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.395	Current_loss:1.127	
Epoch 3	Batch 4940	Train Loss:1.239	Learning rate:0.00004
Epoch 3	Batch 4960	Train Loss:1.238	Learning rate:0.00004
Epoch 3	Batch 4980	Train Loss:1.238	Learning rate:0.00004
Loss_accusation:0.810	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.395	Current_loss:1.205	
Epoch 3	Batch 5000	Train Loss:1.237	Learning rate:0.00004
Epoch 3	Batch 5020	Train Loss:1.237	Learning rate:0.00004
Epoch 3	Batch 5040	Train Loss:1.236	Learning rate:0.00004
Loss_accusation:0.686	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.395	Current_loss:1.080	
going to increment epoch counter....
(3, 1, True)
('number_examples:', 13094)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('x.imprisonment_score.target_value:', 42.0, ';predict_value:', 0.0)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score:', 1.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('f1_micro_accusation:', 0.9171162754527489, ';f1_macro_accusation:', 0.8913979270376121)
()
Epoch 3 ValidLoss:0.932	Macro_f1_accasation:0.891	Micro_f1_accsastion:0.917	Macro_f1_article:0.012	Micro_f1_article:0.013	Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('===>1.Accasation Score:', 90.42571012451805, ';2.Article Score:', 1.2421574602583147, ';3.Penalty Score:', 68.24141487829269, ';Score ALL:', 159.90928246306905)
going to save check point.
Epoch 4	Batch 20	Train Loss:1.332	Learning rate:0.00004
Epoch 4	Batch 40	Train Loss:1.300	Learning rate:0.00004
Epoch 4	Batch 60	Train Loss:1.284	Learning rate:0.00004
Loss_accusation:0.716	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.394	Current_loss:1.110	
Epoch 4	Batch 80	Train Loss:1.273	Learning rate:0.00004
Epoch 4	Batch 100	Train Loss:1.259	Learning rate:0.00004
Epoch 4	Batch 120	Train Loss:1.254	Learning rate:0.00004
Loss_accusation:0.780	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.394	Current_loss:1.174	
Epoch 4	Batch 140	Train Loss:1.244	Learning rate:0.00004
Epoch 4	Batch 160	Train Loss:1.240	Learning rate:0.00004
Epoch 4	Batch 180	Train Loss:1.234	Learning rate:0.00004
Loss_accusation:0.891	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.394	Current_loss:1.285	
Epoch 4	Batch 200	Train Loss:1.222	Learning rate:0.00004
Epoch 4	Batch 220	Train Loss:1.218	Learning rate:0.00004
Epoch 4	Batch 240	Train Loss:1.216	Learning rate:0.00004
Loss_accusation:0.591	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.394	Current_loss:0.985	
Epoch 4	Batch 260	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 280	Train Loss:1.215	Learning rate:0.00004
Epoch 4	Batch 300	Train Loss:1.214	Learning rate:0.00004
Loss_accusation:1.005	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.394	Current_loss:1.399	
Epoch 4	Batch 320	Train Loss:1.213	Learning rate:0.00004
Epoch 4	Batch 340	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 360	Train Loss:1.214	Learning rate:0.00004
Loss_accusation:1.060	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.393	Current_loss:1.454	
Epoch 4	Batch 380	Train Loss:1.211	Learning rate:0.00004
Epoch 4	Batch 400	Train Loss:1.214	Learning rate:0.00004
Epoch 4	Batch 420	Train Loss:1.213	Learning rate:0.00004
Loss_accusation:0.501	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.393	Current_loss:0.894	
Epoch 4	Batch 440	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 460	Train Loss:1.210	Learning rate:0.00004
Epoch 4	Batch 480	Train Loss:1.209	Learning rate:0.00004
Loss_accusation:0.742	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.393	Current_loss:1.135	
Epoch 4	Batch 500	Train Loss:1.206	Learning rate:0.00004
Epoch 4	Batch 520	Train Loss:1.208	Learning rate:0.00004
Epoch 4	Batch 540	Train Loss:1.213	Learning rate:0.00004
Loss_accusation:0.697	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.393	Current_loss:1.090	
Epoch 4	Batch 560	Train Loss:1.213	Learning rate:0.00004
Epoch 4	Batch 580	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 600	Train Loss:1.214	Learning rate:0.00004
Loss_accusation:0.769	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.392	Current_loss:1.162	
Epoch 4	Batch 620	Train Loss:1.215	Learning rate:0.00004
Epoch 4	Batch 640	Train Loss:1.215	Learning rate:0.00004
Epoch 4	Batch 660	Train Loss:1.214	Learning rate:0.00004
Loss_accusation:0.840	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.392	Current_loss:1.232	
Epoch 4	Batch 680	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 700	Train Loss:1.213	Learning rate:0.00004
Epoch 4	Batch 720	Train Loss:1.212	Learning rate:0.00004
Loss_accusation:0.572	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.392	Current_loss:0.964	
Epoch 4	Batch 740	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 760	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 780	Train Loss:1.215	Learning rate:0.00004
Loss_accusation:0.775	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.392	Current_loss:1.167	
Epoch 4	Batch 800	Train Loss:1.216	Learning rate:0.00004
Epoch 4	Batch 820	Train Loss:1.217	Learning rate:0.00004
Epoch 4	Batch 840	Train Loss:1.217	Learning rate:0.00004
Loss_accusation:0.909	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.392	Current_loss:1.301	
Epoch 4	Batch 860	Train Loss:1.217	Learning rate:0.00004
Epoch 4	Batch 880	Train Loss:1.216	Learning rate:0.00004
Epoch 4	Batch 900	Train Loss:1.216	Learning rate:0.00004
Loss_accusation:0.531	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.392	Current_loss:0.923	
Epoch 4	Batch 920	Train Loss:1.216	Learning rate:0.00004
Epoch 4	Batch 940	Train Loss:1.216	Learning rate:0.00004
Epoch 4	Batch 960	Train Loss:1.215	Learning rate:0.00004
Loss_accusation:0.589	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.391	Current_loss:0.980	
Epoch 4	Batch 980	Train Loss:1.213	Learning rate:0.00004
Epoch 4	Batch 1000	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 1020	Train Loss:1.212	Learning rate:0.00004
Loss_accusation:0.871	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.391	Current_loss:1.262	
Epoch 4	Batch 1040	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 1060	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 1080	Train Loss:1.212	Learning rate:0.00004
Loss_accusation:0.665	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.391	Current_loss:1.056	
Epoch 4	Batch 1100	Train Loss:1.212	Learning rate:0.00004
Epoch 4	Batch 1120	Train Loss:1.210	Learning rate:0.00004
Epoch 4	Batch 1140	Train Loss:1.210	Learning rate:0.00004
Loss_accusation:0.951	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.391	Current_loss:1.342	
Epoch 4	Batch 1160	Train Loss:1.209	Learning rate:0.00004
Epoch 4	Batch 1180	Train Loss:1.209	Learning rate:0.00004
Epoch 4	Batch 1200	Train Loss:1.208	Learning rate:0.00004
Loss_accusation:0.875	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.391	Current_loss:1.265	
Epoch 4	Batch 1220	Train Loss:1.208	Learning rate:0.00004
Epoch 4	Batch 1240	Train Loss:1.207	Learning rate:0.00004
Epoch 4	Batch 1260	Train Loss:1.207	Learning rate:0.00004
Loss_accusation:1.217	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.390	Current_loss:1.607	
Epoch 4	Batch 1280	Train Loss:1.208	Learning rate:0.00004
Epoch 4	Batch 1300	Train Loss:1.209	Learning rate:0.00004
Epoch 4	Batch 1320	Train Loss:1.209	Learning rate:0.00004
Loss_accusation:0.770	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.390	Current_loss:1.160	
Epoch 4	Batch 1340	Train Loss:1.209	Learning rate:0.00004
Epoch 4	Batch 1360	Train Loss:1.210	Learning rate:0.00004
Epoch 4	Batch 1380	Train Loss:1.210	Learning rate:0.00004
Loss_accusation:0.725	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.390	Current_loss:1.115	
Epoch 4	Batch 1400	Train Loss:1.209	Learning rate:0.00004
Epoch 4	Batch 1420	Train Loss:1.209	Learning rate:0.00004
Epoch 4	Batch 1440	Train Loss:1.208	Learning rate:0.00004
Loss_accusation:0.680	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.390	Current_loss:1.069	
Epoch 4	Batch 1460	Train Loss:1.207	Learning rate:0.00004
Epoch 4	Batch 1480	Train Loss:1.206	Learning rate:0.00004
Epoch 4	Batch 1500	Train Loss:1.205	Learning rate:0.00004
Loss_accusation:0.654	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.390	Current_loss:1.043	
Epoch 4	Batch 1520	Train Loss:1.204	Learning rate:0.00004
Epoch 4	Batch 1540	Train Loss:1.204	Learning rate:0.00004
Epoch 4	Batch 1560	Train Loss:1.204	Learning rate:0.00004
Loss_accusation:0.872	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.389	Current_loss:1.262	
Epoch 4	Batch 1580	Train Loss:1.204	Learning rate:0.00004
Epoch 4	Batch 1600	Train Loss:1.204	Learning rate:0.00004
Epoch 4	Batch 1620	Train Loss:1.204	Learning rate:0.00004
Loss_accusation:0.828	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.389	Current_loss:1.217	
Epoch 4	Batch 1640	Train Loss:1.204	Learning rate:0.00004
Epoch 4	Batch 1660	Train Loss:1.204	Learning rate:0.00004
Epoch 4	Batch 1680	Train Loss:1.203	Learning rate:0.00004
Loss_accusation:0.820	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.389	Current_loss:1.209	
Epoch 4	Batch 1700	Train Loss:1.202	Learning rate:0.00004
Epoch 4	Batch 1720	Train Loss:1.201	Learning rate:0.00004
Epoch 4	Batch 1740	Train Loss:1.200	Learning rate:0.00004
Loss_accusation:0.595	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.389	Current_loss:0.984	
Epoch 4	Batch 1760	Train Loss:1.199	Learning rate:0.00004
Epoch 4	Batch 1780	Train Loss:1.199	Learning rate:0.00004
Epoch 4	Batch 1800	Train Loss:1.199	Learning rate:0.00004
Loss_accusation:0.979	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.389	Current_loss:1.368	
Epoch 4	Batch 1820	Train Loss:1.199	Learning rate:0.00004
Epoch 4	Batch 1840	Train Loss:1.199	Learning rate:0.00004
Epoch 4	Batch 1860	Train Loss:1.199	Learning rate:0.00004
Loss_accusation:0.970	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.388	Current_loss:1.359	
Epoch 4	Batch 1880	Train Loss:1.199	Learning rate:0.00004
Epoch 4	Batch 1900	Train Loss:1.198	Learning rate:0.00004
Epoch 4	Batch 1920	Train Loss:1.198	Learning rate:0.00004
Loss_accusation:0.944	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.388	Current_loss:1.332	
Epoch 4	Batch 1940	Train Loss:1.197	Learning rate:0.00004
Epoch 4	Batch 1960	Train Loss:1.197	Learning rate:0.00004
Epoch 4	Batch 1980	Train Loss:1.196	Learning rate:0.00004
Loss_accusation:0.918	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.388	Current_loss:1.306	
Epoch 4	Batch 2000	Train Loss:1.196	Learning rate:0.00004
Epoch 4	Batch 2020	Train Loss:1.195	Learning rate:0.00004
Epoch 4	Batch 2040	Train Loss:1.196	Learning rate:0.00004
Loss_accusation:0.601	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.388	Current_loss:0.989	
Epoch 4	Batch 2060	Train Loss:1.196	Learning rate:0.00004
Epoch 4	Batch 2080	Train Loss:1.197	Learning rate:0.00004
Epoch 4	Batch 2100	Train Loss:1.196	Learning rate:0.00004
Loss_accusation:0.715	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.388	Current_loss:1.102	
Epoch 4	Batch 2120	Train Loss:1.196	Learning rate:0.00004
Epoch 4	Batch 2140	Train Loss:1.196	Learning rate:0.00004
Epoch 4	Batch 2160	Train Loss:1.195	Learning rate:0.00004
Loss_accusation:0.651	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.387	Current_loss:1.038	
Epoch 4	Batch 2180	Train Loss:1.195	Learning rate:0.00004
Epoch 4	Batch 2200	Train Loss:1.194	Learning rate:0.00004
Epoch 4	Batch 2220	Train Loss:1.194	Learning rate:0.00004
Loss_accusation:0.703	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.387	Current_loss:1.090	
Epoch 4	Batch 2240	Train Loss:1.193	Learning rate:0.00004
Epoch 4	Batch 2260	Train Loss:1.192	Learning rate:0.00004
Epoch 4	Batch 2280	Train Loss:1.191	Learning rate:0.00004
Loss_accusation:0.708	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.387	Current_loss:1.095	
Epoch 4	Batch 2300	Train Loss:1.192	Learning rate:0.00004
Epoch 4	Batch 2320	Train Loss:1.193	Learning rate:0.00004
Epoch 4	Batch 2340	Train Loss:1.193	Learning rate:0.00004
Loss_accusation:0.943	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.387	Current_loss:1.330	
Epoch 4	Batch 2360	Train Loss:1.192	Learning rate:0.00004
Epoch 4	Batch 2380	Train Loss:1.192	Learning rate:0.00004
Epoch 4	Batch 2400	Train Loss:1.191	Learning rate:0.00004
Loss_accusation:0.519	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.387	Current_loss:0.906	
Epoch 4	Batch 2420	Train Loss:1.190	Learning rate:0.00004
Epoch 4	Batch 2440	Train Loss:1.189	Learning rate:0.00004
Epoch 4	Batch 2460	Train Loss:1.188	Learning rate:0.00004
Loss_accusation:0.816	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.387	Current_loss:1.202	
Epoch 4	Batch 2480	Train Loss:1.188	Learning rate:0.00004
Epoch 4	Batch 2500	Train Loss:1.186	Learning rate:0.00004
Epoch 4	Batch 2520	Train Loss:1.185	Learning rate:0.00004
Loss_accusation:0.770	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.386	Current_loss:1.157	
Epoch 4	Batch 2540	Train Loss:1.185	Learning rate:0.00004
Epoch 4	Batch 2560	Train Loss:1.185	Learning rate:0.00004
Epoch 4	Batch 2580	Train Loss:1.185	Learning rate:0.00004
Loss_accusation:0.970	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.386	Current_loss:1.356	
Epoch 4	Batch 2600	Train Loss:1.185	Learning rate:0.00004
Epoch 4	Batch 2620	Train Loss:1.185	Learning rate:0.00004
Epoch 4	Batch 2640	Train Loss:1.185	Learning rate:0.00004
Loss_accusation:0.718	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.386	Current_loss:1.104	
Epoch 4	Batch 2660	Train Loss:1.185	Learning rate:0.00004
Epoch 4	Batch 2680	Train Loss:1.184	Learning rate:0.00004
Epoch 4	Batch 2700	Train Loss:1.183	Learning rate:0.00004
Loss_accusation:0.368	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.386	Current_loss:0.754	
Epoch 4	Batch 2720	Train Loss:1.182	Learning rate:0.00004
Epoch 4	Batch 2740	Train Loss:1.182	Learning rate:0.00004
Epoch 4	Batch 2760	Train Loss:1.181	Learning rate:0.00004
Loss_accusation:0.456	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.386	Current_loss:0.841	
Epoch 4	Batch 2780	Train Loss:1.180	Learning rate:0.00004
Epoch 4	Batch 2800	Train Loss:1.180	Learning rate:0.00004
Epoch 4	Batch 2820	Train Loss:1.180	Learning rate:0.00004
Loss_accusation:0.732	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.385	Current_loss:1.118	
Epoch 4	Batch 2840	Train Loss:1.181	Learning rate:0.00004
Epoch 4	Batch 2860	Train Loss:1.180	Learning rate:0.00004
Epoch 4	Batch 2880	Train Loss:1.180	Learning rate:0.00004
Loss_accusation:0.610	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.385	Current_loss:0.996	
Epoch 4	Batch 2900	Train Loss:1.180	Learning rate:0.00004
Epoch 4	Batch 2920	Train Loss:1.179	Learning rate:0.00004
Epoch 4	Batch 2940	Train Loss:1.179	Learning rate:0.00004
Loss_accusation:0.801	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.385	Current_loss:1.186	
Epoch 4	Batch 2960	Train Loss:1.178	Learning rate:0.00004
Epoch 4	Batch 2980	Train Loss:1.177	Learning rate:0.00004
Epoch 4	Batch 3000	Train Loss:1.176	Learning rate:0.00004
Loss_accusation:0.588	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.385	Current_loss:0.973	
Epoch 4	Batch 3020	Train Loss:1.176	Learning rate:0.00004
Epoch 4	Batch 3040	Train Loss:1.176	Learning rate:0.00004
Epoch 4	Batch 3060	Train Loss:1.176	Learning rate:0.00004
Loss_accusation:0.871	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.385	Current_loss:1.256	
Epoch 4	Batch 3080	Train Loss:1.176	Learning rate:0.00004
Epoch 4	Batch 3100	Train Loss:1.176	Learning rate:0.00004
Epoch 4	Batch 3120	Train Loss:1.175	Learning rate:0.00004
Loss_accusation:0.941	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.385	Current_loss:1.326	
Epoch 4	Batch 3140	Train Loss:1.175	Learning rate:0.00004
Epoch 4	Batch 3160	Train Loss:1.175	Learning rate:0.00004
Epoch 4	Batch 3180	Train Loss:1.174	Learning rate:0.00004
Loss_accusation:0.520	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.384	Current_loss:0.904	
Epoch 4	Batch 3200	Train Loss:1.174	Learning rate:0.00004
Epoch 4	Batch 3220	Train Loss:1.173	Learning rate:0.00004
Epoch 4	Batch 3240	Train Loss:1.173	Learning rate:0.00004
Loss_accusation:0.775	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.384	Current_loss:1.159	
Epoch 4	Batch 3260	Train Loss:1.173	Learning rate:0.00004
Epoch 4	Batch 3280	Train Loss:1.172	Learning rate:0.00004
Epoch 4	Batch 3300	Train Loss:1.172	Learning rate:0.00004
Loss_accusation:0.760	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.384	Current_loss:1.144	
Epoch 4	Batch 3320	Train Loss:1.172	Learning rate:0.00004
Epoch 4	Batch 3340	Train Loss:1.171	Learning rate:0.00004
Epoch 4	Batch 3360	Train Loss:1.171	Learning rate:0.00004
Loss_accusation:0.925	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.384	Current_loss:1.309	
Epoch 4	Batch 3380	Train Loss:1.171	Learning rate:0.00004
Epoch 4	Batch 3400	Train Loss:1.171	Learning rate:0.00004
Epoch 4	Batch 3420	Train Loss:1.170	Learning rate:0.00004
Loss_accusation:0.856	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.384	Current_loss:1.239	
Epoch 4	Batch 3440	Train Loss:1.170	Learning rate:0.00004
Epoch 4	Batch 3460	Train Loss:1.169	Learning rate:0.00004
Epoch 4	Batch 3480	Train Loss:1.169	Learning rate:0.00004
Loss_accusation:0.438	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.383	Current_loss:0.821	
Epoch 4	Batch 3500	Train Loss:1.168	Learning rate:0.00004
Epoch 4	Batch 3520	Train Loss:1.168	Learning rate:0.00004
Epoch 4	Batch 3540	Train Loss:1.167	Learning rate:0.00004
Loss_accusation:0.782	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.383	Current_loss:1.165	
Epoch 4	Batch 3560	Train Loss:1.168	Learning rate:0.00004
Epoch 4	Batch 3580	Train Loss:1.168	Learning rate:0.00004
Epoch 4	Batch 3600	Train Loss:1.168	Learning rate:0.00004
Loss_accusation:1.056	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.383	Current_loss:1.439	
Epoch 4	Batch 3620	Train Loss:1.168	Learning rate:0.00004
Epoch 4	Batch 3640	Train Loss:1.167	Learning rate:0.00004
Epoch 4	Batch 3660	Train Loss:1.167	Learning rate:0.00004
Loss_accusation:0.689	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.383	Current_loss:1.072	
Epoch 4	Batch 3680	Train Loss:1.166	Learning rate:0.00004
Epoch 4	Batch 3700	Train Loss:1.166	Learning rate:0.00004
Epoch 4	Batch 3720	Train Loss:1.165	Learning rate:0.00004
Loss_accusation:0.626	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.383	Current_loss:1.009	
Epoch 4	Batch 3740	Train Loss:1.165	Learning rate:0.00004
Epoch 4	Batch 3760	Train Loss:1.165	Learning rate:0.00004
Epoch 4	Batch 3780	Train Loss:1.165	Learning rate:0.00004
Loss_accusation:0.765	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.383	Current_loss:1.147	
Epoch 4	Batch 3800	Train Loss:1.164	Learning rate:0.00004
Epoch 4	Batch 3820	Train Loss:1.164	Learning rate:0.00004
Epoch 4	Batch 3840	Train Loss:1.164	Learning rate:0.00004
Loss_accusation:0.662	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.382	Current_loss:1.044	
Epoch 4	Batch 3860	Train Loss:1.164	Learning rate:0.00004
Epoch 4	Batch 3880	Train Loss:1.164	Learning rate:0.00004
Epoch 4	Batch 3900	Train Loss:1.163	Learning rate:0.00004
Loss_accusation:0.699	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.382	Current_loss:1.082	
('number_examples:', 13094)
('imprisonment_score:', 0.0)
('x.imprisonment_score.target_value:', 10.0, ';predict_value:', 0.0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('imprisonment_score:', 0.0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('article.y_target_labels:', [131], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('x.imprisonment_score.target_value:', 12.0, ';predict_value:', 0.0)
('macro', 'precison:', '0.993006923566', ';recall:', '0.993006923566', ';f1_score:', 0.9930019235911252)
('macro', 'precison:', '0.0121783088142', ';recall:', '0.999999937107', ';f1_score:', 0.02406332635721864)
('f1_micro_accusation:', 0.923954827518452, ';f1_macro_accusation:', 0.9018696752911762)
Epoch 4 ValidLoss:0.890	Macro_f1_accasation:0.902	Micro_f1_accsastion:0.924	Macro_f1_article:0.012 Micro_f1_article:0.013 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 91.29122514048142, ';2.Article Score:', 1.2419945925755644, ';3.Penalty Score:', 69.17891478638091, ';Score ALL:', 161.71213451943788)
going to save check point.
Epoch 4	Batch 3920	Train Loss:1.163	Learning rate:0.00004
Epoch 4	Batch 3940	Train Loss:1.163	Learning rate:0.00004
Epoch 4	Batch 3960	Train Loss:1.162	Learning rate:0.00004
Loss_accusation:0.771	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.382	Current_loss:1.153	
Epoch 4	Batch 3980	Train Loss:1.162	Learning rate:0.00004
Epoch 4	Batch 4000	Train Loss:1.161	Learning rate:0.00004
Epoch 4	Batch 4020	Train Loss:1.160	Learning rate:0.00004
Loss_accusation:0.957	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.382	Current_loss:1.339	
Epoch 4	Batch 4040	Train Loss:1.159	Learning rate:0.00004
Epoch 4	Batch 4060	Train Loss:1.159	Learning rate:0.00004
Epoch 4	Batch 4080	Train Loss:1.159	Learning rate:0.00004
Loss_accusation:0.809	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.382	Current_loss:1.191	
Epoch 4	Batch 4100	Train Loss:1.159	Learning rate:0.00004
Epoch 4	Batch 4120	Train Loss:1.158	Learning rate:0.00004
Epoch 4	Batch 4140	Train Loss:1.158	Learning rate:0.00004
Loss_accusation:0.600	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.382	Current_loss:0.982	
Epoch 4	Batch 4160	Train Loss:1.157	Learning rate:0.00004
Epoch 4	Batch 4180	Train Loss:1.157	Learning rate:0.00004
Epoch 4	Batch 4200	Train Loss:1.156	Learning rate:0.00004
Loss_accusation:0.885	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.381	Current_loss:1.266	
Epoch 4	Batch 4220	Train Loss:1.156	Learning rate:0.00004
Epoch 4	Batch 4240	Train Loss:1.155	Learning rate:0.00004
Epoch 4	Batch 4260	Train Loss:1.155	Learning rate:0.00004
Loss_accusation:0.697	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.381	Current_loss:1.078	
Epoch 4	Batch 4280	Train Loss:1.154	Learning rate:0.00004
Epoch 4	Batch 4300	Train Loss:1.154	Learning rate:0.00004
Epoch 4	Batch 4320	Train Loss:1.153	Learning rate:0.00004
Loss_accusation:0.703	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.381	Current_loss:1.084	
Epoch 4	Batch 4340	Train Loss:1.153	Learning rate:0.00004
Epoch 4	Batch 4360	Train Loss:1.153	Learning rate:0.00004
Epoch 4	Batch 4380	Train Loss:1.152	Learning rate:0.00004
Loss_accusation:0.695	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.381	Current_loss:1.076	
Epoch 4	Batch 4400	Train Loss:1.152	Learning rate:0.00004
Epoch 4	Batch 4420	Train Loss:1.151	Learning rate:0.00004
Epoch 4	Batch 4440	Train Loss:1.151	Learning rate:0.00004
Loss_accusation:0.616	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.381	Current_loss:0.997	
Epoch 4	Batch 4460	Train Loss:1.150	Learning rate:0.00004
Epoch 4	Batch 4480	Train Loss:1.149	Learning rate:0.00004
Epoch 4	Batch 4500	Train Loss:1.149	Learning rate:0.00004
Loss_accusation:0.650	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.380	Current_loss:1.031	
Epoch 4	Batch 4520	Train Loss:1.148	Learning rate:0.00004
Epoch 4	Batch 4540	Train Loss:1.148	Learning rate:0.00004
Epoch 4	Batch 4560	Train Loss:1.147	Learning rate:0.00004
Loss_accusation:0.640	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.380	Current_loss:1.020	
Epoch 4	Batch 4580	Train Loss:1.147	Learning rate:0.00004
Epoch 4	Batch 4600	Train Loss:1.147	Learning rate:0.00004
Epoch 4	Batch 4620	Train Loss:1.147	Learning rate:0.00004
Loss_accusation:0.658	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.380	Current_loss:1.038	
Epoch 4	Batch 4640	Train Loss:1.147	Learning rate:0.00004
Epoch 4	Batch 4660	Train Loss:1.146	Learning rate:0.00004
Epoch 4	Batch 4680	Train Loss:1.146	Learning rate:0.00004
Loss_accusation:0.535	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.380	Current_loss:0.915	
Epoch 4	Batch 4700	Train Loss:1.146	Learning rate:0.00004
Epoch 4	Batch 4720	Train Loss:1.145	Learning rate:0.00004
Epoch 4	Batch 4740	Train Loss:1.145	Learning rate:0.00004
Loss_accusation:0.762	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.380	Current_loss:1.142	
Epoch 4	Batch 4760	Train Loss:1.145	Learning rate:0.00004
Epoch 4	Batch 4780	Train Loss:1.144	Learning rate:0.00004
Epoch 4	Batch 4800	Train Loss:1.144	Learning rate:0.00004
Loss_accusation:0.737	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.380	Current_loss:1.117	
Epoch 4	Batch 4820	Train Loss:1.144	Learning rate:0.00004
Epoch 4	Batch 4840	Train Loss:1.144	Learning rate:0.00004
Epoch 4	Batch 4860	Train Loss:1.143	Learning rate:0.00004
Loss_accusation:0.436	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.379	Current_loss:0.815	
Epoch 4	Batch 4880	Train Loss:1.143	Learning rate:0.00004
Epoch 4	Batch 4900	Train Loss:1.143	Learning rate:0.00004
Epoch 4	Batch 4920	Train Loss:1.142	Learning rate:0.00004
Loss_accusation:0.664	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.379	Current_loss:1.043	
Epoch 4	Batch 4940	Train Loss:1.142	Learning rate:0.00004
Epoch 4	Batch 4960	Train Loss:1.142	Learning rate:0.00004
Epoch 4	Batch 4980	Train Loss:1.141	Learning rate:0.00004
Loss_accusation:0.604	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.379	Current_loss:0.983	
Epoch 4	Batch 5000	Train Loss:1.141	Learning rate:0.00004
Epoch 4	Batch 5020	Train Loss:1.140	Learning rate:0.00004
Epoch 4	Batch 5040	Train Loss:1.140	Learning rate:0.00004
Loss_accusation:0.602	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.379	Current_loss:0.981	
going to increment epoch counter....
(4, 1, True)
('number_examples:', 13094)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score:', 1.0)
('accusation.y_target_labels:', [92], ';y_predict_labels:', [92])
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('x.imprisonment_score.target_value:', 36.0, ';predict_value:', 0.0)
('accusation.y_target_labels:', [87], ';y_predict_labels:', [87])
('accusation.y_target_labels:', [181], ';y_predict_labels:', [181])
('article.y_target_labels:', [46], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('macro', 'precison:', '0.999999444445', ';recall:', '0.999999444445', ';f1_score:', 0.9999944444697529)
('accusation_normal_f1_score', 'precison:', '0.999998000004', ';recall:', '0.999998000004', ';f1_score:', 0.999993000029)
('f1_micro_accusation:', 0.9259545886589283, ';f1_macro_accusation:', 0.907119055966385)
()
Epoch 4 ValidLoss:0.871	Macro_f1_accasation:0.907	Micro_f1_accsastion:0.926	Macro_f1_article:0.012	Micro_f1_article:0.012	Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('===>1.Accasation Score:', 91.65368223126566, ';2.Article Score:', 1.241343462079917, ';3.Penalty Score:', 70.16849802269627, ';Score ALL:', 163.06352371604186)
going to save check point.
(0, 'Going to decay learning rate by half.')
(1, 'Going to decay learning rate by half.')
Epoch 5	Batch 20	Train Loss:1.205	Learning rate:0.00001
Epoch 5	Batch 40	Train Loss:1.184	Learning rate:0.00001
Epoch 5	Batch 60	Train Loss:1.182	Learning rate:0.00001
Loss_accusation:0.608	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.379	Current_loss:0.987	
Epoch 5	Batch 80	Train Loss:1.176	Learning rate:0.00001
Epoch 5	Batch 100	Train Loss:1.165	Learning rate:0.00001
Epoch 5	Batch 120	Train Loss:1.167	Learning rate:0.00001
Loss_accusation:0.722	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.379	Current_loss:1.101	
Epoch 5	Batch 140	Train Loss:1.158	Learning rate:0.00001
Epoch 5	Batch 160	Train Loss:1.155	Learning rate:0.00001
Epoch 5	Batch 180	Train Loss:1.152	Learning rate:0.00001
Loss_accusation:0.794	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.379	Current_loss:1.173	
Epoch 5	Batch 200	Train Loss:1.142	Learning rate:0.00001
Epoch 5	Batch 220	Train Loss:1.142	Learning rate:0.00001
Epoch 5	Batch 240	Train Loss:1.142	Learning rate:0.00001
Loss_accusation:0.582	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:0.961	
Epoch 5	Batch 260	Train Loss:1.138	Learning rate:0.00001
Epoch 5	Batch 280	Train Loss:1.139	Learning rate:0.00001
Epoch 5	Batch 300	Train Loss:1.139	Learning rate:0.00001
Loss_accusation:0.979	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:1.357	
Epoch 5	Batch 320	Train Loss:1.139	Learning rate:0.00001
Epoch 5	Batch 340	Train Loss:1.136	Learning rate:0.00001
Epoch 5	Batch 360	Train Loss:1.137	Learning rate:0.00001
Loss_accusation:0.820	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:1.198	
Epoch 5	Batch 380	Train Loss:1.137	Learning rate:0.00001
Epoch 5	Batch 400	Train Loss:1.140	Learning rate:0.00001
Epoch 5	Batch 420	Train Loss:1.139	Learning rate:0.00001
Loss_accusation:0.609	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:0.987	
Epoch 5	Batch 440	Train Loss:1.139	Learning rate:0.00001
Epoch 5	Batch 460	Train Loss:1.138	Learning rate:0.00001
Epoch 5	Batch 480	Train Loss:1.137	Learning rate:0.00001
Loss_accusation:0.692	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:1.070	
Epoch 5	Batch 500	Train Loss:1.136	Learning rate:0.00001
Epoch 5	Batch 520	Train Loss:1.136	Learning rate:0.00001
Epoch 5	Batch 540	Train Loss:1.139	Learning rate:0.00001
Loss_accusation:0.551	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:0.929	
Epoch 5	Batch 560	Train Loss:1.140	Learning rate:0.00001
Epoch 5	Batch 580	Train Loss:1.140	Learning rate:0.00001
Epoch 5	Batch 600	Train Loss:1.140	Learning rate:0.00001
Loss_accusation:0.594	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:0.972	
Epoch 5	Batch 620	Train Loss:1.142	Learning rate:0.00001
Epoch 5	Batch 640	Train Loss:1.142	Learning rate:0.00001
Epoch 5	Batch 660	Train Loss:1.141	Learning rate:0.00001
Loss_accusation:0.921	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:1.299	
Epoch 5	Batch 680	Train Loss:1.140	Learning rate:0.00001
Epoch 5	Batch 700	Train Loss:1.141	Learning rate:0.00001
Epoch 5	Batch 720	Train Loss:1.141	Learning rate:0.00001
Loss_accusation:0.694	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:1.072	
Epoch 5	Batch 740	Train Loss:1.141	Learning rate:0.00001
Epoch 5	Batch 760	Train Loss:1.141	Learning rate:0.00001
Epoch 5	Batch 780	Train Loss:1.142	Learning rate:0.00001
Loss_accusation:0.795	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.378	Current_loss:1.172	
Epoch 5	Batch 800	Train Loss:1.143	Learning rate:0.00001
Epoch 5	Batch 820	Train Loss:1.143	Learning rate:0.00001
Epoch 5	Batch 840	Train Loss:1.143	Learning rate:0.00001
Loss_accusation:0.837	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:1.214	
Epoch 5	Batch 860	Train Loss:1.144	Learning rate:0.00001
Epoch 5	Batch 880	Train Loss:1.142	Learning rate:0.00001
Epoch 5	Batch 900	Train Loss:1.142	Learning rate:0.00001
Loss_accusation:0.537	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:0.914	
Epoch 5	Batch 920	Train Loss:1.142	Learning rate:0.00001
Epoch 5	Batch 940	Train Loss:1.142	Learning rate:0.00001
Epoch 5	Batch 960	Train Loss:1.141	Learning rate:0.00001
Loss_accusation:0.454	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:0.832	
Epoch 5	Batch 980	Train Loss:1.139	Learning rate:0.00001
Epoch 5	Batch 1000	Train Loss:1.138	Learning rate:0.00001
Epoch 5	Batch 1020	Train Loss:1.138	Learning rate:0.00001
Loss_accusation:0.783	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:1.160	
Epoch 5	Batch 1040	Train Loss:1.138	Learning rate:0.00001
Epoch 5	Batch 1060	Train Loss:1.137	Learning rate:0.00001
Epoch 5	Batch 1080	Train Loss:1.136	Learning rate:0.00001
Loss_accusation:0.593	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:0.970	
Epoch 5	Batch 1100	Train Loss:1.137	Learning rate:0.00001
Epoch 5	Batch 1120	Train Loss:1.136	Learning rate:0.00001
Epoch 5	Batch 1140	Train Loss:1.135	Learning rate:0.00001
Loss_accusation:0.942	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:1.319	
Epoch 5	Batch 1160	Train Loss:1.135	Learning rate:0.00001
Epoch 5	Batch 1180	Train Loss:1.135	Learning rate:0.00001
Epoch 5	Batch 1200	Train Loss:1.134	Learning rate:0.00001
Loss_accusation:0.851	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:1.228	
Epoch 5	Batch 1220	Train Loss:1.134	Learning rate:0.00001
Epoch 5	Batch 1240	Train Loss:1.134	Learning rate:0.00001
Epoch 5	Batch 1260	Train Loss:1.133	Learning rate:0.00001
Loss_accusation:1.101	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:1.478	
Epoch 5	Batch 1280	Train Loss:1.134	Learning rate:0.00001
Epoch 5	Batch 1300	Train Loss:1.135	Learning rate:0.00001
Epoch 5	Batch 1320	Train Loss:1.134	Learning rate:0.00001
Loss_accusation:0.585	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:0.961	
Epoch 5	Batch 1340	Train Loss:1.134	Learning rate:0.00001
Epoch 5	Batch 1360	Train Loss:1.134	Learning rate:0.00001
Epoch 5	Batch 1380	Train Loss:1.133	Learning rate:0.00001
Loss_accusation:0.794	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.377	Current_loss:1.170	
Epoch 5	Batch 1400	Train Loss:1.133	Learning rate:0.00001
Epoch 5	Batch 1420	Train Loss:1.133	Learning rate:0.00001
Epoch 5	Batch 1440	Train Loss:1.133	Learning rate:0.00001
Loss_accusation:0.674	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.050	
Epoch 5	Batch 1460	Train Loss:1.131	Learning rate:0.00001
Epoch 5	Batch 1480	Train Loss:1.130	Learning rate:0.00001
Epoch 5	Batch 1500	Train Loss:1.130	Learning rate:0.00001
Loss_accusation:0.807	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.183	
Epoch 5	Batch 1520	Train Loss:1.128	Learning rate:0.00001
Epoch 5	Batch 1540	Train Loss:1.128	Learning rate:0.00001
Epoch 5	Batch 1560	Train Loss:1.127	Learning rate:0.00001
Loss_accusation:0.826	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.202	
Epoch 5	Batch 1580	Train Loss:1.127	Learning rate:0.00001
Epoch 5	Batch 1600	Train Loss:1.127	Learning rate:0.00001
Epoch 5	Batch 1620	Train Loss:1.127	Learning rate:0.00001
Loss_accusation:0.929	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.305	
Epoch 5	Batch 1640	Train Loss:1.127	Learning rate:0.00001
Epoch 5	Batch 1660	Train Loss:1.126	Learning rate:0.00001
Epoch 5	Batch 1680	Train Loss:1.125	Learning rate:0.00001
Loss_accusation:0.684	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.060	
Epoch 5	Batch 1700	Train Loss:1.124	Learning rate:0.00001
Epoch 5	Batch 1720	Train Loss:1.123	Learning rate:0.00001
Epoch 5	Batch 1740	Train Loss:1.123	Learning rate:0.00001
Loss_accusation:0.616	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:0.992	
Epoch 5	Batch 1760	Train Loss:1.123	Learning rate:0.00001
Epoch 5	Batch 1780	Train Loss:1.122	Learning rate:0.00001
Epoch 5	Batch 1800	Train Loss:1.122	Learning rate:0.00001
Loss_accusation:0.881	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.257	
Epoch 5	Batch 1820	Train Loss:1.122	Learning rate:0.00001
Epoch 5	Batch 1840	Train Loss:1.122	Learning rate:0.00001
Epoch 5	Batch 1860	Train Loss:1.122	Learning rate:0.00001
Loss_accusation:0.796	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.171	
Epoch 5	Batch 1880	Train Loss:1.122	Learning rate:0.00001
Epoch 5	Batch 1900	Train Loss:1.121	Learning rate:0.00001
Epoch 5	Batch 1920	Train Loss:1.121	Learning rate:0.00001
Loss_accusation:0.871	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.247	
Epoch 5	Batch 1940	Train Loss:1.121	Learning rate:0.00001
Epoch 5	Batch 1960	Train Loss:1.120	Learning rate:0.00001
Epoch 5	Batch 1980	Train Loss:1.119	Learning rate:0.00001
Loss_accusation:0.838	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.376	Current_loss:1.213	
Epoch 5	Batch 2000	Train Loss:1.119	Learning rate:0.00001
Epoch 5	Batch 2020	Train Loss:1.119	Learning rate:0.00001
Epoch 5	Batch 2040	Train Loss:1.119	Learning rate:0.00001
Loss_accusation:0.570	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:0.945	
Epoch 5	Batch 2060	Train Loss:1.119	Learning rate:0.00001
Epoch 5	Batch 2080	Train Loss:1.119	Learning rate:0.00001
Epoch 5	Batch 2100	Train Loss:1.119	Learning rate:0.00001
Loss_accusation:0.690	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:1.065	
Epoch 5	Batch 2120	Train Loss:1.118	Learning rate:0.00001
Epoch 5	Batch 2140	Train Loss:1.117	Learning rate:0.00001
Epoch 5	Batch 2160	Train Loss:1.117	Learning rate:0.00001
Loss_accusation:0.729	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:1.105	
Epoch 5	Batch 2180	Train Loss:1.117	Learning rate:0.00001
Epoch 5	Batch 2200	Train Loss:1.116	Learning rate:0.00001
Epoch 5	Batch 2220	Train Loss:1.116	Learning rate:0.00001
Loss_accusation:0.557	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:0.933	
Epoch 5	Batch 2240	Train Loss:1.115	Learning rate:0.00001
Epoch 5	Batch 2260	Train Loss:1.115	Learning rate:0.00001
Epoch 5	Batch 2280	Train Loss:1.114	Learning rate:0.00001
Loss_accusation:0.578	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:0.953	
Epoch 5	Batch 2300	Train Loss:1.114	Learning rate:0.00001
Epoch 5	Batch 2320	Train Loss:1.114	Learning rate:0.00001
Epoch 5	Batch 2340	Train Loss:1.114	Learning rate:0.00001
Loss_accusation:0.731	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:1.106	
Epoch 5	Batch 2360	Train Loss:1.113	Learning rate:0.00001
Epoch 5	Batch 2380	Train Loss:1.113	Learning rate:0.00001
Epoch 5	Batch 2400	Train Loss:1.112	Learning rate:0.00001
Loss_accusation:0.483	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:0.858	
Epoch 5	Batch 2420	Train Loss:1.111	Learning rate:0.00001
Epoch 5	Batch 2440	Train Loss:1.110	Learning rate:0.00001
Epoch 5	Batch 2460	Train Loss:1.110	Learning rate:0.00001
Loss_accusation:0.768	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:1.143	
Epoch 5	Batch 2480	Train Loss:1.109	Learning rate:0.00001
Epoch 5	Batch 2500	Train Loss:1.108	Learning rate:0.00001
Epoch 5	Batch 2520	Train Loss:1.108	Learning rate:0.00001
Loss_accusation:0.681	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:1.056	
Epoch 5	Batch 2540	Train Loss:1.107	Learning rate:0.00001
Epoch 5	Batch 2560	Train Loss:1.107	Learning rate:0.00001
Epoch 5	Batch 2580	Train Loss:1.107	Learning rate:0.00001
Loss_accusation:0.899	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.375	Current_loss:1.274	
Epoch 5	Batch 2600	Train Loss:1.107	Learning rate:0.00001
Epoch 5	Batch 2620	Train Loss:1.107	Learning rate:0.00001
Epoch 5	Batch 2640	Train Loss:1.106	Learning rate:0.00001
Loss_accusation:0.558	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.932	
Epoch 5	Batch 2660	Train Loss:1.106	Learning rate:0.00001
Epoch 5	Batch 2680	Train Loss:1.105	Learning rate:0.00001
Epoch 5	Batch 2700	Train Loss:1.104	Learning rate:0.00001
Loss_accusation:0.493	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.867	
Epoch 5	Batch 2720	Train Loss:1.104	Learning rate:0.00001
Epoch 5	Batch 2740	Train Loss:1.103	Learning rate:0.00001
Epoch 5	Batch 2760	Train Loss:1.103	Learning rate:0.00001
Loss_accusation:0.419	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.793	
Epoch 5	Batch 2780	Train Loss:1.102	Learning rate:0.00001
Epoch 5	Batch 2800	Train Loss:1.102	Learning rate:0.00001
Epoch 5	Batch 2820	Train Loss:1.101	Learning rate:0.00001
Loss_accusation:0.583	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.957	
Epoch 5	Batch 2840	Train Loss:1.101	Learning rate:0.00001
Epoch 5	Batch 2860	Train Loss:1.101	Learning rate:0.00001
Epoch 5	Batch 2880	Train Loss:1.101	Learning rate:0.00001
Loss_accusation:0.453	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.827	
Epoch 5	Batch 2900	Train Loss:1.100	Learning rate:0.00001
Epoch 5	Batch 2920	Train Loss:1.100	Learning rate:0.00001
Epoch 5	Batch 2940	Train Loss:1.099	Learning rate:0.00001
Loss_accusation:0.566	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.940	
Epoch 5	Batch 2960	Train Loss:1.099	Learning rate:0.00001
Epoch 5	Batch 2980	Train Loss:1.098	Learning rate:0.00001
Epoch 5	Batch 3000	Train Loss:1.098	Learning rate:0.00001
Loss_accusation:0.604	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.978	
Epoch 5	Batch 3020	Train Loss:1.097	Learning rate:0.00001
Epoch 5	Batch 3040	Train Loss:1.097	Learning rate:0.00001
Epoch 5	Batch 3060	Train Loss:1.097	Learning rate:0.00001
Loss_accusation:0.777	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:1.151	
Epoch 5	Batch 3080	Train Loss:1.097	Learning rate:0.00001
Epoch 5	Batch 3100	Train Loss:1.097	Learning rate:0.00001
Epoch 5	Batch 3120	Train Loss:1.096	Learning rate:0.00001
Loss_accusation:0.797	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:1.171	
Epoch 5	Batch 3140	Train Loss:1.096	Learning rate:0.00001
Epoch 5	Batch 3160	Train Loss:1.096	Learning rate:0.00001
Epoch 5	Batch 3180	Train Loss:1.095	Learning rate:0.00001
Loss_accusation:0.476	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.850	
Epoch 5	Batch 3200	Train Loss:1.095	Learning rate:0.00001
Epoch 5	Batch 3220	Train Loss:1.095	Learning rate:0.00001
Epoch 5	Batch 3240	Train Loss:1.094	Learning rate:0.00001
Loss_accusation:0.559	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.374	Current_loss:0.932	
Epoch 5	Batch 3260	Train Loss:1.094	Learning rate:0.00001
Epoch 5	Batch 3280	Train Loss:1.093	Learning rate:0.00001
Epoch 5	Batch 3300	Train Loss:1.093	Learning rate:0.00001
Loss_accusation:0.636	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:1.009	
Epoch 5	Batch 3320	Train Loss:1.093	Learning rate:0.00001
Epoch 5	Batch 3340	Train Loss:1.092	Learning rate:0.00001
Epoch 5	Batch 3360	Train Loss:1.092	Learning rate:0.00001
Loss_accusation:0.741	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:1.114	
Epoch 5	Batch 3380	Train Loss:1.092	Learning rate:0.00001
Epoch 5	Batch 3400	Train Loss:1.091	Learning rate:0.00001
Epoch 5	Batch 3420	Train Loss:1.091	Learning rate:0.00001
Loss_accusation:0.648	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:1.021	
Epoch 5	Batch 3440	Train Loss:1.091	Learning rate:0.00001
Epoch 5	Batch 3460	Train Loss:1.090	Learning rate:0.00001
Epoch 5	Batch 3480	Train Loss:1.090	Learning rate:0.00001
Loss_accusation:0.441	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:0.814	
Epoch 5	Batch 3500	Train Loss:1.089	Learning rate:0.00001
Epoch 5	Batch 3520	Train Loss:1.089	Learning rate:0.00001
Epoch 5	Batch 3540	Train Loss:1.088	Learning rate:0.00001
Loss_accusation:0.578	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:0.951	
Epoch 5	Batch 3560	Train Loss:1.088	Learning rate:0.00001
Epoch 5	Batch 3580	Train Loss:1.088	Learning rate:0.00001
Epoch 5	Batch 3600	Train Loss:1.088	Learning rate:0.00001
Loss_accusation:0.925	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:1.298	
Epoch 5	Batch 3620	Train Loss:1.088	Learning rate:0.00001
Epoch 5	Batch 3640	Train Loss:1.087	Learning rate:0.00001
Epoch 5	Batch 3660	Train Loss:1.087	Learning rate:0.00001
Loss_accusation:0.606	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:0.979	
Epoch 5	Batch 3680	Train Loss:1.086	Learning rate:0.00001
Epoch 5	Batch 3700	Train Loss:1.086	Learning rate:0.00001
Epoch 5	Batch 3720	Train Loss:1.086	Learning rate:0.00001
Loss_accusation:0.644	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:1.017	
Epoch 5	Batch 3740	Train Loss:1.085	Learning rate:0.00001
Epoch 5	Batch 3760	Train Loss:1.085	Learning rate:0.00001
Epoch 5	Batch 3780	Train Loss:1.085	Learning rate:0.00001
Loss_accusation:0.560	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:0.933	
Epoch 5	Batch 3800	Train Loss:1.085	Learning rate:0.00001
Epoch 5	Batch 3820	Train Loss:1.084	Learning rate:0.00001
Epoch 5	Batch 3840	Train Loss:1.084	Learning rate:0.00001
Loss_accusation:0.516	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:0.889	
Epoch 5	Batch 3860	Train Loss:1.084	Learning rate:0.00001
Epoch 5	Batch 3880	Train Loss:1.083	Learning rate:0.00001
Epoch 5	Batch 3900	Train Loss:1.083	Learning rate:0.00001
Loss_accusation:0.614	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.373	Current_loss:0.987	
('number_examples:', 13094)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score:', 1.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('imprisonment_score:', 0.0)
('f1_micro_accusation:', 0.9323310825441263, ';f1_macro_accusation:', 0.9221249330088004)
Epoch 5 ValidLoss:0.834	Macro_f1_accasation:0.922	Micro_f1_accsastion:0.932	Macro_f1_article:0.012 Micro_f1_article:0.012 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 92.72280077764634, ';2.Article Score:', 1.2416782075578374, ';3.Penalty Score:', 69.38469499496459, ';Score ALL:', 163.34917398016876)
going to save check point.
Epoch 5	Batch 3920	Train Loss:1.083	Learning rate:0.00001
Epoch 5	Batch 3940	Train Loss:1.082	Learning rate:0.00001
Epoch 5	Batch 3960	Train Loss:1.082	Learning rate:0.00001
Loss_accusation:0.558	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:0.930	
Epoch 5	Batch 3980	Train Loss:1.081	Learning rate:0.00001
Epoch 5	Batch 4000	Train Loss:1.081	Learning rate:0.00001
Epoch 5	Batch 4020	Train Loss:1.080	Learning rate:0.00001
Loss_accusation:0.785	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:1.158	
Epoch 5	Batch 4040	Train Loss:1.080	Learning rate:0.00001
Epoch 5	Batch 4060	Train Loss:1.079	Learning rate:0.00001
Epoch 5	Batch 4080	Train Loss:1.079	Learning rate:0.00001
Loss_accusation:0.735	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:1.108	
Epoch 5	Batch 4100	Train Loss:1.078	Learning rate:0.00001
Epoch 5	Batch 4120	Train Loss:1.078	Learning rate:0.00001
Epoch 5	Batch 4140	Train Loss:1.077	Learning rate:0.00001
Loss_accusation:0.588	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:0.961	
Epoch 5	Batch 4160	Train Loss:1.076	Learning rate:0.00001
Epoch 5	Batch 4180	Train Loss:1.076	Learning rate:0.00001
Epoch 5	Batch 4200	Train Loss:1.076	Learning rate:0.00001
Loss_accusation:1.040	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:1.412	
Epoch 5	Batch 4220	Train Loss:1.075	Learning rate:0.00001
Epoch 5	Batch 4240	Train Loss:1.075	Learning rate:0.00001
Epoch 5	Batch 4260	Train Loss:1.074	Learning rate:0.00001
Loss_accusation:0.648	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:1.020	
Epoch 5	Batch 4280	Train Loss:1.074	Learning rate:0.00001
Epoch 5	Batch 4300	Train Loss:1.073	Learning rate:0.00001
Epoch 5	Batch 4320	Train Loss:1.073	Learning rate:0.00001
Loss_accusation:0.524	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:0.896	
Epoch 5	Batch 4340	Train Loss:1.072	Learning rate:0.00001
Epoch 5	Batch 4360	Train Loss:1.072	Learning rate:0.00001
Epoch 5	Batch 4380	Train Loss:1.071	Learning rate:0.00001
Loss_accusation:0.634	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:1.006	
Epoch 5	Batch 4400	Train Loss:1.071	Learning rate:0.00001
Epoch 5	Batch 4420	Train Loss:1.070	Learning rate:0.00001
Epoch 5	Batch 4440	Train Loss:1.070	Learning rate:0.00001
Loss_accusation:0.569	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:0.941	
Epoch 5	Batch 4460	Train Loss:1.069	Learning rate:0.00001
Epoch 5	Batch 4480	Train Loss:1.068	Learning rate:0.00001
Epoch 5	Batch 4500	Train Loss:1.068	Learning rate:0.00001
Loss_accusation:0.644	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:1.016	
Epoch 5	Batch 4520	Train Loss:1.068	Learning rate:0.00001
Epoch 5	Batch 4540	Train Loss:1.067	Learning rate:0.00001
Epoch 5	Batch 4560	Train Loss:1.066	Learning rate:0.00001
Loss_accusation:0.496	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.372	Current_loss:0.867	
Epoch 5	Batch 4580	Train Loss:1.066	Learning rate:0.00001
Epoch 5	Batch 4600	Train Loss:1.066	Learning rate:0.00001
Epoch 5	Batch 4620	Train Loss:1.065	Learning rate:0.00001
Loss_accusation:0.488	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.859	
Epoch 5	Batch 4640	Train Loss:1.065	Learning rate:0.00001
Epoch 5	Batch 4660	Train Loss:1.065	Learning rate:0.00001
Epoch 5	Batch 4680	Train Loss:1.065	Learning rate:0.00001
Loss_accusation:0.411	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.783	
Epoch 5	Batch 4700	Train Loss:1.064	Learning rate:0.00001
Epoch 5	Batch 4720	Train Loss:1.064	Learning rate:0.00001
Epoch 5	Batch 4740	Train Loss:1.063	Learning rate:0.00001
Loss_accusation:0.738	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:1.109	
Epoch 5	Batch 4760	Train Loss:1.063	Learning rate:0.00001
Epoch 5	Batch 4780	Train Loss:1.063	Learning rate:0.00001
Epoch 5	Batch 4800	Train Loss:1.062	Learning rate:0.00001
Loss_accusation:0.643	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:1.014	
Epoch 5	Batch 4820	Train Loss:1.062	Learning rate:0.00001
Epoch 5	Batch 4840	Train Loss:1.062	Learning rate:0.00001
Epoch 5	Batch 4860	Train Loss:1.062	Learning rate:0.00001
Loss_accusation:0.417	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.788	
Epoch 5	Batch 4880	Train Loss:1.061	Learning rate:0.00001
Epoch 5	Batch 4900	Train Loss:1.061	Learning rate:0.00001
Epoch 5	Batch 4920	Train Loss:1.060	Learning rate:0.00001
Loss_accusation:0.523	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.894	
Epoch 5	Batch 4940	Train Loss:1.060	Learning rate:0.00001
Epoch 5	Batch 4960	Train Loss:1.060	Learning rate:0.00001
Epoch 5	Batch 4980	Train Loss:1.059	Learning rate:0.00001
Loss_accusation:0.518	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.889	
Epoch 5	Batch 5000	Train Loss:1.059	Learning rate:0.00001
Epoch 5	Batch 5020	Train Loss:1.058	Learning rate:0.00001
Epoch 5	Batch 5040	Train Loss:1.058	Learning rate:0.00001
Loss_accusation:0.454	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.825	
going to increment epoch counter....
(5, 1, True)
('number_examples:', 13094)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('x.imprisonment_score.target_value:', 60.0, ';predict_value:', 0.0)
('imprisonment_score:', 0.0)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('x.imprisonment_score.target_value:', 24.0, ';predict_value:', 0.0)
('imprisonment_score:', 0.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('x.imprisonment_score.target_value:', 12.0, ';predict_value:', 0.0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('death_lifeimprisonment_score:', 1.0)
('imprisonment_score:', 0.0)
('macro', 'precison:', '0.999995000025', ';recall:', '0.999995000025', ';f1_score:', 0.9999900000499999)
('f1_micro_accusation:', 0.9332023752239431, ';f1_macro_accusation:', 0.9154342364258887)
()
Epoch 5 ValidLoss:0.817	Macro_f1_accasation:0.915	Micro_f1_accsastion:0.933	Macro_f1_article:0.012	Micro_f1_article:0.013	Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('===>1.Accasation Score:', 92.43183058249159, ';2.Article Score:', 1.2420868511451912, ';3.Penalty Score:', 68.29094510219498, ';Score ALL:', 161.96486253583174)
Epoch 6	Batch 20	Train Loss:1.141	Learning rate:0.00001
Epoch 6	Batch 40	Train Loss:1.127	Learning rate:0.00001
Epoch 6	Batch 60	Train Loss:1.120	Learning rate:0.00001
Loss_accusation:0.530	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.901	
Epoch 6	Batch 80	Train Loss:1.122	Learning rate:0.00001
Epoch 6	Batch 100	Train Loss:1.110	Learning rate:0.00001
Epoch 6	Batch 120	Train Loss:1.104	Learning rate:0.00001
Loss_accusation:0.626	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:0.997	
Epoch 6	Batch 140	Train Loss:1.093	Learning rate:0.00001
Epoch 6	Batch 160	Train Loss:1.093	Learning rate:0.00001
Epoch 6	Batch 180	Train Loss:1.092	Learning rate:0.00001
Loss_accusation:0.847	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.371	Current_loss:1.217	
Epoch 6	Batch 200	Train Loss:1.082	Learning rate:0.00001
Epoch 6	Batch 220	Train Loss:1.080	Learning rate:0.00001
Epoch 6	Batch 240	Train Loss:1.078	Learning rate:0.00001
Loss_accusation:0.472	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:0.842	
Epoch 6	Batch 260	Train Loss:1.074	Learning rate:0.00001
Epoch 6	Batch 280	Train Loss:1.076	Learning rate:0.00001
Epoch 6	Batch 300	Train Loss:1.076	Learning rate:0.00001
Loss_accusation:0.812	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:1.183	
Epoch 6	Batch 320	Train Loss:1.074	Learning rate:0.00001
Epoch 6	Batch 340	Train Loss:1.072	Learning rate:0.00001
Epoch 6	Batch 360	Train Loss:1.073	Learning rate:0.00001
Loss_accusation:0.880	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:1.251	
Epoch 6	Batch 380	Train Loss:1.073	Learning rate:0.00001
Epoch 6	Batch 400	Train Loss:1.076	Learning rate:0.00001
Epoch 6	Batch 420	Train Loss:1.076	Learning rate:0.00001
Loss_accusation:0.544	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:0.914	
Epoch 6	Batch 440	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 460	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 480	Train Loss:1.074	Learning rate:0.00001
Loss_accusation:0.689	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:1.059	
Epoch 6	Batch 500	Train Loss:1.072	Learning rate:0.00001
Epoch 6	Batch 520	Train Loss:1.072	Learning rate:0.00001
Epoch 6	Batch 540	Train Loss:1.075	Learning rate:0.00001
Loss_accusation:0.518	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:0.888	
Epoch 6	Batch 560	Train Loss:1.074	Learning rate:0.00001
Epoch 6	Batch 580	Train Loss:1.073	Learning rate:0.00001
Epoch 6	Batch 600	Train Loss:1.075	Learning rate:0.00001
Loss_accusation:0.620	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:0.990	
Epoch 6	Batch 620	Train Loss:1.077	Learning rate:0.00001
Epoch 6	Batch 640	Train Loss:1.077	Learning rate:0.00001
Epoch 6	Batch 660	Train Loss:1.077	Learning rate:0.00001
Loss_accusation:0.861	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:1.231	
Epoch 6	Batch 680	Train Loss:1.077	Learning rate:0.00001
Epoch 6	Batch 700	Train Loss:1.079	Learning rate:0.00001
Epoch 6	Batch 720	Train Loss:1.078	Learning rate:0.00001
Loss_accusation:0.478	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:0.848	
Epoch 6	Batch 740	Train Loss:1.078	Learning rate:0.00001
Epoch 6	Batch 760	Train Loss:1.078	Learning rate:0.00001
Epoch 6	Batch 780	Train Loss:1.079	Learning rate:0.00001
Loss_accusation:0.783	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:1.153	
Epoch 6	Batch 800	Train Loss:1.079	Learning rate:0.00001
Epoch 6	Batch 820	Train Loss:1.080	Learning rate:0.00001
Epoch 6	Batch 840	Train Loss:1.080	Learning rate:0.00001
Loss_accusation:0.736	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:1.106	
Epoch 6	Batch 860	Train Loss:1.080	Learning rate:0.00001
Epoch 6	Batch 880	Train Loss:1.080	Learning rate:0.00001
Epoch 6	Batch 900	Train Loss:1.079	Learning rate:0.00001
Loss_accusation:0.523	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:0.893	
Epoch 6	Batch 920	Train Loss:1.079	Learning rate:0.00001
Epoch 6	Batch 940	Train Loss:1.079	Learning rate:0.00001
Epoch 6	Batch 960	Train Loss:1.078	Learning rate:0.00001
Loss_accusation:0.417	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.370	Current_loss:0.787	
Epoch 6	Batch 980	Train Loss:1.077	Learning rate:0.00001
Epoch 6	Batch 1000	Train Loss:1.076	Learning rate:0.00001
Epoch 6	Batch 1020	Train Loss:1.076	Learning rate:0.00001
Loss_accusation:0.655	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.025	
Epoch 6	Batch 1040	Train Loss:1.076	Learning rate:0.00001
Epoch 6	Batch 1060	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 1080	Train Loss:1.075	Learning rate:0.00001
Loss_accusation:0.714	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.084	
Epoch 6	Batch 1100	Train Loss:1.076	Learning rate:0.00001
Epoch 6	Batch 1120	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 1140	Train Loss:1.075	Learning rate:0.00001
Loss_accusation:0.892	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.262	
Epoch 6	Batch 1160	Train Loss:1.074	Learning rate:0.00001
Epoch 6	Batch 1180	Train Loss:1.074	Learning rate:0.00001
Epoch 6	Batch 1200	Train Loss:1.073	Learning rate:0.00001
Loss_accusation:0.861	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.230	
Epoch 6	Batch 1220	Train Loss:1.074	Learning rate:0.00001
Epoch 6	Batch 1240	Train Loss:1.074	Learning rate:0.00001
Epoch 6	Batch 1260	Train Loss:1.074	Learning rate:0.00001
Loss_accusation:1.049	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.418	
Epoch 6	Batch 1280	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 1300	Train Loss:1.076	Learning rate:0.00001
Epoch 6	Batch 1320	Train Loss:1.076	Learning rate:0.00001
Loss_accusation:0.655	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.024	
Epoch 6	Batch 1340	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 1360	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 1380	Train Loss:1.075	Learning rate:0.00001
Loss_accusation:0.653	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.022	
Epoch 6	Batch 1400	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 1420	Train Loss:1.075	Learning rate:0.00001
Epoch 6	Batch 1440	Train Loss:1.075	Learning rate:0.00001
Loss_accusation:0.573	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:0.942	
Epoch 6	Batch 1460	Train Loss:1.073	Learning rate:0.00001
Epoch 6	Batch 1480	Train Loss:1.073	Learning rate:0.00001
Epoch 6	Batch 1500	Train Loss:1.072	Learning rate:0.00001
Loss_accusation:0.752	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.121	
Epoch 6	Batch 1520	Train Loss:1.071	Learning rate:0.00001
Epoch 6	Batch 1540	Train Loss:1.071	Learning rate:0.00001
Epoch 6	Batch 1560	Train Loss:1.071	Learning rate:0.00001
Loss_accusation:0.841	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.210	
Epoch 6	Batch 1580	Train Loss:1.070	Learning rate:0.00001
Epoch 6	Batch 1600	Train Loss:1.070	Learning rate:0.00001
Epoch 6	Batch 1620	Train Loss:1.071	Learning rate:0.00001
Loss_accusation:0.780	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.149	
Epoch 6	Batch 1640	Train Loss:1.071	Learning rate:0.00001
Epoch 6	Batch 1660	Train Loss:1.071	Learning rate:0.00001
Epoch 6	Batch 1680	Train Loss:1.069	Learning rate:0.00001
Loss_accusation:0.663	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:1.031	
Epoch 6	Batch 1700	Train Loss:1.069	Learning rate:0.00001
Epoch 6	Batch 1720	Train Loss:1.068	Learning rate:0.00001
Epoch 6	Batch 1740	Train Loss:1.068	Learning rate:0.00001
Loss_accusation:0.513	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.369	Current_loss:0.881	
Epoch 6	Batch 1760	Train Loss:1.067	Learning rate:0.00001
Epoch 6	Batch 1780	Train Loss:1.067	Learning rate:0.00001
Epoch 6	Batch 1800	Train Loss:1.067	Learning rate:0.00001
Loss_accusation:0.755	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:1.123	
Epoch 6	Batch 1820	Train Loss:1.067	Learning rate:0.00001
Epoch 6	Batch 1840	Train Loss:1.067	Learning rate:0.00001
Epoch 6	Batch 1860	Train Loss:1.067	Learning rate:0.00001
Loss_accusation:0.782	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:1.151	
Epoch 6	Batch 1880	Train Loss:1.067	Learning rate:0.00001
Epoch 6	Batch 1900	Train Loss:1.066	Learning rate:0.00001
Epoch 6	Batch 1920	Train Loss:1.067	Learning rate:0.00001
Loss_accusation:0.719	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:1.087	
Epoch 6	Batch 1940	Train Loss:1.066	Learning rate:0.00001
Epoch 6	Batch 1960	Train Loss:1.066	Learning rate:0.00001
Epoch 6	Batch 1980	Train Loss:1.065	Learning rate:0.00001
Loss_accusation:0.593	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:0.961	
Epoch 6	Batch 2000	Train Loss:1.065	Learning rate:0.00001
Epoch 6	Batch 2020	Train Loss:1.065	Learning rate:0.00001
Epoch 6	Batch 2040	Train Loss:1.065	Learning rate:0.00001
Loss_accusation:0.526	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:0.894	
Epoch 6	Batch 2060	Train Loss:1.065	Learning rate:0.00001
Epoch 6	Batch 2080	Train Loss:1.065	Learning rate:0.00001
Epoch 6	Batch 2100	Train Loss:1.065	Learning rate:0.00001
Loss_accusation:0.729	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:1.097	
Epoch 6	Batch 2120	Train Loss:1.064	Learning rate:0.00001
Epoch 6	Batch 2140	Train Loss:1.064	Learning rate:0.00001
Epoch 6	Batch 2160	Train Loss:1.063	Learning rate:0.00001
Loss_accusation:0.565	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:0.933	
Epoch 6	Batch 2180	Train Loss:1.063	Learning rate:0.00001
Epoch 6	Batch 2200	Train Loss:1.063	Learning rate:0.00001
Epoch 6	Batch 2220	Train Loss:1.063	Learning rate:0.00001
Loss_accusation:0.530	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:0.898	
Epoch 6	Batch 2240	Train Loss:1.062	Learning rate:0.00001
Epoch 6	Batch 2260	Train Loss:1.062	Learning rate:0.00001
Epoch 6	Batch 2280	Train Loss:1.061	Learning rate:0.00001
Loss_accusation:0.617	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:0.985	
Epoch 6	Batch 2300	Train Loss:1.061	Learning rate:0.00001
Epoch 6	Batch 2320	Train Loss:1.062	Learning rate:0.00001
Epoch 6	Batch 2340	Train Loss:1.062	Learning rate:0.00001
Loss_accusation:0.823	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:1.191	
Epoch 6	Batch 2360	Train Loss:1.061	Learning rate:0.00001
Epoch 6	Batch 2380	Train Loss:1.061	Learning rate:0.00001
Epoch 6	Batch 2400	Train Loss:1.060	Learning rate:0.00001
Loss_accusation:0.550	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:0.918	
Epoch 6	Batch 2420	Train Loss:1.060	Learning rate:0.00001
Epoch 6	Batch 2440	Train Loss:1.059	Learning rate:0.00001
Epoch 6	Batch 2460	Train Loss:1.058	Learning rate:0.00001
Loss_accusation:0.640	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:1.008	
Epoch 6	Batch 2480	Train Loss:1.058	Learning rate:0.00001
Epoch 6	Batch 2500	Train Loss:1.057	Learning rate:0.00001
Epoch 6	Batch 2520	Train Loss:1.057	Learning rate:0.00001
Loss_accusation:0.799	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.368	Current_loss:1.167	
Epoch 6	Batch 2540	Train Loss:1.056	Learning rate:0.00001
Epoch 6	Batch 2560	Train Loss:1.056	Learning rate:0.00001
Epoch 6	Batch 2580	Train Loss:1.056	Learning rate:0.00001
Loss_accusation:0.812	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:1.179	
Epoch 6	Batch 2600	Train Loss:1.056	Learning rate:0.00001
Epoch 6	Batch 2620	Train Loss:1.056	Learning rate:0.00001
Epoch 6	Batch 2640	Train Loss:1.055	Learning rate:0.00001
Loss_accusation:0.595	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.963	
Epoch 6	Batch 2660	Train Loss:1.055	Learning rate:0.00001
Epoch 6	Batch 2680	Train Loss:1.055	Learning rate:0.00001
Epoch 6	Batch 2700	Train Loss:1.054	Learning rate:0.00001
Loss_accusation:0.416	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.784	
Epoch 6	Batch 2720	Train Loss:1.054	Learning rate:0.00001
Epoch 6	Batch 2740	Train Loss:1.053	Learning rate:0.00001
Epoch 6	Batch 2760	Train Loss:1.053	Learning rate:0.00001
Loss_accusation:0.360	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.727	
Epoch 6	Batch 2780	Train Loss:1.052	Learning rate:0.00001
Epoch 6	Batch 2800	Train Loss:1.052	Learning rate:0.00001
Epoch 6	Batch 2820	Train Loss:1.052	Learning rate:0.00001
Loss_accusation:0.639	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:1.007	
Epoch 6	Batch 2840	Train Loss:1.052	Learning rate:0.00001
Epoch 6	Batch 2860	Train Loss:1.051	Learning rate:0.00001
Epoch 6	Batch 2880	Train Loss:1.051	Learning rate:0.00001
Loss_accusation:0.540	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.907	
Epoch 6	Batch 2900	Train Loss:1.051	Learning rate:0.00001
Epoch 6	Batch 2920	Train Loss:1.050	Learning rate:0.00001
Epoch 6	Batch 2940	Train Loss:1.050	Learning rate:0.00001
Loss_accusation:0.724	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:1.091	
Epoch 6	Batch 2960	Train Loss:1.050	Learning rate:0.00001
Epoch 6	Batch 2980	Train Loss:1.049	Learning rate:0.00001
Epoch 6	Batch 3000	Train Loss:1.049	Learning rate:0.00001
Loss_accusation:0.553	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.920	
Epoch 6	Batch 3020	Train Loss:1.048	Learning rate:0.00001
Epoch 6	Batch 3040	Train Loss:1.048	Learning rate:0.00001
Epoch 6	Batch 3060	Train Loss:1.048	Learning rate:0.00001
Loss_accusation:0.725	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:1.092	
Epoch 6	Batch 3080	Train Loss:1.048	Learning rate:0.00001
Epoch 6	Batch 3100	Train Loss:1.048	Learning rate:0.00001
Epoch 6	Batch 3120	Train Loss:1.048	Learning rate:0.00001
Loss_accusation:0.666	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:1.033	
Epoch 6	Batch 3140	Train Loss:1.048	Learning rate:0.00001
Epoch 6	Batch 3160	Train Loss:1.048	Learning rate:0.00001
Epoch 6	Batch 3180	Train Loss:1.047	Learning rate:0.00001
Loss_accusation:0.482	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.849	
Epoch 6	Batch 3200	Train Loss:1.047	Learning rate:0.00001
Epoch 6	Batch 3220	Train Loss:1.047	Learning rate:0.00001
Epoch 6	Batch 3240	Train Loss:1.046	Learning rate:0.00001
Loss_accusation:0.530	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.897	
Epoch 6	Batch 3260	Train Loss:1.046	Learning rate:0.00001
Epoch 6	Batch 3280	Train Loss:1.045	Learning rate:0.00001
Epoch 6	Batch 3300	Train Loss:1.045	Learning rate:0.00001
Loss_accusation:0.581	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.367	Current_loss:0.948	
Epoch 6	Batch 3320	Train Loss:1.045	Learning rate:0.00001
Epoch 6	Batch 3340	Train Loss:1.044	Learning rate:0.00001
Epoch 6	Batch 3360	Train Loss:1.044	Learning rate:0.00001
Loss_accusation:0.786	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:1.152	
Epoch 6	Batch 3380	Train Loss:1.044	Learning rate:0.00001
Epoch 6	Batch 3400	Train Loss:1.044	Learning rate:0.00001
Epoch 6	Batch 3420	Train Loss:1.043	Learning rate:0.00001
Loss_accusation:0.545	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.911	
Epoch 6	Batch 3440	Train Loss:1.043	Learning rate:0.00001
Epoch 6	Batch 3460	Train Loss:1.043	Learning rate:0.00001
Epoch 6	Batch 3480	Train Loss:1.042	Learning rate:0.00001
Loss_accusation:0.486	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.852	
Epoch 6	Batch 3500	Train Loss:1.042	Learning rate:0.00001
Epoch 6	Batch 3520	Train Loss:1.041	Learning rate:0.00001
Epoch 6	Batch 3540	Train Loss:1.041	Learning rate:0.00001
Loss_accusation:0.467	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.834	
Epoch 6	Batch 3560	Train Loss:1.041	Learning rate:0.00001
Epoch 6	Batch 3580	Train Loss:1.041	Learning rate:0.00001
Epoch 6	Batch 3600	Train Loss:1.041	Learning rate:0.00001
Loss_accusation:0.805	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:1.171	
Epoch 6	Batch 3620	Train Loss:1.041	Learning rate:0.00001
Epoch 6	Batch 3640	Train Loss:1.040	Learning rate:0.00001
Epoch 6	Batch 3660	Train Loss:1.040	Learning rate:0.00001
Loss_accusation:0.670	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:1.036	
Epoch 6	Batch 3680	Train Loss:1.039	Learning rate:0.00001
Epoch 6	Batch 3700	Train Loss:1.039	Learning rate:0.00001
Epoch 6	Batch 3720	Train Loss:1.039	Learning rate:0.00001
Loss_accusation:0.612	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.978	
Epoch 6	Batch 3740	Train Loss:1.039	Learning rate:0.00001
Epoch 6	Batch 3760	Train Loss:1.038	Learning rate:0.00001
Epoch 6	Batch 3780	Train Loss:1.038	Learning rate:0.00001
Loss_accusation:0.729	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:1.095	
Epoch 6	Batch 3800	Train Loss:1.038	Learning rate:0.00001
Epoch 6	Batch 3820	Train Loss:1.038	Learning rate:0.00001
Epoch 6	Batch 3840	Train Loss:1.038	Learning rate:0.00001
Loss_accusation:0.633	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.999	
Epoch 6	Batch 3860	Train Loss:1.037	Learning rate:0.00001
Epoch 6	Batch 3880	Train Loss:1.037	Learning rate:0.00001
Epoch 6	Batch 3900	Train Loss:1.037	Learning rate:0.00001
Loss_accusation:0.523	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.889	
('number_examples:', 13094)
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('lifeimprisionment.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score:', 1.0)
('deathpenalty.y_target_labels:', [0], ';y_predict_labels:', [0, 1])
('death_lifeimprisonment_score.target:', 0, ';predict:', 0)
('article.y_target_labels:', [68], ';y_predict_labels:', [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182])
('macro', 'precison:', '0.920634847569', ';recall:', '0.906249929199', ';f1_score:', 0.9133807551888831)
('f1_micro_accusation:', 0.9369136653704377, ';f1_macro_accusation:', 0.9278941203720049)
Epoch 6 ValidLoss:0.803	Macro_f1_accasation:0.928	Micro_f1_accsastion:0.937	Macro_f1_article:0.012 Micro_f1_article:0.013 Macro_f1_deathpenalty:0.503	Micro_f1_deathpenalty:0.667	Macro_f1_lifeimprisonment:0.505	Micro_f1_lifeimprisonment:0.667	
('1.Accasation Score:', 93.24038928712213, ';2.Article Score:', 1.242152533395511, ';3.Penalty Score:', 68.60599817588263, ';Score ALL:', 163.08853999640027)
going to save check point.
Epoch 6	Batch 3920	Train Loss:1.037	Learning rate:0.00001
Epoch 6	Batch 3940	Train Loss:1.036	Learning rate:0.00001
Epoch 6	Batch 3960	Train Loss:1.036	Learning rate:0.00001
Loss_accusation:0.695	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:1.061	
Epoch 6	Batch 3980	Train Loss:1.035	Learning rate:0.00001
Epoch 6	Batch 4000	Train Loss:1.035	Learning rate:0.00001
Epoch 6	Batch 4020	Train Loss:1.034	Learning rate:0.00001
Loss_accusation:0.817	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:1.183	
Epoch 6	Batch 4040	Train Loss:1.034	Learning rate:0.00001
Epoch 6	Batch 4060	Train Loss:1.033	Learning rate:0.00001
Epoch 6	Batch 4080	Train Loss:1.033	Learning rate:0.00001
Loss_accusation:0.608	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.974	
Epoch 6	Batch 4100	Train Loss:1.033	Learning rate:0.00001
Epoch 6	Batch 4120	Train Loss:1.032	Learning rate:0.00001
Epoch 6	Batch 4140	Train Loss:1.032	Learning rate:0.00001
Loss_accusation:0.461	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.366	Current_loss:0.827	
Epoch 6	Batch 4160	Train Loss:1.031	Learning rate:0.00001
Epoch 6	Batch 4180	Train Loss:1.031	Learning rate:0.00001
Epoch 6	Batch 4200	Train Loss:1.031	Learning rate:0.00001
Loss_accusation:0.814	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.365	Current_loss:1.180	
Epoch 6	Batch 4220	Train Loss:1.030	Learning rate:0.00001
Epoch 6	Batch 4240	Train Loss:1.030	Learning rate:0.00001
Epoch 6	Batch 4260	Train Loss:1.029	Learning rate:0.00001
Loss_accusation:0.541	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.365	Current_loss:0.907	
Epoch 6	Batch 4280	Train Loss:1.029	Learning rate:0.00001
Epoch 6	Batch 4300	Train Loss:1.028	Learning rate:0.00001
Epoch 6	Batch 4320	Train Loss:1.028	Learning rate:0.00001
Loss_accusation:0.526	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.365	Current_loss:0.892	
Epoch 6	Batch 4340	Train Loss:1.028	Learning rate:0.00001
Epoch 6	Batch 4360	Train Loss:1.027	Learning rate:0.00001
Epoch 6	Batch 4380	Train Loss:1.027	Learning rate:0.00001
Loss_accusation:0.579	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.365	Current_loss:0.944	
Epoch 6	Batch 4400	Train Loss:1.027	Learning rate:0.00001
Epoch 6	Batch 4420	Train Loss:1.026	Learning rate:0.00001
Epoch 6	Batch 4440	Train Loss:1.026	Learning rate:0.00001
Loss_accusation:0.572	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.365	Current_loss:0.937	
Epoch 6	Batch 4460	Train Loss:1.025	Learning rate:0.00001
Epoch 6	Batch 4480	Train Loss:1.025	Learning rate:0.00001
Epoch 6	Batch 4500	Train Loss:1.024	Learning rate:0.00001
Loss_accusation:0.587	Loss_article:0.000	Loss_deathpenalty:0.000	Loss_lifeimprisonment:0.000	Loss_imprisonment:0.000	L2_loss:0.365	Current_loss:0.952	
Epoch 6	Batch 4520	Train Loss:1.024	Learning rate:0.00001
Epoch 6	Batch 4540	Train Loss:1.023	Learning rate:0.00001
